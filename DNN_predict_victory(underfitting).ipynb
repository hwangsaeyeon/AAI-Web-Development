{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN_predict_victory.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMyjpLq+REFUqoRhWdFn3DE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwangsaeyeon/AAI-Web-Development/blob/main/DNN_predict_victory(underfitting).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfK2tEaPejqp",
        "outputId": "44d8ed7d-7a94-41d1-a42a-5deaa83f4efc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "x = pd.read_csv(\"/content/drive/MyDrive/2022 인공지능 웹 개발 대회/Data/Data_Processing_xData.csv\")\n",
        "x = x.drop(['Unnamed: 0'], axis=1)\n",
        "\n",
        "y = pd.read_csv(\"/content/drive/MyDrive/2022 인공지능 웹 개발 대회/Data/Data_Processing_yData.csv\")\n",
        "y = y.drop(['Unnamed: 0'], axis=1)"
      ],
      "metadata": {
        "id": "ah2c5YrXocMp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jybRO0UvpV93",
        "outputId": "29af9f67-4e8a-4f4f-80c1-070ea350d94a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5449 entries, 0 to 5448\n",
            "Data columns (total 20 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   A0      5440 non-null   float64\n",
            " 1   A1      5448 non-null   float64\n",
            " 2   A2      5449 non-null   float64\n",
            " 3   A3      5449 non-null   float64\n",
            " 4   A4      5420 non-null   float64\n",
            " 5   A5      5443 non-null   float64\n",
            " 6   A6      5448 non-null   float64\n",
            " 7   A7      5442 non-null   float64\n",
            " 8   A8      5444 non-null   float64\n",
            " 9   A9      5432 non-null   float64\n",
            " 10  H0      5445 non-null   float64\n",
            " 11  H1      5445 non-null   float64\n",
            " 12  H2      5449 non-null   float64\n",
            " 13  H3      5447 non-null   float64\n",
            " 14  H4      5430 non-null   float64\n",
            " 15  H5      5447 non-null   float64\n",
            " 16  H6      5446 non-null   float64\n",
            " 17  H7      5445 non-null   float64\n",
            " 18  H8      5443 non-null   float64\n",
            " 19  H9      5438 non-null   float64\n",
            "dtypes: float64(20)\n",
            "memory usage: 851.5 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y,return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eCAqpzRnRbu",
        "outputId": "37007315-8a05-4134-964a-2bedadc64f7b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([2942, 2507]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "x = pd.read_csv(\"/content/drive/MyDrive/2022 인공지능 웹 개발 대회/Data/Data_Processing_xData.csv\")\n",
        "x = x.drop(['Unnamed: 0'], axis=1)\n",
        "# xData nan 값을 해당하는 열의 평균값으로 변경하기\n",
        "xData_column = ['A0','A1','A2','A3','A4','A5','A6','A7','A8','A9','H0','H1','H2','H3','H4','H5','H6','H7','H8','H9']\n",
        "def avg(col):\n",
        "  nanCheck = 0\n",
        "  for i in range(len(x)):\n",
        "      for column in xData_column:\n",
        "          if math.isnan(x[column][i]):\n",
        "              x[column][i] = round(x[column].mean(), 2)\n",
        "              nanCheck += 1\n",
        "  print('%d 개의 nan 값을 각 열의 평균값으로 변경 완료했습니다.' %nanCheck)\n",
        "  return x"
      ],
      "metadata": {
        "id": "JQ2MWMa6cq8p"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "x = pd.read_csv(\"/content/drive/MyDrive/2022 인공지능 웹 개발 대회/Data/Data_Processing_xData.csv\")\n",
        "x = x.drop(['Unnamed: 0'], axis=1)\n",
        "y = pd.read_csv(\"/content/drive/MyDrive/2022 인공지능 웹 개발 대회/Data/Data_Processing_yData.csv\")\n",
        "y = y.drop(['Unnamed: 0'], axis=1)\n",
        "y = np.array(y)\n",
        "\n",
        "x = avg(xData_column)\n",
        "x_away = np.array(x.iloc[:,0:10])\n",
        "x_home = np.array(x.iloc[:,10:])\n",
        "X = pd.concat([pd.DataFrame(x_away),pd.DataFrame(x_home)])\n",
        "X = pd.DataFrame(np.array(X))\n",
        "\n",
        "inverse_y = np.zeros(len(y))\n",
        "inverse_y = np.array(inverse_y).reshape(-1,1)\n",
        "\n",
        "for i in range(len(y)):\n",
        "  inverse_y[i] = 1 - y[i]\n",
        "y = pd.DataFrame(y)\n",
        "inverse_y = pd.DataFrame(inverse_y)\n",
        "y = pd.concat([y,inverse_y])\n",
        "y = pd.DataFrame(np.array(y))\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "print(X_train.shape, X_test.shape)\n",
        "print(y_train.shape, y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "input_shape = [X_train.shape[1]]\n",
        "model = tf.keras.models.Sequential([\n",
        "    #tf.keras.layers.Flatten(input_shape = input_shape),\n",
        "    #tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(30,activation='relu'),\n",
        "    tf.keras.layers.Dense(24,activation='relu'),\n",
        "    tf.keras.layers.Dense(12,activation='relu'),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(4,activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid'),])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "hist = model.fit(X_train, y_train, epochs=30,validation_split=0.2,batch_size=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1cGDvj0Y-vB",
        "outputId": "182ce86a-c76a-4e97-f98b-fe7c77279c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 개의 nan 값을 각 열의 평균값으로 변경 완료했습니다.\n",
            "(8718, 10) (2180, 10)\n",
            "(8718, 1) (2180, 1)\n",
            "Epoch 1/30\n",
            "1395/1395 [==============================] - 5s 3ms/step - loss: 0.6954 - binary_accuracy: 0.4964 - val_loss: 0.6934 - val_binary_accuracy: 0.5103\n",
            "Epoch 2/30\n",
            "1395/1395 [==============================] - 5s 3ms/step - loss: 0.6931 - binary_accuracy: 0.5194 - val_loss: 0.6931 - val_binary_accuracy: 0.5138\n",
            "Epoch 3/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6923 - binary_accuracy: 0.5231 - val_loss: 0.6926 - val_binary_accuracy: 0.5206\n",
            "Epoch 4/30\n",
            "1395/1395 [==============================] - 5s 3ms/step - loss: 0.6916 - binary_accuracy: 0.5254 - val_loss: 0.6923 - val_binary_accuracy: 0.5235\n",
            "Epoch 5/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6917 - binary_accuracy: 0.5247 - val_loss: 0.6928 - val_binary_accuracy: 0.5149\n",
            "Epoch 6/30\n",
            "1395/1395 [==============================] - 5s 3ms/step - loss: 0.6914 - binary_accuracy: 0.5252 - val_loss: 0.6918 - val_binary_accuracy: 0.5344\n",
            "Epoch 7/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6909 - binary_accuracy: 0.5254 - val_loss: 0.6915 - val_binary_accuracy: 0.5384\n",
            "Epoch 8/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6899 - binary_accuracy: 0.5343 - val_loss: 0.6903 - val_binary_accuracy: 0.5499\n",
            "Epoch 9/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6890 - binary_accuracy: 0.5346 - val_loss: 0.6891 - val_binary_accuracy: 0.5407\n",
            "Epoch 10/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6881 - binary_accuracy: 0.5341 - val_loss: 0.6893 - val_binary_accuracy: 0.5493\n",
            "Epoch 11/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6878 - binary_accuracy: 0.5336 - val_loss: 0.6897 - val_binary_accuracy: 0.5482\n",
            "Epoch 12/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6891 - binary_accuracy: 0.5338 - val_loss: 0.6898 - val_binary_accuracy: 0.5447\n",
            "Epoch 13/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6890 - binary_accuracy: 0.5300 - val_loss: 0.6898 - val_binary_accuracy: 0.5413\n",
            "Epoch 14/30\n",
            "1395/1395 [==============================] - 5s 4ms/step - loss: 0.6892 - binary_accuracy: 0.5346 - val_loss: 0.6891 - val_binary_accuracy: 0.5459\n",
            "Epoch 15/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6881 - binary_accuracy: 0.5396 - val_loss: 0.6893 - val_binary_accuracy: 0.5424\n",
            "Epoch 16/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6868 - binary_accuracy: 0.5450 - val_loss: 0.6885 - val_binary_accuracy: 0.5482\n",
            "Epoch 17/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6869 - binary_accuracy: 0.5475 - val_loss: 0.6892 - val_binary_accuracy: 0.5413\n",
            "Epoch 18/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6875 - binary_accuracy: 0.5424 - val_loss: 0.6879 - val_binary_accuracy: 0.5464\n",
            "Epoch 19/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6870 - binary_accuracy: 0.5423 - val_loss: 0.6873 - val_binary_accuracy: 0.5539\n",
            "Epoch 20/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6859 - binary_accuracy: 0.5479 - val_loss: 0.6875 - val_binary_accuracy: 0.5447\n",
            "Epoch 21/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6856 - binary_accuracy: 0.5525 - val_loss: 0.6886 - val_binary_accuracy: 0.5487\n",
            "Epoch 22/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6855 - binary_accuracy: 0.5442 - val_loss: 0.6871 - val_binary_accuracy: 0.5539\n",
            "Epoch 23/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6854 - binary_accuracy: 0.5536 - val_loss: 0.6864 - val_binary_accuracy: 0.5573\n",
            "Epoch 24/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6864 - binary_accuracy: 0.5510 - val_loss: 0.6874 - val_binary_accuracy: 0.5482\n",
            "Epoch 25/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6846 - binary_accuracy: 0.5510 - val_loss: 0.6866 - val_binary_accuracy: 0.5579\n",
            "Epoch 26/30\n",
            "1395/1395 [==============================] - 4s 3ms/step - loss: 0.6841 - binary_accuracy: 0.5568 - val_loss: 0.6863 - val_binary_accuracy: 0.5505\n",
            "Epoch 27/30\n",
            " 418/1395 [=======>......................] - ETA: 2s - loss: 0.6848 - binary_accuracy: 0.5541"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "plt.plot(hist.history['binary_accuracy'])\n",
        "plt.plot(hist.history['val_binary_accuracy'])\n",
        "plt.title('Accuracy')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "VTfHMT6efZMs",
        "outputId": "f3434408-2c4a-457d-9ed3-f3844b91f78e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "x = pd.read_csv(\"/content/drive/MyDrive/2022 인공지능 웹 개발 대회/Data/Data_Processing_xData.csv\")\n",
        "x = x.drop(['Unnamed: 0'], axis=1)\n",
        "y = pd.read_csv(\"/content/drive/MyDrive/2022 인공지능 웹 개발 대회/Data/Data_Processing_yData.csv\")\n",
        "y = y.drop(['Unnamed: 0'], axis=1)\n",
        "y = np.array(y)\n",
        "\n",
        "x = avg(xData_column)\n",
        "\n",
        "X = np.array(x.iloc[:,0:10]) - np.array(x.iloc[:,10:])\n",
        "for i in range(len(X)):\n",
        "  for j in range(len(X[0])):\n",
        "    if X[i][j] < 0 :\n",
        "      X[i][j] = 0 \n",
        "    elif X[i][j] > 0:\n",
        "      X[i][j] = 1\n",
        "    else:\n",
        "      X[i][j] = 0.5\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "print(X_train.shape, X_test.shape)\n",
        "print(y_train.shape, y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "input_shape = [X_train.shape[1]]\n",
        "model = tf.keras.models.Sequential([\n",
        "    #tf.keras.layers.Flatten(input_shape = input_shape),\n",
        "    #tf.keras.layers.BatchNormalization(),\n",
        "    \n",
        "    #tf.keras.layers.Dense(12,activation='relu'),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(4,activation='relu'),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid'),])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "hist = model.fit(X_train, y_train, epochs=200 ,validation_split=0.2,batch_size=5)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PA7N3d5WwLur",
        "outputId": "1f1d3c5f-dc20-43cc-f8d4-f46a7d70b044"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 개의 nan 값을 각 열의 평균값으로 변경 완료했습니다.\n",
            "(4359, 10) (1090, 10)\n",
            "(4359, 1) (1090, 1)\n",
            "Epoch 1/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6897 - binary_accuracy: 0.5472 - val_loss: 0.6934 - val_binary_accuracy: 0.5206\n",
            "Epoch 2/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6795 - binary_accuracy: 0.5500 - val_loss: 0.7115 - val_binary_accuracy: 0.5206\n",
            "Epoch 3/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6713 - binary_accuracy: 0.5856 - val_loss: 0.6850 - val_binary_accuracy: 0.5745\n",
            "Epoch 4/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6723 - binary_accuracy: 0.5830 - val_loss: 0.6826 - val_binary_accuracy: 0.5688\n",
            "Epoch 5/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6721 - binary_accuracy: 0.5802 - val_loss: 0.6870 - val_binary_accuracy: 0.5757\n",
            "Epoch 6/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6711 - binary_accuracy: 0.5787 - val_loss: 0.6928 - val_binary_accuracy: 0.5677\n",
            "Epoch 7/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6702 - binary_accuracy: 0.5919 - val_loss: 0.6844 - val_binary_accuracy: 0.5619\n",
            "Epoch 8/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6705 - binary_accuracy: 0.5813 - val_loss: 0.6892 - val_binary_accuracy: 0.5722\n",
            "Epoch 9/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6691 - binary_accuracy: 0.5850 - val_loss: 0.6918 - val_binary_accuracy: 0.5780\n",
            "Epoch 10/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6688 - binary_accuracy: 0.5931 - val_loss: 0.6884 - val_binary_accuracy: 0.5619\n",
            "Epoch 11/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6691 - binary_accuracy: 0.5827 - val_loss: 0.6888 - val_binary_accuracy: 0.5791\n",
            "Epoch 12/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6697 - binary_accuracy: 0.5847 - val_loss: 0.6859 - val_binary_accuracy: 0.5562\n",
            "Epoch 13/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6669 - binary_accuracy: 0.5916 - val_loss: 0.6860 - val_binary_accuracy: 0.5654\n",
            "Epoch 14/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6685 - binary_accuracy: 0.5868 - val_loss: 0.6881 - val_binary_accuracy: 0.5677\n",
            "Epoch 15/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6672 - binary_accuracy: 0.5865 - val_loss: 0.6997 - val_binary_accuracy: 0.5608\n",
            "Epoch 16/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6668 - binary_accuracy: 0.5931 - val_loss: 0.6936 - val_binary_accuracy: 0.5711\n",
            "Epoch 17/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6677 - binary_accuracy: 0.5902 - val_loss: 0.7022 - val_binary_accuracy: 0.5722\n",
            "Epoch 18/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6666 - binary_accuracy: 0.5945 - val_loss: 0.6889 - val_binary_accuracy: 0.5642\n",
            "Epoch 19/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6668 - binary_accuracy: 0.5974 - val_loss: 0.6857 - val_binary_accuracy: 0.5791\n",
            "Epoch 20/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6673 - binary_accuracy: 0.5939 - val_loss: 0.6999 - val_binary_accuracy: 0.5745\n",
            "Epoch 21/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6655 - binary_accuracy: 0.5933 - val_loss: 0.7093 - val_binary_accuracy: 0.5734\n",
            "Epoch 22/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6672 - binary_accuracy: 0.5933 - val_loss: 0.6860 - val_binary_accuracy: 0.5642\n",
            "Epoch 23/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6666 - binary_accuracy: 0.5962 - val_loss: 0.6868 - val_binary_accuracy: 0.5585\n",
            "Epoch 24/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6660 - binary_accuracy: 0.5988 - val_loss: 0.6972 - val_binary_accuracy: 0.5654\n",
            "Epoch 25/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6656 - binary_accuracy: 0.5888 - val_loss: 0.6860 - val_binary_accuracy: 0.5619\n",
            "Epoch 26/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6659 - binary_accuracy: 0.5942 - val_loss: 0.6910 - val_binary_accuracy: 0.5562\n",
            "Epoch 27/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6671 - binary_accuracy: 0.5965 - val_loss: 0.6974 - val_binary_accuracy: 0.5608\n",
            "Epoch 28/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6652 - binary_accuracy: 0.5948 - val_loss: 0.6917 - val_binary_accuracy: 0.5608\n",
            "Epoch 29/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6652 - binary_accuracy: 0.5919 - val_loss: 0.6899 - val_binary_accuracy: 0.5562\n",
            "Epoch 30/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6655 - binary_accuracy: 0.5885 - val_loss: 0.6986 - val_binary_accuracy: 0.5631\n",
            "Epoch 31/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6646 - binary_accuracy: 0.5965 - val_loss: 0.7006 - val_binary_accuracy: 0.5711\n",
            "Epoch 32/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6653 - binary_accuracy: 0.5982 - val_loss: 0.6885 - val_binary_accuracy: 0.5585\n",
            "Epoch 33/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6650 - binary_accuracy: 0.5954 - val_loss: 0.6959 - val_binary_accuracy: 0.5619\n",
            "Epoch 34/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6640 - binary_accuracy: 0.5991 - val_loss: 0.7143 - val_binary_accuracy: 0.5654\n",
            "Epoch 35/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6639 - binary_accuracy: 0.5954 - val_loss: 0.6969 - val_binary_accuracy: 0.5596\n",
            "Epoch 36/200\n",
            "698/698 [==============================] - 3s 5ms/step - loss: 0.6639 - binary_accuracy: 0.5971 - val_loss: 0.6956 - val_binary_accuracy: 0.5585\n",
            "Epoch 37/200\n",
            "698/698 [==============================] - 3s 5ms/step - loss: 0.6645 - binary_accuracy: 0.5933 - val_loss: 0.6983 - val_binary_accuracy: 0.5585\n",
            "Epoch 38/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6646 - binary_accuracy: 0.5956 - val_loss: 0.6918 - val_binary_accuracy: 0.5654\n",
            "Epoch 39/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6645 - binary_accuracy: 0.5979 - val_loss: 0.6899 - val_binary_accuracy: 0.5711\n",
            "Epoch 40/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6652 - binary_accuracy: 0.5942 - val_loss: 0.6939 - val_binary_accuracy: 0.5665\n",
            "Epoch 41/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6640 - binary_accuracy: 0.5850 - val_loss: 0.6899 - val_binary_accuracy: 0.5654\n",
            "Epoch 42/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6641 - binary_accuracy: 0.5876 - val_loss: 0.7049 - val_binary_accuracy: 0.5596\n",
            "Epoch 43/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6642 - binary_accuracy: 0.5908 - val_loss: 0.6948 - val_binary_accuracy: 0.5539\n",
            "Epoch 44/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6641 - binary_accuracy: 0.5925 - val_loss: 0.7084 - val_binary_accuracy: 0.5688\n",
            "Epoch 45/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6638 - binary_accuracy: 0.5913 - val_loss: 0.7073 - val_binary_accuracy: 0.5608\n",
            "Epoch 46/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6640 - binary_accuracy: 0.5945 - val_loss: 0.7012 - val_binary_accuracy: 0.5608\n",
            "Epoch 47/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6640 - binary_accuracy: 0.5962 - val_loss: 0.6903 - val_binary_accuracy: 0.5665\n",
            "Epoch 48/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6630 - binary_accuracy: 0.5956 - val_loss: 0.6941 - val_binary_accuracy: 0.5585\n",
            "Epoch 49/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6629 - binary_accuracy: 0.5931 - val_loss: 0.7026 - val_binary_accuracy: 0.5631\n",
            "Epoch 50/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6643 - binary_accuracy: 0.5945 - val_loss: 0.6927 - val_binary_accuracy: 0.5528\n",
            "Epoch 51/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6622 - binary_accuracy: 0.5890 - val_loss: 0.6975 - val_binary_accuracy: 0.5711\n",
            "Epoch 52/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6619 - binary_accuracy: 0.5968 - val_loss: 0.6918 - val_binary_accuracy: 0.5677\n",
            "Epoch 53/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6633 - binary_accuracy: 0.5933 - val_loss: 0.6908 - val_binary_accuracy: 0.5654\n",
            "Epoch 54/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6627 - binary_accuracy: 0.5985 - val_loss: 0.6892 - val_binary_accuracy: 0.5493\n",
            "Epoch 55/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6631 - binary_accuracy: 0.5948 - val_loss: 0.7031 - val_binary_accuracy: 0.5596\n",
            "Epoch 56/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6650 - binary_accuracy: 0.5971 - val_loss: 0.7109 - val_binary_accuracy: 0.5745\n",
            "Epoch 57/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6636 - binary_accuracy: 0.5925 - val_loss: 0.6920 - val_binary_accuracy: 0.5585\n",
            "Epoch 58/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6632 - binary_accuracy: 0.5928 - val_loss: 0.6893 - val_binary_accuracy: 0.5608\n",
            "Epoch 59/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6631 - binary_accuracy: 0.5962 - val_loss: 0.6995 - val_binary_accuracy: 0.5688\n",
            "Epoch 60/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6627 - binary_accuracy: 0.5948 - val_loss: 0.7208 - val_binary_accuracy: 0.5654\n",
            "Epoch 61/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6636 - binary_accuracy: 0.5928 - val_loss: 0.6946 - val_binary_accuracy: 0.5642\n",
            "Epoch 62/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6631 - binary_accuracy: 0.5971 - val_loss: 0.6894 - val_binary_accuracy: 0.5642\n",
            "Epoch 63/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6630 - binary_accuracy: 0.5968 - val_loss: 0.6968 - val_binary_accuracy: 0.5665\n",
            "Epoch 64/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6627 - binary_accuracy: 0.5931 - val_loss: 0.7053 - val_binary_accuracy: 0.5677\n",
            "Epoch 65/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6628 - binary_accuracy: 0.5945 - val_loss: 0.6995 - val_binary_accuracy: 0.5711\n",
            "Epoch 66/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6612 - binary_accuracy: 0.5965 - val_loss: 0.7074 - val_binary_accuracy: 0.5665\n",
            "Epoch 67/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6630 - binary_accuracy: 0.5911 - val_loss: 0.7042 - val_binary_accuracy: 0.5642\n",
            "Epoch 68/200\n",
            "698/698 [==============================] - 2s 3ms/step - loss: 0.6634 - binary_accuracy: 0.5942 - val_loss: 0.6998 - val_binary_accuracy: 0.5608\n",
            "Epoch 69/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6614 - binary_accuracy: 0.6011 - val_loss: 0.6929 - val_binary_accuracy: 0.5734\n",
            "Epoch 70/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6633 - binary_accuracy: 0.5890 - val_loss: 0.6923 - val_binary_accuracy: 0.5722\n",
            "Epoch 71/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6621 - binary_accuracy: 0.5951 - val_loss: 0.6948 - val_binary_accuracy: 0.5424\n",
            "Epoch 72/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6632 - binary_accuracy: 0.5936 - val_loss: 0.6875 - val_binary_accuracy: 0.5493\n",
            "Epoch 73/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6625 - binary_accuracy: 0.5922 - val_loss: 0.7120 - val_binary_accuracy: 0.5505\n",
            "Epoch 74/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6625 - binary_accuracy: 0.5913 - val_loss: 0.6945 - val_binary_accuracy: 0.5550\n",
            "Epoch 75/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6613 - binary_accuracy: 0.5968 - val_loss: 0.7028 - val_binary_accuracy: 0.5585\n",
            "Epoch 76/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6632 - binary_accuracy: 0.5939 - val_loss: 0.6864 - val_binary_accuracy: 0.5585\n",
            "Epoch 77/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6626 - binary_accuracy: 0.5982 - val_loss: 0.6855 - val_binary_accuracy: 0.5562\n",
            "Epoch 78/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6636 - binary_accuracy: 0.5916 - val_loss: 0.7055 - val_binary_accuracy: 0.5642\n",
            "Epoch 79/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6626 - binary_accuracy: 0.5959 - val_loss: 0.7162 - val_binary_accuracy: 0.5642\n",
            "Epoch 80/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6614 - binary_accuracy: 0.5956 - val_loss: 0.6953 - val_binary_accuracy: 0.5562\n",
            "Epoch 81/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6617 - binary_accuracy: 0.5951 - val_loss: 0.6978 - val_binary_accuracy: 0.5585\n",
            "Epoch 82/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6623 - binary_accuracy: 0.5951 - val_loss: 0.7147 - val_binary_accuracy: 0.5608\n",
            "Epoch 83/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6618 - binary_accuracy: 0.5939 - val_loss: 0.6918 - val_binary_accuracy: 0.5470\n",
            "Epoch 84/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6636 - binary_accuracy: 0.5913 - val_loss: 0.6952 - val_binary_accuracy: 0.5562\n",
            "Epoch 85/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6626 - binary_accuracy: 0.5922 - val_loss: 0.7060 - val_binary_accuracy: 0.5562\n",
            "Epoch 86/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6624 - binary_accuracy: 0.5976 - val_loss: 0.6900 - val_binary_accuracy: 0.5562\n",
            "Epoch 87/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6624 - binary_accuracy: 0.5976 - val_loss: 0.6983 - val_binary_accuracy: 0.5528\n",
            "Epoch 88/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6625 - binary_accuracy: 0.5885 - val_loss: 0.6968 - val_binary_accuracy: 0.5596\n",
            "Epoch 89/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6609 - binary_accuracy: 0.5962 - val_loss: 0.6942 - val_binary_accuracy: 0.5642\n",
            "Epoch 90/200\n",
            "698/698 [==============================] - 2s 3ms/step - loss: 0.6623 - binary_accuracy: 0.5991 - val_loss: 0.6965 - val_binary_accuracy: 0.5539\n",
            "Epoch 91/200\n",
            "698/698 [==============================] - 3s 4ms/step - loss: 0.6631 - binary_accuracy: 0.5919 - val_loss: 0.6961 - val_binary_accuracy: 0.5573\n",
            "Epoch 92/200\n",
            "698/698 [==============================] - 3s 4ms/step - loss: 0.6630 - binary_accuracy: 0.5936 - val_loss: 0.7058 - val_binary_accuracy: 0.5619\n",
            "Epoch 93/200\n",
            "698/698 [==============================] - 3s 4ms/step - loss: 0.6625 - binary_accuracy: 0.5933 - val_loss: 0.6944 - val_binary_accuracy: 0.5539\n",
            "Epoch 94/200\n",
            "698/698 [==============================] - 2s 3ms/step - loss: 0.6628 - binary_accuracy: 0.5945 - val_loss: 0.7194 - val_binary_accuracy: 0.5700\n",
            "Epoch 95/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6630 - binary_accuracy: 0.5908 - val_loss: 0.7027 - val_binary_accuracy: 0.5573\n",
            "Epoch 96/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6619 - binary_accuracy: 0.5951 - val_loss: 0.6989 - val_binary_accuracy: 0.5642\n",
            "Epoch 97/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6618 - binary_accuracy: 0.5959 - val_loss: 0.6879 - val_binary_accuracy: 0.5424\n",
            "Epoch 98/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6607 - binary_accuracy: 0.5945 - val_loss: 0.7027 - val_binary_accuracy: 0.5562\n",
            "Epoch 99/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6626 - binary_accuracy: 0.5956 - val_loss: 0.6980 - val_binary_accuracy: 0.5711\n",
            "Epoch 100/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6621 - binary_accuracy: 0.6025 - val_loss: 0.6994 - val_binary_accuracy: 0.5596\n",
            "Epoch 101/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6613 - binary_accuracy: 0.5945 - val_loss: 0.6916 - val_binary_accuracy: 0.5688\n",
            "Epoch 102/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6629 - binary_accuracy: 0.5928 - val_loss: 0.6989 - val_binary_accuracy: 0.5596\n",
            "Epoch 103/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6623 - binary_accuracy: 0.5919 - val_loss: 0.6940 - val_binary_accuracy: 0.5562\n",
            "Epoch 104/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6624 - binary_accuracy: 0.5951 - val_loss: 0.6984 - val_binary_accuracy: 0.5550\n",
            "Epoch 105/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6628 - binary_accuracy: 0.5905 - val_loss: 0.6919 - val_binary_accuracy: 0.5677\n",
            "Epoch 106/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6621 - binary_accuracy: 0.5942 - val_loss: 0.6871 - val_binary_accuracy: 0.5642\n",
            "Epoch 107/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6626 - binary_accuracy: 0.5908 - val_loss: 0.6986 - val_binary_accuracy: 0.5677\n",
            "Epoch 108/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6624 - binary_accuracy: 0.5956 - val_loss: 0.6929 - val_binary_accuracy: 0.5562\n",
            "Epoch 109/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6622 - binary_accuracy: 0.5968 - val_loss: 0.6955 - val_binary_accuracy: 0.5596\n",
            "Epoch 110/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6628 - binary_accuracy: 0.5965 - val_loss: 0.6910 - val_binary_accuracy: 0.5585\n",
            "Epoch 111/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6629 - binary_accuracy: 0.5916 - val_loss: 0.6942 - val_binary_accuracy: 0.5711\n",
            "Epoch 112/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6628 - binary_accuracy: 0.5933 - val_loss: 0.7051 - val_binary_accuracy: 0.5642\n",
            "Epoch 113/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6621 - binary_accuracy: 0.5908 - val_loss: 0.7077 - val_binary_accuracy: 0.5493\n",
            "Epoch 114/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6630 - binary_accuracy: 0.5962 - val_loss: 0.7121 - val_binary_accuracy: 0.5585\n",
            "Epoch 115/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6626 - binary_accuracy: 0.5916 - val_loss: 0.6929 - val_binary_accuracy: 0.5619\n",
            "Epoch 116/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6614 - binary_accuracy: 0.5994 - val_loss: 0.7104 - val_binary_accuracy: 0.5688\n",
            "Epoch 117/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6605 - binary_accuracy: 0.5965 - val_loss: 0.7057 - val_binary_accuracy: 0.5665\n",
            "Epoch 118/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6622 - binary_accuracy: 0.5979 - val_loss: 0.6895 - val_binary_accuracy: 0.5562\n",
            "Epoch 119/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6610 - binary_accuracy: 0.5954 - val_loss: 0.7051 - val_binary_accuracy: 0.5562\n",
            "Epoch 120/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6635 - binary_accuracy: 0.5997 - val_loss: 0.7057 - val_binary_accuracy: 0.5711\n",
            "Epoch 121/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6626 - binary_accuracy: 0.5968 - val_loss: 0.7042 - val_binary_accuracy: 0.5608\n",
            "Epoch 122/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6615 - binary_accuracy: 0.5931 - val_loss: 0.6955 - val_binary_accuracy: 0.5596\n",
            "Epoch 123/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6620 - binary_accuracy: 0.5931 - val_loss: 0.6961 - val_binary_accuracy: 0.5722\n",
            "Epoch 124/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6624 - binary_accuracy: 0.5911 - val_loss: 0.6959 - val_binary_accuracy: 0.5722\n",
            "Epoch 125/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6621 - binary_accuracy: 0.5991 - val_loss: 0.6998 - val_binary_accuracy: 0.5562\n",
            "Epoch 126/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6614 - binary_accuracy: 0.5945 - val_loss: 0.7083 - val_binary_accuracy: 0.5619\n",
            "Epoch 127/200\n",
            "698/698 [==============================] - 2s 3ms/step - loss: 0.6609 - binary_accuracy: 0.5942 - val_loss: 0.6905 - val_binary_accuracy: 0.5734\n",
            "Epoch 128/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6610 - binary_accuracy: 0.5913 - val_loss: 0.6945 - val_binary_accuracy: 0.5596\n",
            "Epoch 129/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6612 - binary_accuracy: 0.5919 - val_loss: 0.6917 - val_binary_accuracy: 0.5585\n",
            "Epoch 130/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6614 - binary_accuracy: 0.5991 - val_loss: 0.6997 - val_binary_accuracy: 0.5688\n",
            "Epoch 131/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6632 - binary_accuracy: 0.5919 - val_loss: 0.6934 - val_binary_accuracy: 0.5596\n",
            "Epoch 132/200\n",
            "698/698 [==============================] - 2s 3ms/step - loss: 0.6621 - binary_accuracy: 0.5893 - val_loss: 0.7081 - val_binary_accuracy: 0.5665\n",
            "Epoch 133/200\n",
            "698/698 [==============================] - 2s 3ms/step - loss: 0.6627 - binary_accuracy: 0.5939 - val_loss: 0.6913 - val_binary_accuracy: 0.5550\n",
            "Epoch 134/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6630 - binary_accuracy: 0.5939 - val_loss: 0.7207 - val_binary_accuracy: 0.5654\n",
            "Epoch 135/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6630 - binary_accuracy: 0.5948 - val_loss: 0.6965 - val_binary_accuracy: 0.5596\n",
            "Epoch 136/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6617 - binary_accuracy: 0.5945 - val_loss: 0.6940 - val_binary_accuracy: 0.5562\n",
            "Epoch 137/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6614 - binary_accuracy: 0.5962 - val_loss: 0.7185 - val_binary_accuracy: 0.5711\n",
            "Epoch 138/200\n",
            "698/698 [==============================] - 2s 3ms/step - loss: 0.6624 - binary_accuracy: 0.5936 - val_loss: 0.6992 - val_binary_accuracy: 0.5562\n",
            "Epoch 139/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6604 - binary_accuracy: 0.5919 - val_loss: 0.7055 - val_binary_accuracy: 0.5711\n",
            "Epoch 140/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6618 - binary_accuracy: 0.5922 - val_loss: 0.6950 - val_binary_accuracy: 0.5665\n",
            "Epoch 141/200\n",
            "698/698 [==============================] - 1s 2ms/step - loss: 0.6610 - binary_accuracy: 0.5988 - val_loss: 0.6966 - val_binary_accuracy: 0.5573\n",
            "Epoch 142/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6616 - binary_accuracy: 0.5928 - val_loss: 0.6973 - val_binary_accuracy: 0.5734\n",
            "Epoch 143/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6624 - binary_accuracy: 0.5936 - val_loss: 0.6968 - val_binary_accuracy: 0.5654\n",
            "Epoch 144/200\n",
            "698/698 [==============================] - 2s 2ms/step - loss: 0.6628 - binary_accuracy: 0.5971 - val_loss: 0.6936 - val_binary_accuracy: 0.5596\n",
            "Epoch 145/200\n",
            "332/698 [=============>................] - ETA: 0s - loss: 0.6687 - binary_accuracy: 0.5855"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-00df25babafd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binary_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('정답률:',performance[1], 'loss:', performance[0])"
      ],
      "metadata": {
        "id": "tosg3nyVInnh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4b8676a-66a4-4f17-8480-d2b03f85ed4b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6853 - binary_accuracy: 0.5679\n",
            "정답률: 0.567889928817749 loss: 0.685263454914093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "plt.plot(hist.history['binary_accuracy'])\n",
        "plt.plot(hist.history['val_binary_accuracy'])\n",
        "plt.title('Accuracy')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rj2bOrNvDxff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "\n",
        "x = pd.read_csv(\"/content/drive/MyDrive/2022 인공지능 웹 개발 대회/Data/Data_Processing_xData.csv\")\n",
        "x = x.drop(['Unnamed: 0'], axis=1)\n",
        "y = pd.read_csv(\"/content/drive/MyDrive/2022 인공지능 웹 개발 대회/Data/Data_Processing_yData.csv\")\n",
        "y = y.drop(['Unnamed: 0'], axis=1)\n",
        "y = np.array(y)\n",
        "\n",
        "x = x.replace(np.nan,0)\n",
        "\n",
        "X = np.array(x.iloc[:,0:10]) - np.array(x.iloc[:,10:])\n",
        "for i in range(len(X)):\n",
        "  for j in range(len(X[0])):\n",
        "    if X[i][j] < 0 :\n",
        "      X[i][j] = 0 \n",
        "    elif X[i][j] > 0:\n",
        "      X[i][j] = 1\n",
        "    else:\n",
        "      X[i][j] = 0.5\n",
        "\n",
        "n_fold = 5\n",
        "skf = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state =seed)\n",
        "accuracy = []\n",
        "\n",
        "for train, test in skf.split(X, y):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, activation = 'relu'))\n",
        "  model.add(Dense(12, activation = 'relu'))\n",
        "  model.add(Dense(8, activation = 'relu'))\n",
        "  model.add(Dense(1, activation = 'sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001), metrics = ['binary_accuracy'])\n",
        "\n",
        "\n",
        "  hist = model.fit(X[train], y[train], epochs = 100, batch_size=5)\n",
        "  k_accuracy = \"%.4f\" %(model.evaluate(X[train], y[train])[1])\n",
        "  accuracy.append(k_accuracy)\n",
        "\n",
        "print(\"\\n %.f fold accuracy : \"%(n_fold), accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcDG8SVBMVIS",
        "outputId": "df15777b-56a6-4c14-f582-099fb1faf2db"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 4359 samples\n",
            "Epoch 1/100\n",
            "4359/4359 [==============================] - 3s 679us/sample - loss: 0.7034 - binary_accuracy: 0.5042\n",
            "Epoch 2/100\n",
            "4359/4359 [==============================] - 1s 323us/sample - loss: 0.6983 - binary_accuracy: 0.5102\n",
            "Epoch 3/100\n",
            "4359/4359 [==============================] - 1s 305us/sample - loss: 0.6953 - binary_accuracy: 0.5118\n",
            "Epoch 4/100\n",
            "4359/4359 [==============================] - 1s 307us/sample - loss: 0.6930 - binary_accuracy: 0.5198\n",
            "Epoch 5/100\n",
            "4359/4359 [==============================] - 1s 324us/sample - loss: 0.6909 - binary_accuracy: 0.5276\n",
            "Epoch 6/100\n",
            "4359/4359 [==============================] - 1s 321us/sample - loss: 0.6891 - binary_accuracy: 0.5331\n",
            "Epoch 7/100\n",
            "4359/4359 [==============================] - 1s 304us/sample - loss: 0.6874 - binary_accuracy: 0.5435\n",
            "Epoch 8/100\n",
            "4359/4359 [==============================] - 1s 306us/sample - loss: 0.6859 - binary_accuracy: 0.5490\n",
            "Epoch 9/100\n",
            "4359/4359 [==============================] - 1s 319us/sample - loss: 0.6846 - binary_accuracy: 0.5504\n",
            "Epoch 10/100\n",
            "4359/4359 [==============================] - 1s 323us/sample - loss: 0.6832 - binary_accuracy: 0.5572\n",
            "Epoch 11/100\n",
            "4359/4359 [==============================] - 1s 321us/sample - loss: 0.6819 - binary_accuracy: 0.5618\n",
            "Epoch 12/100\n",
            "4359/4359 [==============================] - 2s 360us/sample - loss: 0.6806 - binary_accuracy: 0.5671\n",
            "Epoch 13/100\n",
            "4359/4359 [==============================] - 1s 310us/sample - loss: 0.6792 - binary_accuracy: 0.5682\n",
            "Epoch 14/100\n",
            "4359/4359 [==============================] - 1s 327us/sample - loss: 0.6780 - binary_accuracy: 0.5728\n",
            "Epoch 15/100\n",
            "4359/4359 [==============================] - 1s 319us/sample - loss: 0.6767 - binary_accuracy: 0.5811\n",
            "Epoch 16/100\n",
            "4359/4359 [==============================] - 1s 327us/sample - loss: 0.6756 - binary_accuracy: 0.5827\n",
            "Epoch 17/100\n",
            "4359/4359 [==============================] - 1s 316us/sample - loss: 0.6746 - binary_accuracy: 0.5813\n",
            "Epoch 18/100\n",
            "4359/4359 [==============================] - 1s 303us/sample - loss: 0.6736 - binary_accuracy: 0.5880\n",
            "Epoch 19/100\n",
            "4359/4359 [==============================] - 1s 310us/sample - loss: 0.6727 - binary_accuracy: 0.5880\n",
            "Epoch 20/100\n",
            "4359/4359 [==============================] - 1s 311us/sample - loss: 0.6719 - binary_accuracy: 0.5900\n",
            "Epoch 21/100\n",
            "4359/4359 [==============================] - 1s 289us/sample - loss: 0.6712 - binary_accuracy: 0.5928\n",
            "Epoch 22/100\n",
            "4359/4359 [==============================] - 1s 297us/sample - loss: 0.6705 - binary_accuracy: 0.5933\n",
            "Epoch 23/100\n",
            "4359/4359 [==============================] - 1s 320us/sample - loss: 0.6699 - binary_accuracy: 0.5928\n",
            "Epoch 24/100\n",
            "4359/4359 [==============================] - 1s 319us/sample - loss: 0.6694 - binary_accuracy: 0.5923\n",
            "Epoch 25/100\n",
            "4359/4359 [==============================] - 1s 317us/sample - loss: 0.6689 - binary_accuracy: 0.5933\n",
            "Epoch 26/100\n",
            "4359/4359 [==============================] - 1s 325us/sample - loss: 0.6685 - binary_accuracy: 0.5953\n",
            "Epoch 27/100\n",
            "4359/4359 [==============================] - 1s 296us/sample - loss: 0.6681 - binary_accuracy: 0.5955\n",
            "Epoch 28/100\n",
            "4359/4359 [==============================] - 1s 303us/sample - loss: 0.6677 - binary_accuracy: 0.5953\n",
            "Epoch 29/100\n",
            "4359/4359 [==============================] - 1s 285us/sample - loss: 0.6672 - binary_accuracy: 0.5944\n",
            "Epoch 30/100\n",
            "4359/4359 [==============================] - 1s 307us/sample - loss: 0.6670 - binary_accuracy: 0.5965\n",
            "Epoch 31/100\n",
            "4359/4359 [==============================] - 1s 296us/sample - loss: 0.6666 - binary_accuracy: 0.5933\n",
            "Epoch 32/100\n",
            "4359/4359 [==============================] - 1s 325us/sample - loss: 0.6664 - binary_accuracy: 0.5967\n",
            "Epoch 33/100\n",
            "4359/4359 [==============================] - 1s 314us/sample - loss: 0.6661 - binary_accuracy: 0.5939\n",
            "Epoch 34/100\n",
            "4359/4359 [==============================] - 1s 315us/sample - loss: 0.6659 - binary_accuracy: 0.5955\n",
            "Epoch 35/100\n",
            "4359/4359 [==============================] - 1s 303us/sample - loss: 0.6657 - binary_accuracy: 0.5944\n",
            "Epoch 36/100\n",
            "4359/4359 [==============================] - 1s 284us/sample - loss: 0.6654 - binary_accuracy: 0.5926\n",
            "Epoch 37/100\n",
            "4359/4359 [==============================] - 1s 296us/sample - loss: 0.6652 - binary_accuracy: 0.5958\n",
            "Epoch 38/100\n",
            "4359/4359 [==============================] - 1s 299us/sample - loss: 0.6650 - binary_accuracy: 0.5951\n",
            "Epoch 39/100\n",
            "4359/4359 [==============================] - 1s 306us/sample - loss: 0.6649 - binary_accuracy: 0.5946\n",
            "Epoch 40/100\n",
            "4359/4359 [==============================] - 1s 323us/sample - loss: 0.6647 - binary_accuracy: 0.5974\n",
            "Epoch 41/100\n",
            "4359/4359 [==============================] - 1s 301us/sample - loss: 0.6644 - binary_accuracy: 0.5960\n",
            "Epoch 42/100\n",
            "4359/4359 [==============================] - 1s 322us/sample - loss: 0.6643 - binary_accuracy: 0.5946\n",
            "Epoch 43/100\n",
            "4359/4359 [==============================] - 1s 303us/sample - loss: 0.6640 - binary_accuracy: 0.5988\n",
            "Epoch 44/100\n",
            "4359/4359 [==============================] - 1s 280us/sample - loss: 0.6641 - binary_accuracy: 0.5965\n",
            "Epoch 45/100\n",
            "4359/4359 [==============================] - 2s 378us/sample - loss: 0.6635 - binary_accuracy: 0.6013\n",
            "Epoch 46/100\n",
            "4359/4359 [==============================] - 2s 481us/sample - loss: 0.6637 - binary_accuracy: 0.5974\n",
            "Epoch 47/100\n",
            "4359/4359 [==============================] - 1s 314us/sample - loss: 0.6634 - binary_accuracy: 0.5976\n",
            "Epoch 48/100\n",
            "4359/4359 [==============================] - 1s 334us/sample - loss: 0.6632 - binary_accuracy: 0.5962\n",
            "Epoch 49/100\n",
            "4359/4359 [==============================] - 1s 323us/sample - loss: 0.6630 - binary_accuracy: 0.6013\n",
            "Epoch 50/100\n",
            "4359/4359 [==============================] - 1s 315us/sample - loss: 0.6628 - binary_accuracy: 0.5992\n",
            "Epoch 51/100\n",
            "4359/4359 [==============================] - 1s 326us/sample - loss: 0.6628 - binary_accuracy: 0.5981\n",
            "Epoch 52/100\n",
            "4359/4359 [==============================] - 1s 339us/sample - loss: 0.6626 - binary_accuracy: 0.5988\n",
            "Epoch 53/100\n",
            "4359/4359 [==============================] - 1s 318us/sample - loss: 0.6625 - binary_accuracy: 0.5997\n",
            "Epoch 54/100\n",
            "4359/4359 [==============================] - 1s 312us/sample - loss: 0.6623 - binary_accuracy: 0.5990\n",
            "Epoch 55/100\n",
            "4359/4359 [==============================] - 1s 320us/sample - loss: 0.6622 - binary_accuracy: 0.5988\n",
            "Epoch 56/100\n",
            "4359/4359 [==============================] - 1s 328us/sample - loss: 0.6620 - binary_accuracy: 0.5978\n",
            "Epoch 57/100\n",
            "4359/4359 [==============================] - 1s 310us/sample - loss: 0.6619 - binary_accuracy: 0.6004\n",
            "Epoch 58/100\n",
            "4359/4359 [==============================] - 1s 305us/sample - loss: 0.6617 - binary_accuracy: 0.5997\n",
            "Epoch 59/100\n",
            "4359/4359 [==============================] - 1s 289us/sample - loss: 0.6613 - binary_accuracy: 0.5990\n",
            "Epoch 60/100\n",
            "4359/4359 [==============================] - 1s 301us/sample - loss: 0.6615 - binary_accuracy: 0.6040\n",
            "Epoch 61/100\n",
            "4359/4359 [==============================] - 1s 310us/sample - loss: 0.6613 - binary_accuracy: 0.6033\n",
            "Epoch 62/100\n",
            "4359/4359 [==============================] - 1s 303us/sample - loss: 0.6612 - binary_accuracy: 0.6017\n",
            "Epoch 63/100\n",
            "4359/4359 [==============================] - 1s 302us/sample - loss: 0.6611 - binary_accuracy: 0.6050\n",
            "Epoch 64/100\n",
            "4359/4359 [==============================] - 1s 297us/sample - loss: 0.6610 - binary_accuracy: 0.6033\n",
            "Epoch 65/100\n",
            "4359/4359 [==============================] - 1s 314us/sample - loss: 0.6608 - binary_accuracy: 0.6024\n",
            "Epoch 66/100\n",
            "4359/4359 [==============================] - 1s 319us/sample - loss: 0.6607 - binary_accuracy: 0.6068\n",
            "Epoch 67/100\n",
            "4359/4359 [==============================] - 1s 330us/sample - loss: 0.6606 - binary_accuracy: 0.6056\n",
            "Epoch 68/100\n",
            "4359/4359 [==============================] - 1s 301us/sample - loss: 0.6604 - binary_accuracy: 0.6011\n",
            "Epoch 69/100\n",
            "4359/4359 [==============================] - 1s 310us/sample - loss: 0.6604 - binary_accuracy: 0.6072\n",
            "Epoch 70/100\n",
            "4359/4359 [==============================] - 1s 310us/sample - loss: 0.6603 - binary_accuracy: 0.6006\n",
            "Epoch 71/100\n",
            "4359/4359 [==============================] - 1s 295us/sample - loss: 0.6603 - binary_accuracy: 0.6054\n",
            "Epoch 72/100\n",
            "4359/4359 [==============================] - 1s 286us/sample - loss: 0.6601 - binary_accuracy: 0.6089\n",
            "Epoch 73/100\n",
            "4359/4359 [==============================] - 1s 311us/sample - loss: 0.6600 - binary_accuracy: 0.6077\n",
            "Epoch 74/100\n",
            "4359/4359 [==============================] - 1s 322us/sample - loss: 0.6598 - binary_accuracy: 0.6043\n",
            "Epoch 75/100\n",
            "4359/4359 [==============================] - 1s 330us/sample - loss: 0.6598 - binary_accuracy: 0.6089\n",
            "Epoch 76/100\n",
            "4359/4359 [==============================] - 1s 325us/sample - loss: 0.6598 - binary_accuracy: 0.6072\n",
            "Epoch 77/100\n",
            "4359/4359 [==============================] - 1s 324us/sample - loss: 0.6596 - binary_accuracy: 0.6061\n",
            "Epoch 78/100\n",
            "4359/4359 [==============================] - 1s 326us/sample - loss: 0.6596 - binary_accuracy: 0.6070\n",
            "Epoch 79/100\n",
            "4359/4359 [==============================] - 1s 308us/sample - loss: 0.6594 - binary_accuracy: 0.6056\n",
            "Epoch 80/100\n",
            "4359/4359 [==============================] - 1s 299us/sample - loss: 0.6594 - binary_accuracy: 0.6091\n",
            "Epoch 81/100\n",
            "4359/4359 [==============================] - 1s 294us/sample - loss: 0.6592 - binary_accuracy: 0.6098\n",
            "Epoch 82/100\n",
            "4359/4359 [==============================] - 1s 311us/sample - loss: 0.6593 - binary_accuracy: 0.6072\n",
            "Epoch 83/100\n",
            "4359/4359 [==============================] - 1s 338us/sample - loss: 0.6591 - binary_accuracy: 0.6086\n",
            "Epoch 84/100\n",
            "4359/4359 [==============================] - 1s 321us/sample - loss: 0.6590 - binary_accuracy: 0.6095\n",
            "Epoch 85/100\n",
            "4359/4359 [==============================] - 1s 291us/sample - loss: 0.6590 - binary_accuracy: 0.6095\n",
            "Epoch 86/100\n",
            "4359/4359 [==============================] - 1s 317us/sample - loss: 0.6588 - binary_accuracy: 0.6077\n",
            "Epoch 87/100\n",
            "4359/4359 [==============================] - 2s 514us/sample - loss: 0.6588 - binary_accuracy: 0.6020\n",
            "Epoch 88/100\n",
            "4359/4359 [==============================] - 2s 540us/sample - loss: 0.6588 - binary_accuracy: 0.6100\n",
            "Epoch 89/100\n",
            "4359/4359 [==============================] - 1s 306us/sample - loss: 0.6586 - binary_accuracy: 0.6109\n",
            "Epoch 90/100\n",
            "4359/4359 [==============================] - 1s 341us/sample - loss: 0.6586 - binary_accuracy: 0.6075\n",
            "Epoch 91/100\n",
            "4359/4359 [==============================] - 1s 317us/sample - loss: 0.6585 - binary_accuracy: 0.6082\n",
            "Epoch 92/100\n",
            "4359/4359 [==============================] - 1s 330us/sample - loss: 0.6584 - binary_accuracy: 0.6098\n",
            "Epoch 93/100\n",
            "4359/4359 [==============================] - 1s 310us/sample - loss: 0.6582 - binary_accuracy: 0.6093\n",
            "Epoch 94/100\n",
            "4359/4359 [==============================] - 1s 309us/sample - loss: 0.6582 - binary_accuracy: 0.6056\n",
            "Epoch 95/100\n",
            "4359/4359 [==============================] - 1s 318us/sample - loss: 0.6582 - binary_accuracy: 0.6100\n",
            "Epoch 96/100\n",
            "4359/4359 [==============================] - 1s 316us/sample - loss: 0.6582 - binary_accuracy: 0.6075\n",
            "Epoch 97/100\n",
            "4359/4359 [==============================] - 1s 311us/sample - loss: 0.6581 - binary_accuracy: 0.6070\n",
            "Epoch 98/100\n",
            "4359/4359 [==============================] - 1s 314us/sample - loss: 0.6578 - binary_accuracy: 0.6109\n",
            "Epoch 99/100\n",
            "4359/4359 [==============================] - 1s 320us/sample - loss: 0.6578 - binary_accuracy: 0.6082\n",
            "Epoch 100/100\n",
            "4359/4359 [==============================] - 1s 303us/sample - loss: 0.6577 - binary_accuracy: 0.6102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 4359 samples\n",
            "Epoch 1/100\n",
            "4359/4359 [==============================] - 2s 370us/sample - loss: 0.6941 - binary_accuracy: 0.4983\n",
            "Epoch 2/100\n",
            "4359/4359 [==============================] - 2s 387us/sample - loss: 0.6920 - binary_accuracy: 0.5210\n",
            "Epoch 3/100\n",
            "4359/4359 [==============================] - 2s 363us/sample - loss: 0.6903 - binary_accuracy: 0.5380\n",
            "Epoch 4/100\n",
            "4359/4359 [==============================] - 2s 348us/sample - loss: 0.6889 - binary_accuracy: 0.5499\n",
            "Epoch 5/100\n",
            "4359/4359 [==============================] - 1s 327us/sample - loss: 0.6874 - binary_accuracy: 0.5582\n",
            "Epoch 6/100\n",
            "4359/4359 [==============================] - 1s 294us/sample - loss: 0.6861 - binary_accuracy: 0.5680\n",
            "Epoch 7/100\n",
            "4359/4359 [==============================] - 1s 327us/sample - loss: 0.6849 - binary_accuracy: 0.5669\n",
            "Epoch 8/100\n",
            "4359/4359 [==============================] - 2s 350us/sample - loss: 0.6836 - binary_accuracy: 0.5724\n",
            "Epoch 9/100\n",
            "4359/4359 [==============================] - 2s 395us/sample - loss: 0.6824 - binary_accuracy: 0.5712\n",
            "Epoch 10/100\n",
            "4359/4359 [==============================] - 2s 366us/sample - loss: 0.6810 - binary_accuracy: 0.5749\n",
            "Epoch 11/100\n",
            "4359/4359 [==============================] - 1s 340us/sample - loss: 0.6799 - binary_accuracy: 0.5756\n",
            "Epoch 12/100\n",
            "4359/4359 [==============================] - 1s 300us/sample - loss: 0.6787 - binary_accuracy: 0.5822\n",
            "Epoch 13/100\n",
            "4359/4359 [==============================] - 1s 298us/sample - loss: 0.6776 - binary_accuracy: 0.5845\n",
            "Epoch 14/100\n",
            "4359/4359 [==============================] - 1s 306us/sample - loss: 0.6766 - binary_accuracy: 0.5866\n",
            "Epoch 15/100\n",
            "4359/4359 [==============================] - 1s 308us/sample - loss: 0.6757 - binary_accuracy: 0.5935\n",
            "Epoch 16/100\n",
            "4359/4359 [==============================] - 1s 322us/sample - loss: 0.6749 - binary_accuracy: 0.5935\n",
            "Epoch 17/100\n",
            "4359/4359 [==============================] - 1s 315us/sample - loss: 0.6740 - binary_accuracy: 0.5962\n",
            "Epoch 18/100\n",
            "4359/4359 [==============================] - 1s 332us/sample - loss: 0.6732 - binary_accuracy: 0.5942\n",
            "Epoch 19/100\n",
            "4359/4359 [==============================] - 1s 324us/sample - loss: 0.6726 - binary_accuracy: 0.5939\n",
            "Epoch 20/100\n",
            "4359/4359 [==============================] - 1s 301us/sample - loss: 0.6718 - binary_accuracy: 0.5933\n",
            "Epoch 21/100\n",
            "4359/4359 [==============================] - 1s 333us/sample - loss: 0.6712 - binary_accuracy: 0.5937\n",
            "Epoch 22/100\n",
            "4359/4359 [==============================] - 1s 322us/sample - loss: 0.6706 - binary_accuracy: 0.5942\n",
            "Epoch 23/100\n",
            "4359/4359 [==============================] - 1s 316us/sample - loss: 0.6701 - binary_accuracy: 0.5953\n",
            "Epoch 24/100\n",
            "4359/4359 [==============================] - 1s 311us/sample - loss: 0.6697 - binary_accuracy: 0.5962\n",
            "Epoch 25/100\n",
            "4359/4359 [==============================] - 1s 326us/sample - loss: 0.6693 - binary_accuracy: 0.5997\n",
            "Epoch 26/100\n",
            "4359/4359 [==============================] - 1s 307us/sample - loss: 0.6690 - binary_accuracy: 0.5983\n",
            "Epoch 27/100\n",
            "4359/4359 [==============================] - 1s 298us/sample - loss: 0.6687 - binary_accuracy: 0.5985\n",
            "Epoch 28/100\n",
            "4359/4359 [==============================] - 1s 305us/sample - loss: 0.6684 - binary_accuracy: 0.5962\n",
            "Epoch 29/100\n",
            "4359/4359 [==============================] - 1s 297us/sample - loss: 0.6682 - binary_accuracy: 0.5981\n",
            "Epoch 30/100\n",
            "4359/4359 [==============================] - 1s 315us/sample - loss: 0.6680 - binary_accuracy: 0.5999\n",
            "Epoch 31/100\n",
            "4359/4359 [==============================] - 1s 329us/sample - loss: 0.6677 - binary_accuracy: 0.5997\n",
            "Epoch 32/100\n",
            "4359/4359 [==============================] - 1s 336us/sample - loss: 0.6673 - binary_accuracy: 0.5972\n",
            "Epoch 33/100\n",
            "4359/4359 [==============================] - 1s 317us/sample - loss: 0.6674 - binary_accuracy: 0.5997\n",
            "Epoch 34/100\n",
            "4359/4359 [==============================] - 1s 319us/sample - loss: 0.6670 - binary_accuracy: 0.5972\n",
            "Epoch 35/100\n",
            "4359/4359 [==============================] - 1s 317us/sample - loss: 0.6667 - binary_accuracy: 0.5988\n",
            "Epoch 36/100\n",
            "4359/4359 [==============================] - 2s 349us/sample - loss: 0.6669 - binary_accuracy: 0.5969\n",
            "Epoch 37/100\n",
            "4359/4359 [==============================] - 1s 331us/sample - loss: 0.6666 - binary_accuracy: 0.5969\n",
            "Epoch 38/100\n",
            "4359/4359 [==============================] - 2s 360us/sample - loss: 0.6664 - binary_accuracy: 0.5955\n",
            "Epoch 39/100\n",
            "4359/4359 [==============================] - 2s 351us/sample - loss: 0.6664 - binary_accuracy: 0.5981\n",
            "Epoch 40/100\n",
            "4359/4359 [==============================] - 2s 349us/sample - loss: 0.6662 - binary_accuracy: 0.5983\n",
            "Epoch 41/100\n",
            "4359/4359 [==============================] - 1s 314us/sample - loss: 0.6661 - binary_accuracy: 0.5969\n",
            "Epoch 42/100\n",
            "4359/4359 [==============================] - 1s 311us/sample - loss: 0.6660 - binary_accuracy: 0.5983\n",
            "Epoch 43/100\n",
            "4359/4359 [==============================] - 1s 316us/sample - loss: 0.6659 - binary_accuracy: 0.5983\n",
            "Epoch 44/100\n",
            "4359/4359 [==============================] - 1s 326us/sample - loss: 0.6657 - binary_accuracy: 0.5955\n",
            "Epoch 45/100\n",
            "4359/4359 [==============================] - 2s 352us/sample - loss: 0.6656 - binary_accuracy: 0.5983\n",
            "Epoch 46/100\n",
            "4359/4359 [==============================] - 2s 350us/sample - loss: 0.6654 - binary_accuracy: 0.5988\n",
            "Epoch 47/100\n",
            "4359/4359 [==============================] - 1s 320us/sample - loss: 0.6654 - binary_accuracy: 0.5962\n",
            "Epoch 48/100\n",
            "4359/4359 [==============================] - 1s 298us/sample - loss: 0.6652 - binary_accuracy: 0.6008\n",
            "Epoch 49/100\n",
            "4359/4359 [==============================] - 1s 323us/sample - loss: 0.6652 - binary_accuracy: 0.6001\n",
            "Epoch 50/100\n",
            "4359/4359 [==============================] - 2s 347us/sample - loss: 0.6650 - binary_accuracy: 0.6004\n",
            "Epoch 51/100\n",
            "4359/4359 [==============================] - 1s 335us/sample - loss: 0.6650 - binary_accuracy: 0.5994\n",
            "Epoch 52/100\n",
            "4359/4359 [==============================] - 2s 350us/sample - loss: 0.6649 - binary_accuracy: 0.6015\n",
            "Epoch 53/100\n",
            "4359/4359 [==============================] - 1s 336us/sample - loss: 0.6648 - binary_accuracy: 0.6017\n",
            "Epoch 54/100\n",
            "4359/4359 [==============================] - 1s 338us/sample - loss: 0.6647 - binary_accuracy: 0.5997\n",
            "Epoch 55/100\n",
            "4359/4359 [==============================] - 1s 332us/sample - loss: 0.6646 - binary_accuracy: 0.6008\n",
            "Epoch 56/100\n",
            "4359/4359 [==============================] - 1s 338us/sample - loss: 0.6643 - binary_accuracy: 0.6043\n",
            "Epoch 57/100\n",
            "4359/4359 [==============================] - 2s 359us/sample - loss: 0.6643 - binary_accuracy: 0.6004\n",
            "Epoch 58/100\n",
            "4359/4359 [==============================] - 2s 345us/sample - loss: 0.6643 - binary_accuracy: 0.6017\n",
            "Epoch 59/100\n",
            "4359/4359 [==============================] - 1s 336us/sample - loss: 0.6643 - binary_accuracy: 0.6029\n",
            "Epoch 60/100\n",
            "4359/4359 [==============================] - 2s 381us/sample - loss: 0.6641 - binary_accuracy: 0.6022\n",
            "Epoch 61/100\n",
            "4359/4359 [==============================] - 1s 319us/sample - loss: 0.6641 - binary_accuracy: 0.6008\n",
            "Epoch 62/100\n",
            "4359/4359 [==============================] - 1s 333us/sample - loss: 0.6641 - binary_accuracy: 0.6017\n",
            "Epoch 63/100\n",
            "4359/4359 [==============================] - 2s 350us/sample - loss: 0.6639 - binary_accuracy: 0.6040\n",
            "Epoch 64/100\n",
            "4359/4359 [==============================] - 1s 339us/sample - loss: 0.6639 - binary_accuracy: 0.6031\n",
            "Epoch 65/100\n",
            "4359/4359 [==============================] - 1s 337us/sample - loss: 0.6638 - binary_accuracy: 0.6022\n",
            "Epoch 66/100\n",
            "4359/4359 [==============================] - 1s 332us/sample - loss: 0.6638 - binary_accuracy: 0.6036\n",
            "Epoch 67/100\n",
            "4359/4359 [==============================] - 1s 339us/sample - loss: 0.6636 - binary_accuracy: 0.6008\n",
            "Epoch 68/100\n",
            "4359/4359 [==============================] - 1s 301us/sample - loss: 0.6636 - binary_accuracy: 0.6015\n",
            "Epoch 69/100\n",
            "4359/4359 [==============================] - 1s 309us/sample - loss: 0.6635 - binary_accuracy: 0.6033\n",
            "Epoch 70/100\n",
            "4359/4359 [==============================] - 1s 321us/sample - loss: 0.6634 - binary_accuracy: 0.6050\n",
            "Epoch 71/100\n",
            "4359/4359 [==============================] - 1s 323us/sample - loss: 0.6634 - binary_accuracy: 0.6017\n",
            "Epoch 72/100\n",
            "4359/4359 [==============================] - 1s 321us/sample - loss: 0.6632 - binary_accuracy: 0.6020\n",
            "Epoch 73/100\n",
            "4359/4359 [==============================] - 1s 324us/sample - loss: 0.6632 - binary_accuracy: 0.6024\n",
            "Epoch 74/100\n",
            "4359/4359 [==============================] - 1s 321us/sample - loss: 0.6631 - binary_accuracy: 0.6036\n",
            "Epoch 75/100\n",
            "4359/4359 [==============================] - 1s 311us/sample - loss: 0.6632 - binary_accuracy: 0.6033\n",
            "Epoch 76/100\n",
            "4359/4359 [==============================] - 1s 327us/sample - loss: 0.6629 - binary_accuracy: 0.6020\n",
            "Epoch 77/100\n",
            "4359/4359 [==============================] - 1s 323us/sample - loss: 0.6628 - binary_accuracy: 0.6020\n",
            "Epoch 78/100\n",
            "4359/4359 [==============================] - 2s 348us/sample - loss: 0.6629 - binary_accuracy: 0.6031\n",
            "Epoch 79/100\n",
            "4359/4359 [==============================] - 1s 325us/sample - loss: 0.6628 - binary_accuracy: 0.6017\n",
            "Epoch 80/100\n",
            "4359/4359 [==============================] - 2s 367us/sample - loss: 0.6627 - binary_accuracy: 0.6050\n",
            "Epoch 81/100\n",
            "4359/4359 [==============================] - 1s 319us/sample - loss: 0.6626 - binary_accuracy: 0.6033\n",
            "Epoch 82/100\n",
            "4359/4359 [==============================] - 1s 313us/sample - loss: 0.6626 - binary_accuracy: 0.6027\n",
            "Epoch 83/100\n",
            "4359/4359 [==============================] - 1s 316us/sample - loss: 0.6626 - binary_accuracy: 0.6001\n",
            "Epoch 84/100\n",
            "4359/4359 [==============================] - 1s 332us/sample - loss: 0.6624 - binary_accuracy: 0.6022\n",
            "Epoch 85/100\n",
            "4359/4359 [==============================] - 1s 337us/sample - loss: 0.6623 - binary_accuracy: 0.6043\n",
            "Epoch 86/100\n",
            "4359/4359 [==============================] - 2s 360us/sample - loss: 0.6622 - binary_accuracy: 0.6008\n",
            "Epoch 87/100\n",
            "4359/4359 [==============================] - 1s 324us/sample - loss: 0.6622 - binary_accuracy: 0.6008\n",
            "Epoch 88/100\n",
            "4359/4359 [==============================] - 1s 339us/sample - loss: 0.6620 - binary_accuracy: 0.6022\n",
            "Epoch 89/100\n",
            "4359/4359 [==============================] - 1s 318us/sample - loss: 0.6619 - binary_accuracy: 0.6040\n",
            "Epoch 90/100\n",
            "4359/4359 [==============================] - 1s 299us/sample - loss: 0.6620 - binary_accuracy: 0.6033\n",
            "Epoch 91/100\n",
            "4359/4359 [==============================] - 1s 334us/sample - loss: 0.6619 - binary_accuracy: 0.6013\n",
            "Epoch 92/100\n",
            "4359/4359 [==============================] - 2s 382us/sample - loss: 0.6618 - binary_accuracy: 0.6020\n",
            "Epoch 93/100\n",
            "4359/4359 [==============================] - 2s 347us/sample - loss: 0.6617 - binary_accuracy: 0.6029\n",
            "Epoch 94/100\n",
            "4359/4359 [==============================] - 1s 333us/sample - loss: 0.6617 - binary_accuracy: 0.6011\n",
            "Epoch 95/100\n",
            "4359/4359 [==============================] - 1s 314us/sample - loss: 0.6615 - binary_accuracy: 0.6013\n",
            "Epoch 96/100\n",
            "4359/4359 [==============================] - 1s 323us/sample - loss: 0.6615 - binary_accuracy: 0.6008\n",
            "Epoch 97/100\n",
            "4359/4359 [==============================] - 1s 315us/sample - loss: 0.6613 - binary_accuracy: 0.6038\n",
            "Epoch 98/100\n",
            "4359/4359 [==============================] - 1s 324us/sample - loss: 0.6614 - binary_accuracy: 0.6027\n",
            "Epoch 99/100\n",
            "4359/4359 [==============================] - 1s 332us/sample - loss: 0.6612 - binary_accuracy: 0.6015\n",
            "Epoch 100/100\n",
            "4359/4359 [==============================] - 1s 326us/sample - loss: 0.6611 - binary_accuracy: 0.6036\n",
            "Train on 4359 samples\n",
            "Epoch 1/100\n",
            "4359/4359 [==============================] - 2s 352us/sample - loss: 0.6968 - binary_accuracy: 0.4797\n",
            "Epoch 2/100\n",
            "4359/4359 [==============================] - 1s 295us/sample - loss: 0.6923 - binary_accuracy: 0.5260\n",
            "Epoch 3/100\n",
            "4359/4359 [==============================] - 1s 342us/sample - loss: 0.6899 - binary_accuracy: 0.5448\n",
            "Epoch 4/100\n",
            "4359/4359 [==============================] - 1s 319us/sample - loss: 0.6883 - binary_accuracy: 0.5487\n",
            "Epoch 5/100\n",
            "4359/4359 [==============================] - 1s 334us/sample - loss: 0.6871 - binary_accuracy: 0.5545\n",
            "Epoch 6/100\n",
            "4359/4359 [==============================] - 1s 335us/sample - loss: 0.6859 - binary_accuracy: 0.5577\n",
            "Epoch 7/100\n",
            "4359/4359 [==============================] - 2s 371us/sample - loss: 0.6847 - binary_accuracy: 0.5655\n",
            "Epoch 8/100\n",
            "4359/4359 [==============================] - 1s 332us/sample - loss: 0.6836 - binary_accuracy: 0.5728\n",
            "Epoch 9/100\n",
            "4359/4359 [==============================] - 1s 320us/sample - loss: 0.6824 - binary_accuracy: 0.5751\n",
            "Epoch 10/100\n",
            "4359/4359 [==============================] - 1s 335us/sample - loss: 0.6813 - binary_accuracy: 0.5726\n",
            "Epoch 11/100\n",
            "4359/4359 [==============================] - 1s 322us/sample - loss: 0.6802 - binary_accuracy: 0.5749\n",
            "Epoch 12/100\n",
            "4359/4359 [==============================] - 1s 321us/sample - loss: 0.6791 - binary_accuracy: 0.5733\n",
            "Epoch 13/100\n",
            "4359/4359 [==============================] - 1s 319us/sample - loss: 0.6782 - binary_accuracy: 0.5770\n",
            "Epoch 14/100\n",
            "4359/4359 [==============================] - 1s 340us/sample - loss: 0.6773 - binary_accuracy: 0.5758\n",
            "Epoch 15/100\n",
            "4359/4359 [==============================] - 1s 322us/sample - loss: 0.6765 - binary_accuracy: 0.5783\n",
            "Epoch 16/100\n",
            "4359/4359 [==============================] - 1s 339us/sample - loss: 0.6758 - binary_accuracy: 0.5786\n",
            "Epoch 17/100\n",
            "4359/4359 [==============================] - 1s 324us/sample - loss: 0.6751 - binary_accuracy: 0.5795\n",
            "Epoch 18/100\n",
            "4359/4359 [==============================] - 2s 349us/sample - loss: 0.6744 - binary_accuracy: 0.5811\n",
            "Epoch 19/100\n",
            "4359/4359 [==============================] - 1s 322us/sample - loss: 0.6740 - binary_accuracy: 0.5841\n",
            "Epoch 20/100\n",
            "4359/4359 [==============================] - 1s 332us/sample - loss: 0.6733 - binary_accuracy: 0.5832\n",
            "Epoch 21/100\n",
            "4359/4359 [==============================] - 2s 359us/sample - loss: 0.6729 - binary_accuracy: 0.5820\n",
            "Epoch 22/100\n",
            "4359/4359 [==============================] - 1s 320us/sample - loss: 0.6723 - binary_accuracy: 0.5861\n",
            "Epoch 23/100\n",
            "4359/4359 [==============================] - 2s 346us/sample - loss: 0.6718 - binary_accuracy: 0.5843\n",
            "Epoch 24/100\n",
            "4359/4359 [==============================] - 2s 345us/sample - loss: 0.6714 - binary_accuracy: 0.5884\n",
            "Epoch 25/100\n",
            "4359/4359 [==============================] - 1s 336us/sample - loss: 0.6710 - binary_accuracy: 0.5859\n",
            "Epoch 26/100\n",
            "4359/4359 [==============================] - 2s 357us/sample - loss: 0.6708 - binary_accuracy: 0.5884\n",
            "Epoch 27/100\n",
            "4359/4359 [==============================] - 2s 397us/sample - loss: 0.6703 - binary_accuracy: 0.5905\n",
            "Epoch 28/100\n",
            "4359/4359 [==============================] - 2s 357us/sample - loss: 0.6701 - binary_accuracy: 0.5912\n",
            "Epoch 29/100\n",
            "4359/4359 [==============================] - 1s 334us/sample - loss: 0.6698 - binary_accuracy: 0.5905\n",
            "Epoch 30/100\n",
            "4359/4359 [==============================] - 1s 324us/sample - loss: 0.6694 - binary_accuracy: 0.5891\n",
            "Epoch 31/100\n",
            "4359/4359 [==============================] - 2s 354us/sample - loss: 0.6692 - binary_accuracy: 0.5923\n",
            "Epoch 32/100\n",
            "4359/4359 [==============================] - 2s 383us/sample - loss: 0.6691 - binary_accuracy: 0.5912\n",
            "Epoch 33/100\n",
            "4359/4359 [==============================] - 2s 373us/sample - loss: 0.6689 - binary_accuracy: 0.5914\n",
            "Epoch 34/100\n",
            "4359/4359 [==============================] - 2s 346us/sample - loss: 0.6686 - binary_accuracy: 0.5914\n",
            "Epoch 35/100\n",
            "4359/4359 [==============================] - 1s 330us/sample - loss: 0.6685 - binary_accuracy: 0.5926\n",
            "Epoch 36/100\n",
            "4359/4359 [==============================] - 1s 335us/sample - loss: 0.6683 - binary_accuracy: 0.5919\n",
            "Epoch 37/100\n",
            "4359/4359 [==============================] - 2s 358us/sample - loss: 0.6682 - binary_accuracy: 0.5912\n",
            "Epoch 38/100\n",
            "4359/4359 [==============================] - 1s 335us/sample - loss: 0.6680 - binary_accuracy: 0.5919\n",
            "Epoch 39/100\n",
            "4359/4359 [==============================] - 1s 317us/sample - loss: 0.6678 - binary_accuracy: 0.5905\n",
            "Epoch 40/100\n",
            "4359/4359 [==============================] - 1s 320us/sample - loss: 0.6677 - binary_accuracy: 0.5905\n",
            "Epoch 41/100\n",
            "4359/4359 [==============================] - 1s 321us/sample - loss: 0.6676 - binary_accuracy: 0.5937\n",
            "Epoch 42/100\n",
            "4359/4359 [==============================] - 1s 316us/sample - loss: 0.6675 - binary_accuracy: 0.5923\n",
            "Epoch 43/100\n",
            "4359/4359 [==============================] - 1s 321us/sample - loss: 0.6673 - binary_accuracy: 0.5905\n",
            "Epoch 44/100\n",
            "4359/4359 [==============================] - 2s 348us/sample - loss: 0.6672 - binary_accuracy: 0.5898\n",
            "Epoch 45/100\n",
            "4359/4359 [==============================] - 1s 331us/sample - loss: 0.6670 - binary_accuracy: 0.5926\n",
            "Epoch 46/100\n",
            "4359/4359 [==============================] - 1s 336us/sample - loss: 0.6670 - binary_accuracy: 0.5926\n",
            "Epoch 47/100\n",
            "4359/4359 [==============================] - 1s 339us/sample - loss: 0.6668 - binary_accuracy: 0.5942\n",
            "Epoch 48/100\n",
            "4359/4359 [==============================] - 1s 328us/sample - loss: 0.6669 - binary_accuracy: 0.5916\n",
            "Epoch 49/100\n",
            "4359/4359 [==============================] - 1s 309us/sample - loss: 0.6668 - binary_accuracy: 0.5923\n",
            "Epoch 50/100\n",
            "4359/4359 [==============================] - 1s 326us/sample - loss: 0.6666 - binary_accuracy: 0.5905\n",
            "Epoch 51/100\n",
            "4359/4359 [==============================] - 1s 336us/sample - loss: 0.6665 - binary_accuracy: 0.5921\n",
            "Epoch 52/100\n",
            "4359/4359 [==============================] - 1s 320us/sample - loss: 0.6665 - binary_accuracy: 0.5921\n",
            "Epoch 53/100\n",
            "4359/4359 [==============================] - 1s 310us/sample - loss: 0.6663 - binary_accuracy: 0.5914\n",
            "Epoch 54/100\n",
            "4359/4359 [==============================] - 1s 321us/sample - loss: 0.6663 - binary_accuracy: 0.5937\n",
            "Epoch 55/100\n",
            "4359/4359 [==============================] - 1s 323us/sample - loss: 0.6661 - binary_accuracy: 0.5930\n",
            "Epoch 56/100\n",
            "4359/4359 [==============================] - 1s 326us/sample - loss: 0.6660 - binary_accuracy: 0.5912\n",
            "Epoch 57/100\n",
            "4359/4359 [==============================] - 1s 318us/sample - loss: 0.6659 - binary_accuracy: 0.5944\n",
            "Epoch 58/100\n",
            "4359/4359 [==============================] - 1s 323us/sample - loss: 0.6658 - binary_accuracy: 0.5933\n",
            "Epoch 59/100\n",
            "4359/4359 [==============================] - 1s 340us/sample - loss: 0.6658 - binary_accuracy: 0.5935\n",
            "Epoch 60/100\n",
            "4359/4359 [==============================] - 1s 326us/sample - loss: 0.6657 - binary_accuracy: 0.5923\n",
            "Epoch 61/100\n",
            "4359/4359 [==============================] - 1s 324us/sample - loss: 0.6656 - binary_accuracy: 0.5939\n",
            "Epoch 62/100\n",
            "4359/4359 [==============================] - 1s 339us/sample - loss: 0.6655 - binary_accuracy: 0.5949\n",
            "Epoch 63/100\n",
            "4359/4359 [==============================] - 1s 323us/sample - loss: 0.6655 - binary_accuracy: 0.5930\n",
            "Epoch 64/100\n",
            "4359/4359 [==============================] - 2s 347us/sample - loss: 0.6653 - binary_accuracy: 0.5930\n",
            "Epoch 65/100\n",
            "4359/4359 [==============================] - 1s 338us/sample - loss: 0.6652 - binary_accuracy: 0.5955\n",
            "Epoch 66/100\n",
            "4359/4359 [==============================] - 2s 348us/sample - loss: 0.6651 - binary_accuracy: 0.5955\n",
            "Epoch 67/100\n",
            "4359/4359 [==============================] - 2s 357us/sample - loss: 0.6651 - binary_accuracy: 0.5937\n",
            "Epoch 68/100\n",
            "4359/4359 [==============================] - 1s 328us/sample - loss: 0.6649 - binary_accuracy: 0.5921\n",
            "Epoch 69/100\n",
            "4359/4359 [==============================] - 1s 334us/sample - loss: 0.6650 - binary_accuracy: 0.5921\n",
            "Epoch 70/100\n",
            "4359/4359 [==============================] - 1s 343us/sample - loss: 0.6649 - binary_accuracy: 0.5942\n",
            "Epoch 71/100\n",
            "4359/4359 [==============================] - 1s 325us/sample - loss: 0.6648 - binary_accuracy: 0.5946\n",
            "Epoch 72/100\n",
            "4359/4359 [==============================] - 2s 359us/sample - loss: 0.6648 - binary_accuracy: 0.5933\n",
            "Epoch 73/100\n",
            "4359/4359 [==============================] - 2s 360us/sample - loss: 0.6646 - binary_accuracy: 0.5953\n",
            "Epoch 74/100\n",
            "4359/4359 [==============================] - 2s 346us/sample - loss: 0.6645 - binary_accuracy: 0.5958\n",
            "Epoch 75/100\n",
            "4359/4359 [==============================] - 2s 345us/sample - loss: 0.6644 - binary_accuracy: 0.5937\n",
            "Epoch 76/100\n",
            "4359/4359 [==============================] - 2s 345us/sample - loss: 0.6643 - binary_accuracy: 0.5955\n",
            "Epoch 77/100\n",
            "4359/4359 [==============================] - 1s 333us/sample - loss: 0.6642 - binary_accuracy: 0.5949\n",
            "Epoch 78/100\n",
            "4359/4359 [==============================] - 1s 325us/sample - loss: 0.6641 - binary_accuracy: 0.5955\n",
            "Epoch 79/100\n",
            "4359/4359 [==============================] - 1s 344us/sample - loss: 0.6640 - binary_accuracy: 0.5951\n",
            "Epoch 80/100\n",
            "4359/4359 [==============================] - 1s 312us/sample - loss: 0.6640 - binary_accuracy: 0.5967\n",
            "Epoch 81/100\n",
            "4359/4359 [==============================] - 1s 317us/sample - loss: 0.6640 - binary_accuracy: 0.5942\n",
            "Epoch 82/100\n",
            "4359/4359 [==============================] - 1s 325us/sample - loss: 0.6638 - binary_accuracy: 0.5969\n",
            "Epoch 83/100\n",
            "4359/4359 [==============================] - 1s 312us/sample - loss: 0.6638 - binary_accuracy: 0.5958\n",
            "Epoch 84/100\n",
            "4359/4359 [==============================] - 1s 303us/sample - loss: 0.6637 - binary_accuracy: 0.5976\n",
            "Epoch 85/100\n",
            "4359/4359 [==============================] - 1s 327us/sample - loss: 0.6635 - binary_accuracy: 0.5974\n",
            "Epoch 86/100\n",
            "4359/4359 [==============================] - 1s 332us/sample - loss: 0.6635 - binary_accuracy: 0.5946\n",
            "Epoch 87/100\n",
            "4359/4359 [==============================] - 1s 332us/sample - loss: 0.6635 - binary_accuracy: 0.5974\n",
            "Epoch 88/100\n",
            "4359/4359 [==============================] - 1s 313us/sample - loss: 0.6634 - binary_accuracy: 0.5958\n",
            "Epoch 89/100\n",
            "4359/4359 [==============================] - 1s 325us/sample - loss: 0.6633 - binary_accuracy: 0.5962\n",
            "Epoch 90/100\n",
            "4359/4359 [==============================] - 1s 312us/sample - loss: 0.6631 - binary_accuracy: 0.5955\n",
            "Epoch 91/100\n",
            "4359/4359 [==============================] - 1s 290us/sample - loss: 0.6631 - binary_accuracy: 0.5937\n",
            "Epoch 92/100\n",
            "4359/4359 [==============================] - 1s 327us/sample - loss: 0.6630 - binary_accuracy: 0.5953\n",
            "Epoch 93/100\n",
            "4359/4359 [==============================] - 1s 325us/sample - loss: 0.6629 - binary_accuracy: 0.5958\n",
            "Epoch 94/100\n",
            "4359/4359 [==============================] - 1s 305us/sample - loss: 0.6629 - binary_accuracy: 0.5953\n",
            "Epoch 95/100\n",
            "4359/4359 [==============================] - 1s 320us/sample - loss: 0.6628 - binary_accuracy: 0.5969\n",
            "Epoch 96/100\n",
            "4359/4359 [==============================] - 1s 336us/sample - loss: 0.6628 - binary_accuracy: 0.5972\n",
            "Epoch 97/100\n",
            "4359/4359 [==============================] - 1s 326us/sample - loss: 0.6624 - binary_accuracy: 0.5958\n",
            "Epoch 98/100\n",
            "4359/4359 [==============================] - 1s 309us/sample - loss: 0.6627 - binary_accuracy: 0.5946\n",
            "Epoch 99/100\n",
            "4359/4359 [==============================] - 1s 319us/sample - loss: 0.6625 - binary_accuracy: 0.5955\n",
            "Epoch 100/100\n",
            "4359/4359 [==============================] - 1s 341us/sample - loss: 0.6623 - binary_accuracy: 0.5935\n",
            "Train on 4359 samples\n",
            "Epoch 1/100\n",
            "4359/4359 [==============================] - 2s 378us/sample - loss: 0.6939 - binary_accuracy: 0.5003\n",
            "Epoch 2/100\n",
            "4359/4359 [==============================] - 2s 351us/sample - loss: 0.6916 - binary_accuracy: 0.5178\n",
            "Epoch 3/100\n",
            "4359/4359 [==============================] - 1s 319us/sample - loss: 0.6900 - binary_accuracy: 0.5354\n",
            "Epoch 4/100\n",
            "4359/4359 [==============================] - 1s 325us/sample - loss: 0.6883 - binary_accuracy: 0.5428\n",
            "Epoch 5/100\n",
            "4359/4359 [==============================] - 2s 346us/sample - loss: 0.6869 - binary_accuracy: 0.5499\n",
            "Epoch 6/100\n",
            "4359/4359 [==============================] - 2s 373us/sample - loss: 0.6858 - binary_accuracy: 0.5586\n",
            "Epoch 7/100\n",
            "4359/4359 [==============================] - 2s 356us/sample - loss: 0.6847 - binary_accuracy: 0.5609\n",
            "Epoch 8/100\n",
            "4359/4359 [==============================] - 2s 351us/sample - loss: 0.6838 - binary_accuracy: 0.5607\n",
            "Epoch 9/100\n",
            "4359/4359 [==============================] - 2s 347us/sample - loss: 0.6828 - binary_accuracy: 0.5634\n",
            "Epoch 10/100\n",
            "4359/4359 [==============================] - 1s 334us/sample - loss: 0.6818 - binary_accuracy: 0.5685\n",
            "Epoch 11/100\n",
            "4359/4359 [==============================] - 1s 335us/sample - loss: 0.6809 - binary_accuracy: 0.5694\n",
            "Epoch 12/100\n",
            "4359/4359 [==============================] - 2s 363us/sample - loss: 0.6800 - binary_accuracy: 0.5708\n",
            "Epoch 13/100\n",
            "4359/4359 [==============================] - 2s 355us/sample - loss: 0.6791 - binary_accuracy: 0.5710\n",
            "Epoch 14/100\n",
            "4359/4359 [==============================] - 2s 364us/sample - loss: 0.6783 - binary_accuracy: 0.5724\n",
            "Epoch 15/100\n",
            "4359/4359 [==============================] - 2s 350us/sample - loss: 0.6776 - binary_accuracy: 0.5751\n",
            "Epoch 16/100\n",
            "4359/4359 [==============================] - 1s 340us/sample - loss: 0.6768 - binary_accuracy: 0.5756\n",
            "Epoch 17/100\n",
            "4359/4359 [==============================] - 1s 310us/sample - loss: 0.6761 - binary_accuracy: 0.5763\n",
            "Epoch 18/100\n",
            "4359/4359 [==============================] - 1s 335us/sample - loss: 0.6753 - binary_accuracy: 0.5754\n",
            "Epoch 19/100\n",
            "4359/4359 [==============================] - 2s 355us/sample - loss: 0.6746 - binary_accuracy: 0.5770\n",
            "Epoch 20/100\n",
            "4359/4359 [==============================] - 2s 373us/sample - loss: 0.6739 - binary_accuracy: 0.5767\n",
            "Epoch 21/100\n",
            "4359/4359 [==============================] - 1s 340us/sample - loss: 0.6733 - binary_accuracy: 0.5788\n",
            "Epoch 22/100\n",
            "4359/4359 [==============================] - 2s 355us/sample - loss: 0.6726 - binary_accuracy: 0.5790\n",
            "Epoch 23/100\n",
            "4359/4359 [==============================] - 2s 364us/sample - loss: 0.6719 - binary_accuracy: 0.5875\n",
            "Epoch 24/100\n",
            "4359/4359 [==============================] - 1s 324us/sample - loss: 0.6714 - binary_accuracy: 0.5843\n",
            "Epoch 25/100\n",
            "4359/4359 [==============================] - 2s 348us/sample - loss: 0.6709 - binary_accuracy: 0.5887\n",
            "Epoch 26/100\n",
            "4359/4359 [==============================] - 2s 382us/sample - loss: 0.6703 - binary_accuracy: 0.5836\n",
            "Epoch 27/100\n",
            "4359/4359 [==============================] - 2s 356us/sample - loss: 0.6700 - binary_accuracy: 0.5916\n",
            "Epoch 28/100\n",
            "4359/4359 [==============================] - 2s 358us/sample - loss: 0.6696 - binary_accuracy: 0.5896\n",
            "Epoch 29/100\n",
            "4359/4359 [==============================] - 2s 349us/sample - loss: 0.6692 - binary_accuracy: 0.5905\n",
            "Epoch 30/100\n",
            "4359/4359 [==============================] - 2s 373us/sample - loss: 0.6688 - binary_accuracy: 0.5914\n",
            "Epoch 31/100\n",
            "4359/4359 [==============================] - 2s 380us/sample - loss: 0.6685 - binary_accuracy: 0.5942\n",
            "Epoch 32/100\n",
            "4359/4359 [==============================] - 2s 381us/sample - loss: 0.6681 - binary_accuracy: 0.5894\n",
            "Epoch 33/100\n",
            "4359/4359 [==============================] - 2s 404us/sample - loss: 0.6678 - binary_accuracy: 0.5910\n",
            "Epoch 34/100\n",
            "4359/4359 [==============================] - 2s 353us/sample - loss: 0.6675 - binary_accuracy: 0.5914\n",
            "Epoch 35/100\n",
            "4359/4359 [==============================] - 2s 392us/sample - loss: 0.6672 - binary_accuracy: 0.5907\n",
            "Epoch 36/100\n",
            "4359/4359 [==============================] - 2s 356us/sample - loss: 0.6670 - binary_accuracy: 0.5926\n",
            "Epoch 37/100\n",
            "4359/4359 [==============================] - 2s 363us/sample - loss: 0.6667 - binary_accuracy: 0.5919\n",
            "Epoch 38/100\n",
            "4359/4359 [==============================] - 2s 408us/sample - loss: 0.6663 - binary_accuracy: 0.5928\n",
            "Epoch 39/100\n",
            "4359/4359 [==============================] - 2s 363us/sample - loss: 0.6662 - binary_accuracy: 0.5939\n",
            "Epoch 40/100\n",
            "4359/4359 [==============================] - 2s 360us/sample - loss: 0.6657 - binary_accuracy: 0.5951\n",
            "Epoch 41/100\n",
            "4359/4359 [==============================] - 1s 342us/sample - loss: 0.6656 - binary_accuracy: 0.5953\n",
            "Epoch 42/100\n",
            "4359/4359 [==============================] - 2s 352us/sample - loss: 0.6655 - binary_accuracy: 0.5960\n",
            "Epoch 43/100\n",
            "4359/4359 [==============================] - 2s 350us/sample - loss: 0.6653 - binary_accuracy: 0.5960\n",
            "Epoch 44/100\n",
            "4359/4359 [==============================] - 2s 359us/sample - loss: 0.6651 - binary_accuracy: 0.5946\n",
            "Epoch 45/100\n",
            "4359/4359 [==============================] - 2s 352us/sample - loss: 0.6649 - binary_accuracy: 0.5935\n",
            "Epoch 46/100\n",
            "4359/4359 [==============================] - 1s 339us/sample - loss: 0.6648 - binary_accuracy: 0.5923\n",
            "Epoch 47/100\n",
            "4359/4359 [==============================] - 2s 374us/sample - loss: 0.6647 - binary_accuracy: 0.5923\n",
            "Epoch 48/100\n",
            "4359/4359 [==============================] - 2s 361us/sample - loss: 0.6645 - binary_accuracy: 0.5965\n",
            "Epoch 49/100\n",
            "4359/4359 [==============================] - 2s 362us/sample - loss: 0.6643 - binary_accuracy: 0.5969\n",
            "Epoch 50/100\n",
            "4359/4359 [==============================] - 2s 360us/sample - loss: 0.6642 - binary_accuracy: 0.5942\n",
            "Epoch 51/100\n",
            "4359/4359 [==============================] - 2s 360us/sample - loss: 0.6640 - binary_accuracy: 0.5921\n",
            "Epoch 52/100\n",
            "4359/4359 [==============================] - 2s 381us/sample - loss: 0.6639 - binary_accuracy: 0.5962\n",
            "Epoch 53/100\n",
            "4359/4359 [==============================] - 2s 347us/sample - loss: 0.6638 - binary_accuracy: 0.5962\n",
            "Epoch 54/100\n",
            "4359/4359 [==============================] - 2s 358us/sample - loss: 0.6637 - binary_accuracy: 0.5958\n",
            "Epoch 55/100\n",
            "4359/4359 [==============================] - 2s 348us/sample - loss: 0.6635 - binary_accuracy: 0.5949\n",
            "Epoch 56/100\n",
            "4359/4359 [==============================] - 2s 370us/sample - loss: 0.6634 - binary_accuracy: 0.5974\n",
            "Epoch 57/100\n",
            "4359/4359 [==============================] - 2s 404us/sample - loss: 0.6633 - binary_accuracy: 0.5972\n",
            "Epoch 58/100\n",
            "4359/4359 [==============================] - 2s 383us/sample - loss: 0.6633 - binary_accuracy: 0.5960\n",
            "Epoch 59/100\n",
            "4359/4359 [==============================] - 2s 387us/sample - loss: 0.6630 - binary_accuracy: 0.5994\n",
            "Epoch 60/100\n",
            "4359/4359 [==============================] - 2s 374us/sample - loss: 0.6630 - binary_accuracy: 0.5939\n",
            "Epoch 61/100\n",
            "4359/4359 [==============================] - 2s 368us/sample - loss: 0.6628 - binary_accuracy: 0.5972\n",
            "Epoch 62/100\n",
            "4359/4359 [==============================] - 2s 354us/sample - loss: 0.6628 - binary_accuracy: 0.5992\n",
            "Epoch 63/100\n",
            "4359/4359 [==============================] - 2s 383us/sample - loss: 0.6626 - binary_accuracy: 0.5983\n",
            "Epoch 64/100\n",
            "4359/4359 [==============================] - 2s 375us/sample - loss: 0.6625 - binary_accuracy: 0.5960\n",
            "Epoch 65/100\n",
            "4359/4359 [==============================] - 2s 394us/sample - loss: 0.6624 - binary_accuracy: 0.5969\n",
            "Epoch 66/100\n",
            "4359/4359 [==============================] - 2s 351us/sample - loss: 0.6623 - binary_accuracy: 0.5965\n",
            "Epoch 67/100\n",
            "4359/4359 [==============================] - 1s 335us/sample - loss: 0.6621 - binary_accuracy: 0.5981\n",
            "Epoch 68/100\n",
            "4359/4359 [==============================] - 2s 363us/sample - loss: 0.6618 - binary_accuracy: 0.5969\n",
            "Epoch 69/100\n",
            "4359/4359 [==============================] - 2s 357us/sample - loss: 0.6619 - binary_accuracy: 0.6011\n",
            "Epoch 70/100\n",
            "4359/4359 [==============================] - 2s 346us/sample - loss: 0.6619 - binary_accuracy: 0.5958\n",
            "Epoch 71/100\n",
            "4359/4359 [==============================] - 1s 340us/sample - loss: 0.6617 - binary_accuracy: 0.5974\n",
            "Epoch 72/100\n",
            "4359/4359 [==============================] - 1s 334us/sample - loss: 0.6617 - binary_accuracy: 0.5988\n",
            "Epoch 73/100\n",
            "4359/4359 [==============================] - 1s 332us/sample - loss: 0.6615 - binary_accuracy: 0.5985\n",
            "Epoch 74/100\n",
            "4359/4359 [==============================] - 1s 326us/sample - loss: 0.6613 - binary_accuracy: 0.6001\n",
            "Epoch 75/100\n",
            "4359/4359 [==============================] - 1s 334us/sample - loss: 0.6613 - binary_accuracy: 0.5988\n",
            "Epoch 76/100\n",
            "4359/4359 [==============================] - 2s 372us/sample - loss: 0.6612 - binary_accuracy: 0.5960\n",
            "Epoch 77/100\n",
            "4359/4359 [==============================] - 1s 343us/sample - loss: 0.6612 - binary_accuracy: 0.6004\n",
            "Epoch 78/100\n",
            "4359/4359 [==============================] - 2s 383us/sample - loss: 0.6610 - binary_accuracy: 0.5999\n",
            "Epoch 79/100\n",
            "4359/4359 [==============================] - 2s 363us/sample - loss: 0.6611 - binary_accuracy: 0.5992\n",
            "Epoch 80/100\n",
            "4359/4359 [==============================] - 1s 337us/sample - loss: 0.6610 - binary_accuracy: 0.5997\n",
            "Epoch 81/100\n",
            "4359/4359 [==============================] - 2s 345us/sample - loss: 0.6608 - binary_accuracy: 0.5990\n",
            "Epoch 82/100\n",
            "4359/4359 [==============================] - 2s 388us/sample - loss: 0.6608 - binary_accuracy: 0.5994\n",
            "Epoch 83/100\n",
            "4359/4359 [==============================] - 2s 367us/sample - loss: 0.6607 - binary_accuracy: 0.5988\n",
            "Epoch 84/100\n",
            "4359/4359 [==============================] - 2s 371us/sample - loss: 0.6606 - binary_accuracy: 0.6004\n",
            "Epoch 85/100\n",
            "4359/4359 [==============================] - 2s 399us/sample - loss: 0.6605 - binary_accuracy: 0.6001\n",
            "Epoch 86/100\n",
            "4359/4359 [==============================] - 2s 381us/sample - loss: 0.6604 - binary_accuracy: 0.6015\n",
            "Epoch 87/100\n",
            "4359/4359 [==============================] - 2s 344us/sample - loss: 0.6605 - binary_accuracy: 0.5969\n",
            "Epoch 88/100\n",
            "4359/4359 [==============================] - 2s 379us/sample - loss: 0.6603 - binary_accuracy: 0.5985\n",
            "Epoch 89/100\n",
            "4359/4359 [==============================] - 2s 385us/sample - loss: 0.6601 - binary_accuracy: 0.6015\n",
            "Epoch 90/100\n",
            "4359/4359 [==============================] - 2s 381us/sample - loss: 0.6601 - binary_accuracy: 0.6017\n",
            "Epoch 91/100\n",
            "4359/4359 [==============================] - 2s 385us/sample - loss: 0.6600 - binary_accuracy: 0.6020\n",
            "Epoch 92/100\n",
            "4359/4359 [==============================] - 1s 335us/sample - loss: 0.6599 - binary_accuracy: 0.6004\n",
            "Epoch 93/100\n",
            "4359/4359 [==============================] - 2s 349us/sample - loss: 0.6599 - binary_accuracy: 0.6029\n",
            "Epoch 94/100\n",
            "4359/4359 [==============================] - 2s 368us/sample - loss: 0.6597 - binary_accuracy: 0.6033\n",
            "Epoch 95/100\n",
            "4359/4359 [==============================] - 2s 371us/sample - loss: 0.6596 - binary_accuracy: 0.6031\n",
            "Epoch 96/100\n",
            "4359/4359 [==============================] - 2s 346us/sample - loss: 0.6597 - binary_accuracy: 0.6001\n",
            "Epoch 97/100\n",
            "4359/4359 [==============================] - 2s 356us/sample - loss: 0.6595 - binary_accuracy: 0.6020\n",
            "Epoch 98/100\n",
            "4359/4359 [==============================] - 1s 334us/sample - loss: 0.6594 - binary_accuracy: 0.6020\n",
            "Epoch 99/100\n",
            "4359/4359 [==============================] - 1s 327us/sample - loss: 0.6594 - binary_accuracy: 0.6020\n",
            "Epoch 100/100\n",
            "4359/4359 [==============================] - 2s 345us/sample - loss: 0.6593 - binary_accuracy: 0.6027\n",
            "Train on 4360 samples\n",
            "Epoch 1/100\n",
            "4360/4360 [==============================] - 2s 375us/sample - loss: 0.6962 - binary_accuracy: 0.4725\n",
            "Epoch 2/100\n",
            "4360/4360 [==============================] - 1s 340us/sample - loss: 0.6920 - binary_accuracy: 0.5294\n",
            "Epoch 3/100\n",
            "4360/4360 [==============================] - 2s 360us/sample - loss: 0.6893 - binary_accuracy: 0.5433\n",
            "Epoch 4/100\n",
            "4360/4360 [==============================] - 1s 328us/sample - loss: 0.6876 - binary_accuracy: 0.5417\n",
            "Epoch 5/100\n",
            "4360/4360 [==============================] - 1s 333us/sample - loss: 0.6865 - binary_accuracy: 0.5378\n",
            "Epoch 6/100\n",
            "4360/4360 [==============================] - 1s 337us/sample - loss: 0.6854 - binary_accuracy: 0.5411\n",
            "Epoch 7/100\n",
            "4360/4360 [==============================] - 2s 358us/sample - loss: 0.6843 - binary_accuracy: 0.5459\n",
            "Epoch 8/100\n",
            "4360/4360 [==============================] - 2s 350us/sample - loss: 0.6832 - binary_accuracy: 0.5525\n",
            "Epoch 9/100\n",
            "4360/4360 [==============================] - 2s 355us/sample - loss: 0.6820 - binary_accuracy: 0.5628\n",
            "Epoch 10/100\n",
            "4360/4360 [==============================] - 1s 335us/sample - loss: 0.6808 - binary_accuracy: 0.5670\n",
            "Epoch 11/100\n",
            "4360/4360 [==============================] - 1s 325us/sample - loss: 0.6796 - binary_accuracy: 0.5798\n",
            "Epoch 12/100\n",
            "4360/4360 [==============================] - 1s 335us/sample - loss: 0.6784 - binary_accuracy: 0.5888\n",
            "Epoch 13/100\n",
            "4360/4360 [==============================] - 1s 330us/sample - loss: 0.6772 - binary_accuracy: 0.5865\n",
            "Epoch 14/100\n",
            "4360/4360 [==============================] - 1s 325us/sample - loss: 0.6762 - binary_accuracy: 0.5952\n",
            "Epoch 15/100\n",
            "4360/4360 [==============================] - 2s 344us/sample - loss: 0.6751 - binary_accuracy: 0.5959\n",
            "Epoch 16/100\n",
            "4360/4360 [==============================] - 1s 343us/sample - loss: 0.6742 - binary_accuracy: 0.5956\n",
            "Epoch 17/100\n",
            "4360/4360 [==============================] - 2s 344us/sample - loss: 0.6734 - binary_accuracy: 0.5970\n",
            "Epoch 18/100\n",
            "4360/4360 [==============================] - 1s 333us/sample - loss: 0.6725 - binary_accuracy: 0.5940\n",
            "Epoch 19/100\n",
            "4360/4360 [==============================] - 1s 325us/sample - loss: 0.6718 - binary_accuracy: 0.5945\n",
            "Epoch 20/100\n",
            "4360/4360 [==============================] - 2s 352us/sample - loss: 0.6711 - binary_accuracy: 0.5975\n",
            "Epoch 21/100\n",
            "4360/4360 [==============================] - 2s 356us/sample - loss: 0.6705 - binary_accuracy: 0.5947\n",
            "Epoch 22/100\n",
            "4360/4360 [==============================] - 2s 349us/sample - loss: 0.6700 - binary_accuracy: 0.5954\n",
            "Epoch 23/100\n",
            "4360/4360 [==============================] - 2s 354us/sample - loss: 0.6696 - binary_accuracy: 0.5952\n",
            "Epoch 24/100\n",
            "4360/4360 [==============================] - 2s 351us/sample - loss: 0.6691 - binary_accuracy: 0.5961\n",
            "Epoch 25/100\n",
            "4360/4360 [==============================] - 1s 343us/sample - loss: 0.6687 - binary_accuracy: 0.5963\n",
            "Epoch 26/100\n",
            "4360/4360 [==============================] - 2s 351us/sample - loss: 0.6682 - binary_accuracy: 0.5961\n",
            "Epoch 27/100\n",
            "4360/4360 [==============================] - 1s 340us/sample - loss: 0.6678 - binary_accuracy: 0.5972\n",
            "Epoch 28/100\n",
            "4360/4360 [==============================] - 2s 368us/sample - loss: 0.6675 - binary_accuracy: 0.5970\n",
            "Epoch 29/100\n",
            "4360/4360 [==============================] - 2s 361us/sample - loss: 0.6673 - binary_accuracy: 0.5989\n",
            "Epoch 30/100\n",
            "4360/4360 [==============================] - 2s 365us/sample - loss: 0.6670 - binary_accuracy: 0.5989\n",
            "Epoch 31/100\n",
            "4360/4360 [==============================] - 1s 327us/sample - loss: 0.6666 - binary_accuracy: 0.6000\n",
            "Epoch 32/100\n",
            "4360/4360 [==============================] - 2s 350us/sample - loss: 0.6665 - binary_accuracy: 0.5982\n",
            "Epoch 33/100\n",
            "4360/4360 [==============================] - 2s 351us/sample - loss: 0.6662 - binary_accuracy: 0.6030\n",
            "Epoch 34/100\n",
            "4360/4360 [==============================] - 2s 346us/sample - loss: 0.6660 - binary_accuracy: 0.6005\n",
            "Epoch 35/100\n",
            "4360/4360 [==============================] - 2s 348us/sample - loss: 0.6657 - binary_accuracy: 0.6028\n",
            "Epoch 36/100\n",
            "4360/4360 [==============================] - 2s 345us/sample - loss: 0.6655 - binary_accuracy: 0.6014\n",
            "Epoch 37/100\n",
            "4360/4360 [==============================] - 1s 319us/sample - loss: 0.6653 - binary_accuracy: 0.6030\n",
            "Epoch 38/100\n",
            "4360/4360 [==============================] - 2s 347us/sample - loss: 0.6652 - binary_accuracy: 0.6009\n",
            "Epoch 39/100\n",
            "4360/4360 [==============================] - 1s 343us/sample - loss: 0.6649 - binary_accuracy: 0.6028\n",
            "Epoch 40/100\n",
            "4360/4360 [==============================] - 2s 360us/sample - loss: 0.6647 - binary_accuracy: 0.6021\n",
            "Epoch 41/100\n",
            "4360/4360 [==============================] - 2s 346us/sample - loss: 0.6645 - binary_accuracy: 0.6046\n",
            "Epoch 42/100\n",
            "4360/4360 [==============================] - 2s 360us/sample - loss: 0.6644 - binary_accuracy: 0.6025\n",
            "Epoch 43/100\n",
            "4360/4360 [==============================] - 2s 361us/sample - loss: 0.6641 - binary_accuracy: 0.6025\n",
            "Epoch 44/100\n",
            "4360/4360 [==============================] - 2s 351us/sample - loss: 0.6640 - binary_accuracy: 0.6030\n",
            "Epoch 45/100\n",
            "4360/4360 [==============================] - 1s 326us/sample - loss: 0.6638 - binary_accuracy: 0.6067\n",
            "Epoch 46/100\n",
            "4360/4360 [==============================] - 2s 383us/sample - loss: 0.6637 - binary_accuracy: 0.6030\n",
            "Epoch 47/100\n",
            "4360/4360 [==============================] - 2s 356us/sample - loss: 0.6635 - binary_accuracy: 0.6028\n",
            "Epoch 48/100\n",
            "4360/4360 [==============================] - 2s 348us/sample - loss: 0.6633 - binary_accuracy: 0.6050\n",
            "Epoch 49/100\n",
            "4360/4360 [==============================] - 2s 349us/sample - loss: 0.6631 - binary_accuracy: 0.6067\n",
            "Epoch 50/100\n",
            "4360/4360 [==============================] - 2s 349us/sample - loss: 0.6631 - binary_accuracy: 0.6076\n",
            "Epoch 51/100\n",
            "4360/4360 [==============================] - 2s 360us/sample - loss: 0.6629 - binary_accuracy: 0.6067\n",
            "Epoch 52/100\n",
            "4360/4360 [==============================] - 2s 350us/sample - loss: 0.6627 - binary_accuracy: 0.6064\n",
            "Epoch 53/100\n",
            "4360/4360 [==============================] - 2s 384us/sample - loss: 0.6627 - binary_accuracy: 0.6069\n",
            "Epoch 54/100\n",
            "4360/4360 [==============================] - 2s 369us/sample - loss: 0.6625 - binary_accuracy: 0.6060\n",
            "Epoch 55/100\n",
            "4360/4360 [==============================] - 2s 380us/sample - loss: 0.6624 - binary_accuracy: 0.6053\n",
            "Epoch 56/100\n",
            "4360/4360 [==============================] - 2s 360us/sample - loss: 0.6622 - binary_accuracy: 0.6073\n",
            "Epoch 57/100\n",
            "4360/4360 [==============================] - 2s 366us/sample - loss: 0.6619 - binary_accuracy: 0.6064\n",
            "Epoch 58/100\n",
            "4360/4360 [==============================] - 2s 364us/sample - loss: 0.6621 - binary_accuracy: 0.6083\n",
            "Epoch 59/100\n",
            "4360/4360 [==============================] - 2s 383us/sample - loss: 0.6617 - binary_accuracy: 0.6087\n",
            "Epoch 60/100\n",
            "4360/4360 [==============================] - 2s 364us/sample - loss: 0.6618 - binary_accuracy: 0.6064\n",
            "Epoch 61/100\n",
            "4360/4360 [==============================] - 2s 359us/sample - loss: 0.6617 - binary_accuracy: 0.6080\n",
            "Epoch 62/100\n",
            "4360/4360 [==============================] - 2s 384us/sample - loss: 0.6615 - binary_accuracy: 0.6071\n",
            "Epoch 63/100\n",
            "4360/4360 [==============================] - 2s 361us/sample - loss: 0.6614 - binary_accuracy: 0.6078\n",
            "Epoch 64/100\n",
            "4360/4360 [==============================] - 2s 356us/sample - loss: 0.6613 - binary_accuracy: 0.6099\n",
            "Epoch 65/100\n",
            "4360/4360 [==============================] - 2s 349us/sample - loss: 0.6612 - binary_accuracy: 0.6089\n",
            "Epoch 66/100\n",
            "4360/4360 [==============================] - 2s 420us/sample - loss: 0.6611 - binary_accuracy: 0.6076\n",
            "Epoch 67/100\n",
            "4360/4360 [==============================] - 2s 405us/sample - loss: 0.6608 - binary_accuracy: 0.6083\n",
            "Epoch 68/100\n",
            "4360/4360 [==============================] - 2s 367us/sample - loss: 0.6609 - binary_accuracy: 0.6085\n",
            "Epoch 69/100\n",
            "4360/4360 [==============================] - 2s 388us/sample - loss: 0.6607 - binary_accuracy: 0.6101\n",
            "Epoch 70/100\n",
            "4360/4360 [==============================] - 2s 378us/sample - loss: 0.6606 - binary_accuracy: 0.6103\n",
            "Epoch 71/100\n",
            "4360/4360 [==============================] - 2s 380us/sample - loss: 0.6605 - binary_accuracy: 0.6089\n",
            "Epoch 72/100\n",
            "4360/4360 [==============================] - 2s 384us/sample - loss: 0.6604 - binary_accuracy: 0.6089\n",
            "Epoch 73/100\n",
            "4360/4360 [==============================] - 2s 352us/sample - loss: 0.6602 - binary_accuracy: 0.6071\n",
            "Epoch 74/100\n",
            "4360/4360 [==============================] - 2s 361us/sample - loss: 0.6602 - binary_accuracy: 0.6119\n",
            "Epoch 75/100\n",
            "4360/4360 [==============================] - 2s 356us/sample - loss: 0.6600 - binary_accuracy: 0.6106\n",
            "Epoch 76/100\n",
            "4360/4360 [==============================] - 1s 335us/sample - loss: 0.6601 - binary_accuracy: 0.6119\n",
            "Epoch 77/100\n",
            "4360/4360 [==============================] - 2s 351us/sample - loss: 0.6599 - binary_accuracy: 0.6128\n",
            "Epoch 78/100\n",
            "4360/4360 [==============================] - 2s 350us/sample - loss: 0.6598 - binary_accuracy: 0.6108\n",
            "Epoch 79/100\n",
            "4360/4360 [==============================] - 1s 341us/sample - loss: 0.6596 - binary_accuracy: 0.6126\n",
            "Epoch 80/100\n",
            "4360/4360 [==============================] - 2s 355us/sample - loss: 0.6597 - binary_accuracy: 0.6108\n",
            "Epoch 81/100\n",
            "4360/4360 [==============================] - 1s 329us/sample - loss: 0.6595 - binary_accuracy: 0.6112\n",
            "Epoch 82/100\n",
            "4360/4360 [==============================] - 1s 324us/sample - loss: 0.6595 - binary_accuracy: 0.6103\n",
            "Epoch 83/100\n",
            "4360/4360 [==============================] - 1s 339us/sample - loss: 0.6594 - binary_accuracy: 0.6103\n",
            "Epoch 84/100\n",
            "4360/4360 [==============================] - 2s 366us/sample - loss: 0.6592 - binary_accuracy: 0.6096\n",
            "Epoch 85/100\n",
            "4360/4360 [==============================] - 2s 365us/sample - loss: 0.6592 - binary_accuracy: 0.6124\n",
            "Epoch 86/100\n",
            "4360/4360 [==============================] - 2s 358us/sample - loss: 0.6592 - binary_accuracy: 0.6110\n",
            "Epoch 87/100\n",
            "4360/4360 [==============================] - 2s 360us/sample - loss: 0.6590 - binary_accuracy: 0.6131\n",
            "Epoch 88/100\n",
            "4360/4360 [==============================] - 2s 345us/sample - loss: 0.6589 - binary_accuracy: 0.6112\n",
            "Epoch 89/100\n",
            "4360/4360 [==============================] - 2s 348us/sample - loss: 0.6589 - binary_accuracy: 0.6110\n",
            "Epoch 90/100\n",
            "4360/4360 [==============================] - 2s 349us/sample - loss: 0.6587 - binary_accuracy: 0.6110\n",
            "Epoch 91/100\n",
            "4360/4360 [==============================] - 2s 369us/sample - loss: 0.6587 - binary_accuracy: 0.6103\n",
            "Epoch 92/100\n",
            "4360/4360 [==============================] - 2s 350us/sample - loss: 0.6585 - binary_accuracy: 0.6108\n",
            "Epoch 93/100\n",
            "4360/4360 [==============================] - 2s 375us/sample - loss: 0.6584 - binary_accuracy: 0.6119\n",
            "Epoch 94/100\n",
            "4360/4360 [==============================] - 2s 356us/sample - loss: 0.6584 - binary_accuracy: 0.6124\n",
            "Epoch 95/100\n",
            "4360/4360 [==============================] - 2s 347us/sample - loss: 0.6583 - binary_accuracy: 0.6110\n",
            "Epoch 96/100\n",
            "4360/4360 [==============================] - 2s 362us/sample - loss: 0.6582 - binary_accuracy: 0.6122\n",
            "Epoch 97/100\n",
            "4360/4360 [==============================] - 2s 371us/sample - loss: 0.6582 - binary_accuracy: 0.6094\n",
            "Epoch 98/100\n",
            "4360/4360 [==============================] - 2s 359us/sample - loss: 0.6580 - binary_accuracy: 0.6138\n",
            "Epoch 99/100\n",
            "4360/4360 [==============================] - 2s 379us/sample - loss: 0.6580 - binary_accuracy: 0.6119\n",
            "Epoch 100/100\n",
            "4360/4360 [==============================] - 2s 354us/sample - loss: 0.6578 - binary_accuracy: 0.6117\n",
            "\n",
            " 5 fold accuracy :  ['0.6066', '0.6040', '0.5983', '0.6043', '0.6131']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('정답률:',performance[1], 'loss:', performance[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVd-_SLKOgUp",
        "outputId": "af339332-57b9-493b-c1c6-0e578afec396"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정답률: 0.6238532 loss: 0.6527562088922623\n"
          ]
        }
      ]
    }
  ]
}