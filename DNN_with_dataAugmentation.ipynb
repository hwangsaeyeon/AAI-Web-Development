{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN with dataAugmentation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMVYO0wCPjBdq5Wt/cne0mQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwangsaeyeon/AAI-Web-Development/blob/main/DNN_with_dataAugmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrQ42kmUc5u_",
        "outputId": "b40c4ca3-a31e-48fe-bda9-cea1e0b818d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "x = pd.read_csv(\"/content/drive/MyDrive/2022 인공지능 웹 개발 대회/Data/Data_Processing_xData.csv\")\n",
        "x = x.drop(['Unnamed: 0'], axis=1)\n",
        "\n",
        "y = pd.read_csv(\"/content/drive/MyDrive/2022 인공지능 웹 개발 대회/Data/Data_Processing_yData.csv\")\n",
        "y = y.drop(['Unnamed: 0'], axis=1)"
      ],
      "metadata": {
        "id": "Xj_8RnM1dAJE"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPTo3jfLdBN1",
        "outputId": "6ef462a5-708c-4362-8e61-8c8811e39418"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5449 entries, 0 to 5448\n",
            "Data columns (total 20 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   A0      5440 non-null   float64\n",
            " 1   A1      5448 non-null   float64\n",
            " 2   A2      5449 non-null   float64\n",
            " 3   A3      5449 non-null   float64\n",
            " 4   A4      5420 non-null   float64\n",
            " 5   A5      5443 non-null   float64\n",
            " 6   A6      5448 non-null   float64\n",
            " 7   A7      5442 non-null   float64\n",
            " 8   A8      5444 non-null   float64\n",
            " 9   A9      5432 non-null   float64\n",
            " 10  H0      5445 non-null   float64\n",
            " 11  H1      5445 non-null   float64\n",
            " 12  H2      5449 non-null   float64\n",
            " 13  H3      5447 non-null   float64\n",
            " 14  H4      5430 non-null   float64\n",
            " 15  H5      5447 non-null   float64\n",
            " 16  H6      5446 non-null   float64\n",
            " 17  H7      5445 non-null   float64\n",
            " 18  H8      5443 non-null   float64\n",
            " 19  H9      5438 non-null   float64\n",
            "dtypes: float64(20)\n",
            "memory usage: 851.5 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.replace(np.nan, 0.01)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QOnKZ7XvdHOY",
        "outputId": "76b5fc51-52a0-4d78-9bfb-286fd9dfa3b8"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        A0    A1    A2    A3     A4    A5    A6    A7    A8    A9    H0    H1  \\\n",
              "0     2.37  4.41 -1.62  3.34   5.30  0.61  0.15 -1.28 -1.43  0.33  6.35  1.89   \n",
              "1     0.09  3.52  0.84  4.46  11.73  0.76  2.19  0.85  0.25  1.03  1.64  1.94   \n",
              "2     0.36  0.01  1.51  4.68   5.25  1.58 -0.53 -0.50  0.78 -0.21  3.28  4.73   \n",
              "3     1.58  0.99 -1.84  1.76   1.30  2.29 -0.46 -0.22  1.44  1.80  3.12  6.93   \n",
              "4     7.18  2.87  1.33  2.91  -0.56 -0.63 -0.78 -0.24 -0.29 -1.04  3.72  2.51   \n",
              "...    ...   ...   ...   ...    ...   ...   ...   ...   ...   ...   ...   ...   \n",
              "5444  1.75  1.56  0.70  0.62   2.08  2.86  0.49 -0.58 -0.20 -1.06  4.83  0.63   \n",
              "5445  3.56  1.95  2.26  2.61   2.06  1.59  1.38 -0.22  0.29  0.23  1.59  2.24   \n",
              "5446  1.28  2.62  3.45  3.09   3.52  1.22  0.10 -0.41  0.05 -0.27 -1.35  1.55   \n",
              "5447  3.81  3.04  0.57  2.63   1.75 -0.45  1.05 -0.30 -0.65 -0.69  2.00  1.13   \n",
              "5448  0.05  2.24 -0.56  2.02   0.63  0.19 -0.08  0.11  0.30 -0.22  1.20  1.01   \n",
              "\n",
              "        H2    H3    H4    H5    H6    H7    H8    H9  \n",
              "0     2.63  6.90  8.96  2.20  2.37 -0.47  4.09 -0.01  \n",
              "1     1.34  6.13 -0.41  0.01  1.85  5.51  0.00  2.93  \n",
              "2     3.35  3.34  5.05 -2.16  7.03 -1.02  2.88 -0.87  \n",
              "3     2.11  7.05  5.28  3.30  3.97  1.89  0.55  2.08  \n",
              "4    -2.04  2.50  0.58  0.31  3.68  1.27 -1.03 -0.39  \n",
              "...    ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "5444  2.26  4.61  0.78  1.02 -0.30 -0.08  0.57  1.39  \n",
              "5445  0.35  1.39  0.96 -0.37  0.57  0.09 -0.17 -0.04  \n",
              "5446  0.70  4.54  1.94  0.05 -0.07 -0.38 -0.14 -0.47  \n",
              "5447 -0.20  0.31  2.97  2.45  1.44  1.31  0.84  0.59  \n",
              "5448  0.35  0.06  3.94  0.47  1.31 -0.34  0.23 -0.05  \n",
              "\n",
              "[5449 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25882a98-c3ed-4287-ac59-9f587dfae527\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A0</th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "      <th>A9</th>\n",
              "      <th>H0</th>\n",
              "      <th>H1</th>\n",
              "      <th>H2</th>\n",
              "      <th>H3</th>\n",
              "      <th>H4</th>\n",
              "      <th>H5</th>\n",
              "      <th>H6</th>\n",
              "      <th>H7</th>\n",
              "      <th>H8</th>\n",
              "      <th>H9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.37</td>\n",
              "      <td>4.41</td>\n",
              "      <td>-1.62</td>\n",
              "      <td>3.34</td>\n",
              "      <td>5.30</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.15</td>\n",
              "      <td>-1.28</td>\n",
              "      <td>-1.43</td>\n",
              "      <td>0.33</td>\n",
              "      <td>6.35</td>\n",
              "      <td>1.89</td>\n",
              "      <td>2.63</td>\n",
              "      <td>6.90</td>\n",
              "      <td>8.96</td>\n",
              "      <td>2.20</td>\n",
              "      <td>2.37</td>\n",
              "      <td>-0.47</td>\n",
              "      <td>4.09</td>\n",
              "      <td>-0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.09</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.84</td>\n",
              "      <td>4.46</td>\n",
              "      <td>11.73</td>\n",
              "      <td>0.76</td>\n",
              "      <td>2.19</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.64</td>\n",
              "      <td>1.94</td>\n",
              "      <td>1.34</td>\n",
              "      <td>6.13</td>\n",
              "      <td>-0.41</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1.85</td>\n",
              "      <td>5.51</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.36</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1.51</td>\n",
              "      <td>4.68</td>\n",
              "      <td>5.25</td>\n",
              "      <td>1.58</td>\n",
              "      <td>-0.53</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>0.78</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>3.28</td>\n",
              "      <td>4.73</td>\n",
              "      <td>3.35</td>\n",
              "      <td>3.34</td>\n",
              "      <td>5.05</td>\n",
              "      <td>-2.16</td>\n",
              "      <td>7.03</td>\n",
              "      <td>-1.02</td>\n",
              "      <td>2.88</td>\n",
              "      <td>-0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.58</td>\n",
              "      <td>0.99</td>\n",
              "      <td>-1.84</td>\n",
              "      <td>1.76</td>\n",
              "      <td>1.30</td>\n",
              "      <td>2.29</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>1.44</td>\n",
              "      <td>1.80</td>\n",
              "      <td>3.12</td>\n",
              "      <td>6.93</td>\n",
              "      <td>2.11</td>\n",
              "      <td>7.05</td>\n",
              "      <td>5.28</td>\n",
              "      <td>3.30</td>\n",
              "      <td>3.97</td>\n",
              "      <td>1.89</td>\n",
              "      <td>0.55</td>\n",
              "      <td>2.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.18</td>\n",
              "      <td>2.87</td>\n",
              "      <td>1.33</td>\n",
              "      <td>2.91</td>\n",
              "      <td>-0.56</td>\n",
              "      <td>-0.63</td>\n",
              "      <td>-0.78</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>-0.29</td>\n",
              "      <td>-1.04</td>\n",
              "      <td>3.72</td>\n",
              "      <td>2.51</td>\n",
              "      <td>-2.04</td>\n",
              "      <td>2.50</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.31</td>\n",
              "      <td>3.68</td>\n",
              "      <td>1.27</td>\n",
              "      <td>-1.03</td>\n",
              "      <td>-0.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5444</th>\n",
              "      <td>1.75</td>\n",
              "      <td>1.56</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.62</td>\n",
              "      <td>2.08</td>\n",
              "      <td>2.86</td>\n",
              "      <td>0.49</td>\n",
              "      <td>-0.58</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>-1.06</td>\n",
              "      <td>4.83</td>\n",
              "      <td>0.63</td>\n",
              "      <td>2.26</td>\n",
              "      <td>4.61</td>\n",
              "      <td>0.78</td>\n",
              "      <td>1.02</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.57</td>\n",
              "      <td>1.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5445</th>\n",
              "      <td>3.56</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.26</td>\n",
              "      <td>2.61</td>\n",
              "      <td>2.06</td>\n",
              "      <td>1.59</td>\n",
              "      <td>1.38</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.59</td>\n",
              "      <td>2.24</td>\n",
              "      <td>0.35</td>\n",
              "      <td>1.39</td>\n",
              "      <td>0.96</td>\n",
              "      <td>-0.37</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-0.17</td>\n",
              "      <td>-0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5446</th>\n",
              "      <td>1.28</td>\n",
              "      <td>2.62</td>\n",
              "      <td>3.45</td>\n",
              "      <td>3.09</td>\n",
              "      <td>3.52</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0.10</td>\n",
              "      <td>-0.41</td>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.27</td>\n",
              "      <td>-1.35</td>\n",
              "      <td>1.55</td>\n",
              "      <td>0.70</td>\n",
              "      <td>4.54</td>\n",
              "      <td>1.94</td>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.38</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>-0.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5447</th>\n",
              "      <td>3.81</td>\n",
              "      <td>3.04</td>\n",
              "      <td>0.57</td>\n",
              "      <td>2.63</td>\n",
              "      <td>1.75</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>1.05</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>-0.65</td>\n",
              "      <td>-0.69</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1.13</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>0.31</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.45</td>\n",
              "      <td>1.44</td>\n",
              "      <td>1.31</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>0.05</td>\n",
              "      <td>2.24</td>\n",
              "      <td>-0.56</td>\n",
              "      <td>2.02</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.19</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.30</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>1.20</td>\n",
              "      <td>1.01</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.06</td>\n",
              "      <td>3.94</td>\n",
              "      <td>0.47</td>\n",
              "      <td>1.31</td>\n",
              "      <td>-0.34</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5449 rows × 20 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25882a98-c3ed-4287-ac59-9f587dfae527')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-25882a98-c3ed-4287-ac59-9f587dfae527 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-25882a98-c3ed-4287-ac59-9f587dfae527');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.hist(figsize=(20,20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TR2lW0v-dIpg",
        "outputId": "2a368f78-2e58-486f-f725-7507c11b8d95"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f6b20549610>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f6b20509810>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f6b204bbc90>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f6b2047c1d0>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f6b204326d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f6b1e587bd0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f6b1e54c190>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f6b1e5055d0>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f6b1e505610>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f6b1e538c10>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f6b1e4b3550>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f6b1e46aa50>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f6b1e421f50>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f6b1e3e4490>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f6b1e39b990>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f6b1e352e90>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f6b1e3153d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f6b1e2cb8d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f6b1e282dd0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f6b1e246310>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_away = np.array(x.iloc[:,0:10])\n",
        "x_home = np.array(x.iloc[:,10:])\n",
        "x_inv = np.concatenate((x_home,x_away),axis=1)\n",
        "X = np.concatenate((x,x_inv),axis=0)"
      ],
      "metadata": {
        "id": "yBUxF2K9dL39"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "X = MinMaxScaler().fit_transform(X.data)"
      ],
      "metadata": {
        "id": "I_pFb1_QkgVj"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.read_csv(\"/content/drive/MyDrive/2022 인공지능 웹 개발 대회/Data/Data_Processing_yData.csv\")\n",
        "y = y.drop(['Unnamed: 0'], axis=1)\n",
        "y = np.array(y)\n",
        "import numpy as np\n",
        "print(np.unique(y,return_counts=True))\n",
        "\n",
        "inverse_y = np.zeros(len(y))\n",
        "inverse_y = np.array(inverse_y).reshape(-1,1)\n",
        "\n",
        "for i in range(len(y)):\n",
        "  if int(y[i]) == 1:\n",
        "    inverse_y[i] = 0\n",
        "  elif int(y[i]) == 0: \n",
        "    inverse_y[i] = 1\n",
        "\n",
        "y = np.concatenate((y,inverse_y),axis=0)\n",
        "print(np.unique(inverse_y,return_counts=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgk8nIyEdKXf",
        "outputId": "0f05e5a2-310b-4683-bd95-4ca5ec87f106"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1]), array([2942, 2507]))\n",
            "(array([0., 1.]), array([2507, 2942]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tXaK20n5dVAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#train,val,test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "\n",
        "import tensorflow as tf\n",
        "input_shape = [X_train.shape[1]]\n",
        "model = tf.keras.models.Sequential([\n",
        "    #tf.keras.layers.Flatten(input_shape = input_shape),\n",
        "    #tf.keras.layers.BatchNormalization(),\n",
        "    #tf.keras.layers.Dense(64,activation='relu'),\n",
        "    tf.keras.layers.Dense(32,activation='relu'),\n",
        "    tf.keras.layers.Dense(16,activation='relu'),\n",
        "    tf.keras.layers.Dense(8,activation='relu'),\n",
        "    tf.keras.layers.Dense(4,activation='relu'),\n",
        "    #tf.keras.layers.Dense(10,activation='relu'),\n",
        "    #tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid'),])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(patience=10)\n",
        "hist = model.fit(X_train, y_train, epochs=1000, validation_data=(X_val,y_val), callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3KxqbbldS2n",
        "outputId": "8e3563b6-3b9d-408d-f692-7bb955d24d52"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6538, 20) (6538, 1)\n",
            "(2180, 20) (2180, 1)\n",
            "(2180, 20) (2180, 1)\n",
            "Epoch 1/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6996 - binary_accuracy: 0.4948 - val_loss: 0.6972 - val_binary_accuracy: 0.5050\n",
            "Epoch 2/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6983 - binary_accuracy: 0.4945 - val_loss: 0.6963 - val_binary_accuracy: 0.5060\n",
            "Epoch 3/1000\n",
            "205/205 [==============================] - 1s 2ms/step - loss: 0.6973 - binary_accuracy: 0.4939 - val_loss: 0.6955 - val_binary_accuracy: 0.5087\n",
            "Epoch 4/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6964 - binary_accuracy: 0.4928 - val_loss: 0.6949 - val_binary_accuracy: 0.5110\n",
            "Epoch 5/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6956 - binary_accuracy: 0.4939 - val_loss: 0.6943 - val_binary_accuracy: 0.5106\n",
            "Epoch 6/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6949 - binary_accuracy: 0.4960 - val_loss: 0.6938 - val_binary_accuracy: 0.5106\n",
            "Epoch 7/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6943 - binary_accuracy: 0.5003 - val_loss: 0.6933 - val_binary_accuracy: 0.5133\n",
            "Epoch 8/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6937 - binary_accuracy: 0.5037 - val_loss: 0.6928 - val_binary_accuracy: 0.5142\n",
            "Epoch 9/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6931 - binary_accuracy: 0.5049 - val_loss: 0.6923 - val_binary_accuracy: 0.5202\n",
            "Epoch 10/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6925 - binary_accuracy: 0.5127 - val_loss: 0.6918 - val_binary_accuracy: 0.5248\n",
            "Epoch 11/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6920 - binary_accuracy: 0.5153 - val_loss: 0.6912 - val_binary_accuracy: 0.5239\n",
            "Epoch 12/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6914 - binary_accuracy: 0.5202 - val_loss: 0.6907 - val_binary_accuracy: 0.5307\n",
            "Epoch 13/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6909 - binary_accuracy: 0.5258 - val_loss: 0.6902 - val_binary_accuracy: 0.5372\n",
            "Epoch 14/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6904 - binary_accuracy: 0.5344 - val_loss: 0.6897 - val_binary_accuracy: 0.5367\n",
            "Epoch 15/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6900 - binary_accuracy: 0.5393 - val_loss: 0.6893 - val_binary_accuracy: 0.5431\n",
            "Epoch 16/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6896 - binary_accuracy: 0.5457 - val_loss: 0.6888 - val_binary_accuracy: 0.5459\n",
            "Epoch 17/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6892 - binary_accuracy: 0.5529 - val_loss: 0.6884 - val_binary_accuracy: 0.5468\n",
            "Epoch 18/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6888 - binary_accuracy: 0.5586 - val_loss: 0.6880 - val_binary_accuracy: 0.5514\n",
            "Epoch 19/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6885 - binary_accuracy: 0.5612 - val_loss: 0.6876 - val_binary_accuracy: 0.5518\n",
            "Epoch 20/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6882 - binary_accuracy: 0.5597 - val_loss: 0.6873 - val_binary_accuracy: 0.5569\n",
            "Epoch 21/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6879 - binary_accuracy: 0.5629 - val_loss: 0.6870 - val_binary_accuracy: 0.5523\n",
            "Epoch 22/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6876 - binary_accuracy: 0.5652 - val_loss: 0.6867 - val_binary_accuracy: 0.5578\n",
            "Epoch 23/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6874 - binary_accuracy: 0.5671 - val_loss: 0.6864 - val_binary_accuracy: 0.5592\n",
            "Epoch 24/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6871 - binary_accuracy: 0.5670 - val_loss: 0.6861 - val_binary_accuracy: 0.5624\n",
            "Epoch 25/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6869 - binary_accuracy: 0.5658 - val_loss: 0.6858 - val_binary_accuracy: 0.5633\n",
            "Epoch 26/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6867 - binary_accuracy: 0.5664 - val_loss: 0.6856 - val_binary_accuracy: 0.5679\n",
            "Epoch 27/1000\n",
            "205/205 [==============================] - 1s 2ms/step - loss: 0.6864 - binary_accuracy: 0.5661 - val_loss: 0.6853 - val_binary_accuracy: 0.5720\n",
            "Epoch 28/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6862 - binary_accuracy: 0.5687 - val_loss: 0.6850 - val_binary_accuracy: 0.5716\n",
            "Epoch 29/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6860 - binary_accuracy: 0.5675 - val_loss: 0.6848 - val_binary_accuracy: 0.5706\n",
            "Epoch 30/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6858 - binary_accuracy: 0.5687 - val_loss: 0.6846 - val_binary_accuracy: 0.5706\n",
            "Epoch 31/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6856 - binary_accuracy: 0.5671 - val_loss: 0.6843 - val_binary_accuracy: 0.5697\n",
            "Epoch 32/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6853 - binary_accuracy: 0.5688 - val_loss: 0.6841 - val_binary_accuracy: 0.5693\n",
            "Epoch 33/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6851 - binary_accuracy: 0.5679 - val_loss: 0.6839 - val_binary_accuracy: 0.5706\n",
            "Epoch 34/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6849 - binary_accuracy: 0.5673 - val_loss: 0.6836 - val_binary_accuracy: 0.5725\n",
            "Epoch 35/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6846 - binary_accuracy: 0.5711 - val_loss: 0.6834 - val_binary_accuracy: 0.5748\n",
            "Epoch 36/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6844 - binary_accuracy: 0.5696 - val_loss: 0.6832 - val_binary_accuracy: 0.5743\n",
            "Epoch 37/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6842 - binary_accuracy: 0.5696 - val_loss: 0.6830 - val_binary_accuracy: 0.5761\n",
            "Epoch 38/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6840 - binary_accuracy: 0.5728 - val_loss: 0.6827 - val_binary_accuracy: 0.5752\n",
            "Epoch 39/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6838 - binary_accuracy: 0.5740 - val_loss: 0.6825 - val_binary_accuracy: 0.5752\n",
            "Epoch 40/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6836 - binary_accuracy: 0.5745 - val_loss: 0.6823 - val_binary_accuracy: 0.5771\n",
            "Epoch 41/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6833 - binary_accuracy: 0.5757 - val_loss: 0.6820 - val_binary_accuracy: 0.5771\n",
            "Epoch 42/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6831 - binary_accuracy: 0.5734 - val_loss: 0.6818 - val_binary_accuracy: 0.5775\n",
            "Epoch 43/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6829 - binary_accuracy: 0.5749 - val_loss: 0.6816 - val_binary_accuracy: 0.5780\n",
            "Epoch 44/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6827 - binary_accuracy: 0.5756 - val_loss: 0.6814 - val_binary_accuracy: 0.5771\n",
            "Epoch 45/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6825 - binary_accuracy: 0.5737 - val_loss: 0.6812 - val_binary_accuracy: 0.5775\n",
            "Epoch 46/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6823 - binary_accuracy: 0.5745 - val_loss: 0.6810 - val_binary_accuracy: 0.5807\n",
            "Epoch 47/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6821 - binary_accuracy: 0.5733 - val_loss: 0.6808 - val_binary_accuracy: 0.5798\n",
            "Epoch 48/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6819 - binary_accuracy: 0.5748 - val_loss: 0.6807 - val_binary_accuracy: 0.5812\n",
            "Epoch 49/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6817 - binary_accuracy: 0.5739 - val_loss: 0.6805 - val_binary_accuracy: 0.5789\n",
            "Epoch 50/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6816 - binary_accuracy: 0.5728 - val_loss: 0.6803 - val_binary_accuracy: 0.5780\n",
            "Epoch 51/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6814 - binary_accuracy: 0.5743 - val_loss: 0.6801 - val_binary_accuracy: 0.5798\n",
            "Epoch 52/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6812 - binary_accuracy: 0.5737 - val_loss: 0.6799 - val_binary_accuracy: 0.5789\n",
            "Epoch 53/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6810 - binary_accuracy: 0.5754 - val_loss: 0.6797 - val_binary_accuracy: 0.5798\n",
            "Epoch 54/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6808 - binary_accuracy: 0.5745 - val_loss: 0.6795 - val_binary_accuracy: 0.5780\n",
            "Epoch 55/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6806 - binary_accuracy: 0.5746 - val_loss: 0.6793 - val_binary_accuracy: 0.5784\n",
            "Epoch 56/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6804 - binary_accuracy: 0.5743 - val_loss: 0.6792 - val_binary_accuracy: 0.5775\n",
            "Epoch 57/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6802 - binary_accuracy: 0.5759 - val_loss: 0.6790 - val_binary_accuracy: 0.5784\n",
            "Epoch 58/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6801 - binary_accuracy: 0.5765 - val_loss: 0.6788 - val_binary_accuracy: 0.5761\n",
            "Epoch 59/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6799 - binary_accuracy: 0.5775 - val_loss: 0.6786 - val_binary_accuracy: 0.5784\n",
            "Epoch 60/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6797 - binary_accuracy: 0.5759 - val_loss: 0.6784 - val_binary_accuracy: 0.5803\n",
            "Epoch 61/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6795 - binary_accuracy: 0.5756 - val_loss: 0.6783 - val_binary_accuracy: 0.5794\n",
            "Epoch 62/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6794 - binary_accuracy: 0.5763 - val_loss: 0.6781 - val_binary_accuracy: 0.5789\n",
            "Epoch 63/1000\n",
            "205/205 [==============================] - 1s 2ms/step - loss: 0.6792 - binary_accuracy: 0.5766 - val_loss: 0.6779 - val_binary_accuracy: 0.5789\n",
            "Epoch 64/1000\n",
            "205/205 [==============================] - 1s 2ms/step - loss: 0.6790 - binary_accuracy: 0.5757 - val_loss: 0.6778 - val_binary_accuracy: 0.5794\n",
            "Epoch 65/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6789 - binary_accuracy: 0.5760 - val_loss: 0.6776 - val_binary_accuracy: 0.5794\n",
            "Epoch 66/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6787 - binary_accuracy: 0.5762 - val_loss: 0.6774 - val_binary_accuracy: 0.5789\n",
            "Epoch 67/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6785 - binary_accuracy: 0.5757 - val_loss: 0.6773 - val_binary_accuracy: 0.5798\n",
            "Epoch 68/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6784 - binary_accuracy: 0.5765 - val_loss: 0.6771 - val_binary_accuracy: 0.5817\n",
            "Epoch 69/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6782 - binary_accuracy: 0.5760 - val_loss: 0.6770 - val_binary_accuracy: 0.5817\n",
            "Epoch 70/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6781 - binary_accuracy: 0.5748 - val_loss: 0.6768 - val_binary_accuracy: 0.5821\n",
            "Epoch 71/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6779 - binary_accuracy: 0.5763 - val_loss: 0.6767 - val_binary_accuracy: 0.5817\n",
            "Epoch 72/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6777 - binary_accuracy: 0.5763 - val_loss: 0.6765 - val_binary_accuracy: 0.5817\n",
            "Epoch 73/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6776 - binary_accuracy: 0.5757 - val_loss: 0.6763 - val_binary_accuracy: 0.5807\n",
            "Epoch 74/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6774 - binary_accuracy: 0.5757 - val_loss: 0.6762 - val_binary_accuracy: 0.5807\n",
            "Epoch 75/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6773 - binary_accuracy: 0.5748 - val_loss: 0.6761 - val_binary_accuracy: 0.5803\n",
            "Epoch 76/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6771 - binary_accuracy: 0.5757 - val_loss: 0.6759 - val_binary_accuracy: 0.5817\n",
            "Epoch 77/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6770 - binary_accuracy: 0.5748 - val_loss: 0.6758 - val_binary_accuracy: 0.5821\n",
            "Epoch 78/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6768 - binary_accuracy: 0.5756 - val_loss: 0.6757 - val_binary_accuracy: 0.5830\n",
            "Epoch 79/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6767 - binary_accuracy: 0.5753 - val_loss: 0.6755 - val_binary_accuracy: 0.5821\n",
            "Epoch 80/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6766 - binary_accuracy: 0.5743 - val_loss: 0.6754 - val_binary_accuracy: 0.5812\n",
            "Epoch 81/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6764 - binary_accuracy: 0.5763 - val_loss: 0.6753 - val_binary_accuracy: 0.5812\n",
            "Epoch 82/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6763 - binary_accuracy: 0.5759 - val_loss: 0.6751 - val_binary_accuracy: 0.5821\n",
            "Epoch 83/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6761 - binary_accuracy: 0.5766 - val_loss: 0.6750 - val_binary_accuracy: 0.5821\n",
            "Epoch 84/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6760 - binary_accuracy: 0.5760 - val_loss: 0.6749 - val_binary_accuracy: 0.5821\n",
            "Epoch 85/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6759 - binary_accuracy: 0.5765 - val_loss: 0.6747 - val_binary_accuracy: 0.5812\n",
            "Epoch 86/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6757 - binary_accuracy: 0.5775 - val_loss: 0.6746 - val_binary_accuracy: 0.5812\n",
            "Epoch 87/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6756 - binary_accuracy: 0.5769 - val_loss: 0.6745 - val_binary_accuracy: 0.5812\n",
            "Epoch 88/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6755 - binary_accuracy: 0.5762 - val_loss: 0.6744 - val_binary_accuracy: 0.5807\n",
            "Epoch 89/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6754 - binary_accuracy: 0.5762 - val_loss: 0.6743 - val_binary_accuracy: 0.5812\n",
            "Epoch 90/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6752 - binary_accuracy: 0.5779 - val_loss: 0.6742 - val_binary_accuracy: 0.5817\n",
            "Epoch 91/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6751 - binary_accuracy: 0.5771 - val_loss: 0.6740 - val_binary_accuracy: 0.5817\n",
            "Epoch 92/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6750 - binary_accuracy: 0.5775 - val_loss: 0.6739 - val_binary_accuracy: 0.5830\n",
            "Epoch 93/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6749 - binary_accuracy: 0.5774 - val_loss: 0.6738 - val_binary_accuracy: 0.5821\n",
            "Epoch 94/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6747 - binary_accuracy: 0.5754 - val_loss: 0.6737 - val_binary_accuracy: 0.5830\n",
            "Epoch 95/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6746 - binary_accuracy: 0.5777 - val_loss: 0.6736 - val_binary_accuracy: 0.5821\n",
            "Epoch 96/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6745 - binary_accuracy: 0.5782 - val_loss: 0.6735 - val_binary_accuracy: 0.5821\n",
            "Epoch 97/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6744 - binary_accuracy: 0.5785 - val_loss: 0.6734 - val_binary_accuracy: 0.5821\n",
            "Epoch 98/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6743 - binary_accuracy: 0.5788 - val_loss: 0.6733 - val_binary_accuracy: 0.5817\n",
            "Epoch 99/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6742 - binary_accuracy: 0.5788 - val_loss: 0.6732 - val_binary_accuracy: 0.5821\n",
            "Epoch 100/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6740 - binary_accuracy: 0.5800 - val_loss: 0.6731 - val_binary_accuracy: 0.5821\n",
            "Epoch 101/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6739 - binary_accuracy: 0.5795 - val_loss: 0.6730 - val_binary_accuracy: 0.5821\n",
            "Epoch 102/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6738 - binary_accuracy: 0.5803 - val_loss: 0.6729 - val_binary_accuracy: 0.5839\n",
            "Epoch 103/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6737 - binary_accuracy: 0.5794 - val_loss: 0.6728 - val_binary_accuracy: 0.5830\n",
            "Epoch 104/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6736 - binary_accuracy: 0.5798 - val_loss: 0.6727 - val_binary_accuracy: 0.5830\n",
            "Epoch 105/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6735 - binary_accuracy: 0.5800 - val_loss: 0.6726 - val_binary_accuracy: 0.5826\n",
            "Epoch 106/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6734 - binary_accuracy: 0.5798 - val_loss: 0.6725 - val_binary_accuracy: 0.5821\n",
            "Epoch 107/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6733 - binary_accuracy: 0.5798 - val_loss: 0.6724 - val_binary_accuracy: 0.5830\n",
            "Epoch 108/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6732 - binary_accuracy: 0.5803 - val_loss: 0.6723 - val_binary_accuracy: 0.5830\n",
            "Epoch 109/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6731 - binary_accuracy: 0.5811 - val_loss: 0.6722 - val_binary_accuracy: 0.5812\n",
            "Epoch 110/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6730 - binary_accuracy: 0.5805 - val_loss: 0.6721 - val_binary_accuracy: 0.5821\n",
            "Epoch 111/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6729 - binary_accuracy: 0.5801 - val_loss: 0.6720 - val_binary_accuracy: 0.5835\n",
            "Epoch 112/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6728 - binary_accuracy: 0.5801 - val_loss: 0.6720 - val_binary_accuracy: 0.5835\n",
            "Epoch 113/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6727 - binary_accuracy: 0.5801 - val_loss: 0.6719 - val_binary_accuracy: 0.5830\n",
            "Epoch 114/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6726 - binary_accuracy: 0.5823 - val_loss: 0.6718 - val_binary_accuracy: 0.5830\n",
            "Epoch 115/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6725 - binary_accuracy: 0.5809 - val_loss: 0.6717 - val_binary_accuracy: 0.5830\n",
            "Epoch 116/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6724 - binary_accuracy: 0.5805 - val_loss: 0.6716 - val_binary_accuracy: 0.5839\n",
            "Epoch 117/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6723 - binary_accuracy: 0.5812 - val_loss: 0.6715 - val_binary_accuracy: 0.5835\n",
            "Epoch 118/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6722 - binary_accuracy: 0.5814 - val_loss: 0.6714 - val_binary_accuracy: 0.5849\n",
            "Epoch 119/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6721 - binary_accuracy: 0.5814 - val_loss: 0.6714 - val_binary_accuracy: 0.5849\n",
            "Epoch 120/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6720 - binary_accuracy: 0.5805 - val_loss: 0.6713 - val_binary_accuracy: 0.5844\n",
            "Epoch 121/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6720 - binary_accuracy: 0.5815 - val_loss: 0.6712 - val_binary_accuracy: 0.5858\n",
            "Epoch 122/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6719 - binary_accuracy: 0.5815 - val_loss: 0.6712 - val_binary_accuracy: 0.5858\n",
            "Epoch 123/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6718 - binary_accuracy: 0.5824 - val_loss: 0.6711 - val_binary_accuracy: 0.5862\n",
            "Epoch 124/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6717 - binary_accuracy: 0.5826 - val_loss: 0.6711 - val_binary_accuracy: 0.5867\n",
            "Epoch 125/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6716 - binary_accuracy: 0.5831 - val_loss: 0.6709 - val_binary_accuracy: 0.5862\n",
            "Epoch 126/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6715 - binary_accuracy: 0.5823 - val_loss: 0.6709 - val_binary_accuracy: 0.5862\n",
            "Epoch 127/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6715 - binary_accuracy: 0.5834 - val_loss: 0.6708 - val_binary_accuracy: 0.5867\n",
            "Epoch 128/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6714 - binary_accuracy: 0.5840 - val_loss: 0.6707 - val_binary_accuracy: 0.5872\n",
            "Epoch 129/1000\n",
            "205/205 [==============================] - 1s 2ms/step - loss: 0.6713 - binary_accuracy: 0.5840 - val_loss: 0.6707 - val_binary_accuracy: 0.5872\n",
            "Epoch 130/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6712 - binary_accuracy: 0.5838 - val_loss: 0.6706 - val_binary_accuracy: 0.5872\n",
            "Epoch 131/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6711 - binary_accuracy: 0.5847 - val_loss: 0.6705 - val_binary_accuracy: 0.5867\n",
            "Epoch 132/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6710 - binary_accuracy: 0.5840 - val_loss: 0.6705 - val_binary_accuracy: 0.5867\n",
            "Epoch 133/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6710 - binary_accuracy: 0.5829 - val_loss: 0.6704 - val_binary_accuracy: 0.5867\n",
            "Epoch 134/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6709 - binary_accuracy: 0.5841 - val_loss: 0.6703 - val_binary_accuracy: 0.5858\n",
            "Epoch 135/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6708 - binary_accuracy: 0.5844 - val_loss: 0.6703 - val_binary_accuracy: 0.5858\n",
            "Epoch 136/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6707 - binary_accuracy: 0.5840 - val_loss: 0.6702 - val_binary_accuracy: 0.5858\n",
            "Epoch 137/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6707 - binary_accuracy: 0.5834 - val_loss: 0.6702 - val_binary_accuracy: 0.5862\n",
            "Epoch 138/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6706 - binary_accuracy: 0.5837 - val_loss: 0.6701 - val_binary_accuracy: 0.5862\n",
            "Epoch 139/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6705 - binary_accuracy: 0.5835 - val_loss: 0.6700 - val_binary_accuracy: 0.5858\n",
            "Epoch 140/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6705 - binary_accuracy: 0.5844 - val_loss: 0.6700 - val_binary_accuracy: 0.5858\n",
            "Epoch 141/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6704 - binary_accuracy: 0.5852 - val_loss: 0.6699 - val_binary_accuracy: 0.5858\n",
            "Epoch 142/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6703 - binary_accuracy: 0.5849 - val_loss: 0.6699 - val_binary_accuracy: 0.5849\n",
            "Epoch 143/1000\n",
            "205/205 [==============================] - 1s 2ms/step - loss: 0.6703 - binary_accuracy: 0.5849 - val_loss: 0.6698 - val_binary_accuracy: 0.5853\n",
            "Epoch 144/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6702 - binary_accuracy: 0.5837 - val_loss: 0.6698 - val_binary_accuracy: 0.5844\n",
            "Epoch 145/1000\n",
            "205/205 [==============================] - 1s 2ms/step - loss: 0.6701 - binary_accuracy: 0.5846 - val_loss: 0.6697 - val_binary_accuracy: 0.5839\n",
            "Epoch 146/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6701 - binary_accuracy: 0.5844 - val_loss: 0.6697 - val_binary_accuracy: 0.5844\n",
            "Epoch 147/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6700 - binary_accuracy: 0.5847 - val_loss: 0.6696 - val_binary_accuracy: 0.5853\n",
            "Epoch 148/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6699 - binary_accuracy: 0.5858 - val_loss: 0.6696 - val_binary_accuracy: 0.5853\n",
            "Epoch 149/1000\n",
            "205/205 [==============================] - 1s 2ms/step - loss: 0.6699 - binary_accuracy: 0.5852 - val_loss: 0.6695 - val_binary_accuracy: 0.5849\n",
            "Epoch 150/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6698 - binary_accuracy: 0.5846 - val_loss: 0.6695 - val_binary_accuracy: 0.5853\n",
            "Epoch 151/1000\n",
            "205/205 [==============================] - 1s 2ms/step - loss: 0.6698 - binary_accuracy: 0.5855 - val_loss: 0.6694 - val_binary_accuracy: 0.5849\n",
            "Epoch 152/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6697 - binary_accuracy: 0.5857 - val_loss: 0.6694 - val_binary_accuracy: 0.5858\n",
            "Epoch 153/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6696 - binary_accuracy: 0.5864 - val_loss: 0.6693 - val_binary_accuracy: 0.5858\n",
            "Epoch 154/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6696 - binary_accuracy: 0.5850 - val_loss: 0.6693 - val_binary_accuracy: 0.5858\n",
            "Epoch 155/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6695 - binary_accuracy: 0.5866 - val_loss: 0.6692 - val_binary_accuracy: 0.5862\n",
            "Epoch 156/1000\n",
            "205/205 [==============================] - 1s 2ms/step - loss: 0.6695 - binary_accuracy: 0.5869 - val_loss: 0.6692 - val_binary_accuracy: 0.5853\n",
            "Epoch 157/1000\n",
            "205/205 [==============================] - 1s 2ms/step - loss: 0.6694 - binary_accuracy: 0.5853 - val_loss: 0.6691 - val_binary_accuracy: 0.5862\n",
            "Epoch 158/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6693 - binary_accuracy: 0.5850 - val_loss: 0.6691 - val_binary_accuracy: 0.5858\n",
            "Epoch 159/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6693 - binary_accuracy: 0.5857 - val_loss: 0.6691 - val_binary_accuracy: 0.5858\n",
            "Epoch 160/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6692 - binary_accuracy: 0.5861 - val_loss: 0.6690 - val_binary_accuracy: 0.5858\n",
            "Epoch 161/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6692 - binary_accuracy: 0.5866 - val_loss: 0.6690 - val_binary_accuracy: 0.5858\n",
            "Epoch 162/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6691 - binary_accuracy: 0.5864 - val_loss: 0.6690 - val_binary_accuracy: 0.5867\n",
            "Epoch 163/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6691 - binary_accuracy: 0.5858 - val_loss: 0.6689 - val_binary_accuracy: 0.5853\n",
            "Epoch 164/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6690 - binary_accuracy: 0.5860 - val_loss: 0.6688 - val_binary_accuracy: 0.5853\n",
            "Epoch 165/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6690 - binary_accuracy: 0.5873 - val_loss: 0.6688 - val_binary_accuracy: 0.5862\n",
            "Epoch 166/1000\n",
            "205/205 [==============================] - 1s 2ms/step - loss: 0.6689 - binary_accuracy: 0.5867 - val_loss: 0.6687 - val_binary_accuracy: 0.5862\n",
            "Epoch 167/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6689 - binary_accuracy: 0.5872 - val_loss: 0.6687 - val_binary_accuracy: 0.5853\n",
            "Epoch 168/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6688 - binary_accuracy: 0.5872 - val_loss: 0.6687 - val_binary_accuracy: 0.5872\n",
            "Epoch 169/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6688 - binary_accuracy: 0.5869 - val_loss: 0.6687 - val_binary_accuracy: 0.5867\n",
            "Epoch 170/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6687 - binary_accuracy: 0.5876 - val_loss: 0.6686 - val_binary_accuracy: 0.5867\n",
            "Epoch 171/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6686 - binary_accuracy: 0.5864 - val_loss: 0.6686 - val_binary_accuracy: 0.5867\n",
            "Epoch 172/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6686 - binary_accuracy: 0.5878 - val_loss: 0.6685 - val_binary_accuracy: 0.5862\n",
            "Epoch 173/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6685 - binary_accuracy: 0.5873 - val_loss: 0.6685 - val_binary_accuracy: 0.5872\n",
            "Epoch 174/1000\n",
            "205/205 [==============================] - 1s 2ms/step - loss: 0.6685 - binary_accuracy: 0.5884 - val_loss: 0.6685 - val_binary_accuracy: 0.5867\n",
            "Epoch 175/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6684 - binary_accuracy: 0.5869 - val_loss: 0.6685 - val_binary_accuracy: 0.5872\n",
            "Epoch 176/1000\n",
            "205/205 [==============================] - 1s 2ms/step - loss: 0.6684 - binary_accuracy: 0.5879 - val_loss: 0.6684 - val_binary_accuracy: 0.5876\n",
            "Epoch 177/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6683 - binary_accuracy: 0.5875 - val_loss: 0.6684 - val_binary_accuracy: 0.5872\n",
            "Epoch 178/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6683 - binary_accuracy: 0.5875 - val_loss: 0.6683 - val_binary_accuracy: 0.5881\n",
            "Epoch 179/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6682 - binary_accuracy: 0.5884 - val_loss: 0.6683 - val_binary_accuracy: 0.5881\n",
            "Epoch 180/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6682 - binary_accuracy: 0.5886 - val_loss: 0.6683 - val_binary_accuracy: 0.5881\n",
            "Epoch 181/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6681 - binary_accuracy: 0.5884 - val_loss: 0.6682 - val_binary_accuracy: 0.5885\n",
            "Epoch 182/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6681 - binary_accuracy: 0.5878 - val_loss: 0.6682 - val_binary_accuracy: 0.5885\n",
            "Epoch 183/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6680 - binary_accuracy: 0.5881 - val_loss: 0.6682 - val_binary_accuracy: 0.5885\n",
            "Epoch 184/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6680 - binary_accuracy: 0.5893 - val_loss: 0.6682 - val_binary_accuracy: 0.5885\n",
            "Epoch 185/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6679 - binary_accuracy: 0.5890 - val_loss: 0.6681 - val_binary_accuracy: 0.5885\n",
            "Epoch 186/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6679 - binary_accuracy: 0.5886 - val_loss: 0.6681 - val_binary_accuracy: 0.5890\n",
            "Epoch 187/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6679 - binary_accuracy: 0.5893 - val_loss: 0.6681 - val_binary_accuracy: 0.5881\n",
            "Epoch 188/1000\n",
            "205/205 [==============================] - 1s 2ms/step - loss: 0.6678 - binary_accuracy: 0.5890 - val_loss: 0.6681 - val_binary_accuracy: 0.5885\n",
            "Epoch 189/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6678 - binary_accuracy: 0.5892 - val_loss: 0.6680 - val_binary_accuracy: 0.5890\n",
            "Epoch 190/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6677 - binary_accuracy: 0.5893 - val_loss: 0.6680 - val_binary_accuracy: 0.5885\n",
            "Epoch 191/1000\n",
            "205/205 [==============================] - 1s 2ms/step - loss: 0.6677 - binary_accuracy: 0.5901 - val_loss: 0.6679 - val_binary_accuracy: 0.5899\n",
            "Epoch 192/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6676 - binary_accuracy: 0.5909 - val_loss: 0.6679 - val_binary_accuracy: 0.5899\n",
            "Epoch 193/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6676 - binary_accuracy: 0.5901 - val_loss: 0.6679 - val_binary_accuracy: 0.5885\n",
            "Epoch 194/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6675 - binary_accuracy: 0.5902 - val_loss: 0.6678 - val_binary_accuracy: 0.5894\n",
            "Epoch 195/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6675 - binary_accuracy: 0.5918 - val_loss: 0.6678 - val_binary_accuracy: 0.5885\n",
            "Epoch 196/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6674 - binary_accuracy: 0.5907 - val_loss: 0.6678 - val_binary_accuracy: 0.5894\n",
            "Epoch 197/1000\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.6674 - binary_accuracy: 0.5899 - val_loss: 0.6678 - val_binary_accuracy: 0.5890\n",
            "Epoch 198/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6674 - binary_accuracy: 0.5910 - val_loss: 0.6678 - val_binary_accuracy: 0.5890\n",
            "Epoch 199/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6673 - binary_accuracy: 0.5910 - val_loss: 0.6677 - val_binary_accuracy: 0.5890\n",
            "Epoch 200/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6673 - binary_accuracy: 0.5905 - val_loss: 0.6677 - val_binary_accuracy: 0.5894\n",
            "Epoch 201/1000\n",
            "205/205 [==============================] - 1s 6ms/step - loss: 0.6672 - binary_accuracy: 0.5912 - val_loss: 0.6677 - val_binary_accuracy: 0.5890\n",
            "Epoch 202/1000\n",
            "205/205 [==============================] - 1s 6ms/step - loss: 0.6672 - binary_accuracy: 0.5902 - val_loss: 0.6676 - val_binary_accuracy: 0.5899\n",
            "Epoch 203/1000\n",
            "205/205 [==============================] - 1s 5ms/step - loss: 0.6672 - binary_accuracy: 0.5916 - val_loss: 0.6676 - val_binary_accuracy: 0.5904\n",
            "Epoch 204/1000\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.6671 - binary_accuracy: 0.5915 - val_loss: 0.6676 - val_binary_accuracy: 0.5890\n",
            "Epoch 205/1000\n",
            "205/205 [==============================] - 1s 5ms/step - loss: 0.6671 - binary_accuracy: 0.5921 - val_loss: 0.6676 - val_binary_accuracy: 0.5890\n",
            "Epoch 206/1000\n",
            "205/205 [==============================] - 1s 2ms/step - loss: 0.6670 - binary_accuracy: 0.5910 - val_loss: 0.6676 - val_binary_accuracy: 0.5894\n",
            "Epoch 207/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6670 - binary_accuracy: 0.5904 - val_loss: 0.6675 - val_binary_accuracy: 0.5908\n",
            "Epoch 208/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6670 - binary_accuracy: 0.5927 - val_loss: 0.6675 - val_binary_accuracy: 0.5894\n",
            "Epoch 209/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6669 - binary_accuracy: 0.5913 - val_loss: 0.6676 - val_binary_accuracy: 0.5885\n",
            "Epoch 210/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6669 - binary_accuracy: 0.5912 - val_loss: 0.6675 - val_binary_accuracy: 0.5890\n",
            "Epoch 211/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6669 - binary_accuracy: 0.5904 - val_loss: 0.6675 - val_binary_accuracy: 0.5890\n",
            "Epoch 212/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6668 - binary_accuracy: 0.5905 - val_loss: 0.6675 - val_binary_accuracy: 0.5890\n",
            "Epoch 213/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6668 - binary_accuracy: 0.5924 - val_loss: 0.6675 - val_binary_accuracy: 0.5899\n",
            "Epoch 214/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6668 - binary_accuracy: 0.5921 - val_loss: 0.6674 - val_binary_accuracy: 0.5890\n",
            "Epoch 215/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6667 - binary_accuracy: 0.5905 - val_loss: 0.6674 - val_binary_accuracy: 0.5899\n",
            "Epoch 216/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6667 - binary_accuracy: 0.5925 - val_loss: 0.6674 - val_binary_accuracy: 0.5904\n",
            "Epoch 217/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6667 - binary_accuracy: 0.5913 - val_loss: 0.6674 - val_binary_accuracy: 0.5904\n",
            "Epoch 218/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6667 - binary_accuracy: 0.5921 - val_loss: 0.6674 - val_binary_accuracy: 0.5904\n",
            "Epoch 219/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6666 - binary_accuracy: 0.5924 - val_loss: 0.6674 - val_binary_accuracy: 0.5917\n",
            "Epoch 220/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6666 - binary_accuracy: 0.5912 - val_loss: 0.6674 - val_binary_accuracy: 0.5904\n",
            "Epoch 221/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6666 - binary_accuracy: 0.5924 - val_loss: 0.6673 - val_binary_accuracy: 0.5899\n",
            "Epoch 222/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6665 - binary_accuracy: 0.5912 - val_loss: 0.6673 - val_binary_accuracy: 0.5917\n",
            "Epoch 223/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6665 - binary_accuracy: 0.5919 - val_loss: 0.6673 - val_binary_accuracy: 0.5917\n",
            "Epoch 224/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6665 - binary_accuracy: 0.5922 - val_loss: 0.6673 - val_binary_accuracy: 0.5922\n",
            "Epoch 225/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6664 - binary_accuracy: 0.5927 - val_loss: 0.6673 - val_binary_accuracy: 0.5917\n",
            "Epoch 226/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6664 - binary_accuracy: 0.5919 - val_loss: 0.6673 - val_binary_accuracy: 0.5917\n",
            "Epoch 227/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6664 - binary_accuracy: 0.5921 - val_loss: 0.6673 - val_binary_accuracy: 0.5917\n",
            "Epoch 228/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6663 - binary_accuracy: 0.5918 - val_loss: 0.6672 - val_binary_accuracy: 0.5913\n",
            "Epoch 229/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6663 - binary_accuracy: 0.5938 - val_loss: 0.6672 - val_binary_accuracy: 0.5913\n",
            "Epoch 230/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6663 - binary_accuracy: 0.5925 - val_loss: 0.6672 - val_binary_accuracy: 0.5922\n",
            "Epoch 231/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6662 - binary_accuracy: 0.5927 - val_loss: 0.6672 - val_binary_accuracy: 0.5917\n",
            "Epoch 232/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6662 - binary_accuracy: 0.5928 - val_loss: 0.6672 - val_binary_accuracy: 0.5908\n",
            "Epoch 233/1000\n",
            "205/205 [==============================] - 0s 2ms/step - loss: 0.6662 - binary_accuracy: 0.5921 - val_loss: 0.6671 - val_binary_accuracy: 0.5913\n",
            "Epoch 234/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6662 - binary_accuracy: 0.5927 - val_loss: 0.6671 - val_binary_accuracy: 0.5899\n",
            "Epoch 235/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6662 - binary_accuracy: 0.5939 - val_loss: 0.6671 - val_binary_accuracy: 0.5899\n",
            "Epoch 236/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6661 - binary_accuracy: 0.5925 - val_loss: 0.6671 - val_binary_accuracy: 0.5904\n",
            "Epoch 237/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6661 - binary_accuracy: 0.5936 - val_loss: 0.6671 - val_binary_accuracy: 0.5908\n",
            "Epoch 238/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6661 - binary_accuracy: 0.5936 - val_loss: 0.6671 - val_binary_accuracy: 0.5904\n",
            "Epoch 239/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6661 - binary_accuracy: 0.5931 - val_loss: 0.6671 - val_binary_accuracy: 0.5904\n",
            "Epoch 240/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6660 - binary_accuracy: 0.5916 - val_loss: 0.6671 - val_binary_accuracy: 0.5904\n",
            "Epoch 241/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6660 - binary_accuracy: 0.5938 - val_loss: 0.6671 - val_binary_accuracy: 0.5908\n",
            "Epoch 242/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6660 - binary_accuracy: 0.5922 - val_loss: 0.6671 - val_binary_accuracy: 0.5904\n",
            "Epoch 243/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6660 - binary_accuracy: 0.5930 - val_loss: 0.6670 - val_binary_accuracy: 0.5890\n",
            "Epoch 244/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6659 - binary_accuracy: 0.5938 - val_loss: 0.6670 - val_binary_accuracy: 0.5904\n",
            "Epoch 245/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6659 - binary_accuracy: 0.5916 - val_loss: 0.6670 - val_binary_accuracy: 0.5908\n",
            "Epoch 246/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6659 - binary_accuracy: 0.5912 - val_loss: 0.6670 - val_binary_accuracy: 0.5904\n",
            "Epoch 247/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6659 - binary_accuracy: 0.5933 - val_loss: 0.6670 - val_binary_accuracy: 0.5894\n",
            "Epoch 248/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6658 - binary_accuracy: 0.5928 - val_loss: 0.6670 - val_binary_accuracy: 0.5894\n",
            "Epoch 249/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6658 - binary_accuracy: 0.5930 - val_loss: 0.6670 - val_binary_accuracy: 0.5894\n",
            "Epoch 250/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6658 - binary_accuracy: 0.5936 - val_loss: 0.6670 - val_binary_accuracy: 0.5899\n",
            "Epoch 251/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6658 - binary_accuracy: 0.5922 - val_loss: 0.6670 - val_binary_accuracy: 0.5908\n",
            "Epoch 252/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6657 - binary_accuracy: 0.5921 - val_loss: 0.6669 - val_binary_accuracy: 0.5899\n",
            "Epoch 253/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6657 - binary_accuracy: 0.5924 - val_loss: 0.6669 - val_binary_accuracy: 0.5899\n",
            "Epoch 254/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6657 - binary_accuracy: 0.5941 - val_loss: 0.6669 - val_binary_accuracy: 0.5894\n",
            "Epoch 255/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6657 - binary_accuracy: 0.5930 - val_loss: 0.6669 - val_binary_accuracy: 0.5904\n",
            "Epoch 256/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6656 - binary_accuracy: 0.5930 - val_loss: 0.6669 - val_binary_accuracy: 0.5899\n",
            "Epoch 257/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6656 - binary_accuracy: 0.5918 - val_loss: 0.6669 - val_binary_accuracy: 0.5894\n",
            "Epoch 258/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6656 - binary_accuracy: 0.5925 - val_loss: 0.6669 - val_binary_accuracy: 0.5890\n",
            "Epoch 259/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6656 - binary_accuracy: 0.5944 - val_loss: 0.6669 - val_binary_accuracy: 0.5885\n",
            "Epoch 260/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6655 - binary_accuracy: 0.5950 - val_loss: 0.6669 - val_binary_accuracy: 0.5894\n",
            "Epoch 261/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6655 - binary_accuracy: 0.5933 - val_loss: 0.6669 - val_binary_accuracy: 0.5890\n",
            "Epoch 262/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6655 - binary_accuracy: 0.5921 - val_loss: 0.6668 - val_binary_accuracy: 0.5890\n",
            "Epoch 263/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6655 - binary_accuracy: 0.5942 - val_loss: 0.6668 - val_binary_accuracy: 0.5890\n",
            "Epoch 264/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6655 - binary_accuracy: 0.5939 - val_loss: 0.6668 - val_binary_accuracy: 0.5894\n",
            "Epoch 265/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6655 - binary_accuracy: 0.5918 - val_loss: 0.6668 - val_binary_accuracy: 0.5890\n",
            "Epoch 266/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6654 - binary_accuracy: 0.5944 - val_loss: 0.6668 - val_binary_accuracy: 0.5894\n",
            "Epoch 267/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6654 - binary_accuracy: 0.5938 - val_loss: 0.6668 - val_binary_accuracy: 0.5890\n",
            "Epoch 268/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6654 - binary_accuracy: 0.5948 - val_loss: 0.6668 - val_binary_accuracy: 0.5890\n",
            "Epoch 269/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6654 - binary_accuracy: 0.5948 - val_loss: 0.6668 - val_binary_accuracy: 0.5881\n",
            "Epoch 270/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6653 - binary_accuracy: 0.5941 - val_loss: 0.6668 - val_binary_accuracy: 0.5876\n",
            "Epoch 271/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6653 - binary_accuracy: 0.5950 - val_loss: 0.6668 - val_binary_accuracy: 0.5876\n",
            "Epoch 272/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6653 - binary_accuracy: 0.5927 - val_loss: 0.6668 - val_binary_accuracy: 0.5876\n",
            "Epoch 273/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6653 - binary_accuracy: 0.5922 - val_loss: 0.6668 - val_binary_accuracy: 0.5890\n",
            "Epoch 274/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6652 - binary_accuracy: 0.5947 - val_loss: 0.6668 - val_binary_accuracy: 0.5881\n",
            "Epoch 275/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6652 - binary_accuracy: 0.5944 - val_loss: 0.6668 - val_binary_accuracy: 0.5881\n",
            "Epoch 276/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6652 - binary_accuracy: 0.5935 - val_loss: 0.6668 - val_binary_accuracy: 0.5881\n",
            "Epoch 277/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6652 - binary_accuracy: 0.5935 - val_loss: 0.6668 - val_binary_accuracy: 0.5885\n",
            "Epoch 278/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6651 - binary_accuracy: 0.5930 - val_loss: 0.6668 - val_binary_accuracy: 0.5890\n",
            "Epoch 279/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6652 - binary_accuracy: 0.5954 - val_loss: 0.6667 - val_binary_accuracy: 0.5890\n",
            "Epoch 280/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6651 - binary_accuracy: 0.5941 - val_loss: 0.6668 - val_binary_accuracy: 0.5885\n",
            "Epoch 281/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6651 - binary_accuracy: 0.5941 - val_loss: 0.6667 - val_binary_accuracy: 0.5885\n",
            "Epoch 282/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6651 - binary_accuracy: 0.5927 - val_loss: 0.6667 - val_binary_accuracy: 0.5872\n",
            "Epoch 283/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6651 - binary_accuracy: 0.5945 - val_loss: 0.6667 - val_binary_accuracy: 0.5872\n",
            "Epoch 284/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6650 - binary_accuracy: 0.5956 - val_loss: 0.6667 - val_binary_accuracy: 0.5881\n",
            "Epoch 285/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6650 - binary_accuracy: 0.5947 - val_loss: 0.6667 - val_binary_accuracy: 0.5881\n",
            "Epoch 286/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6650 - binary_accuracy: 0.5948 - val_loss: 0.6667 - val_binary_accuracy: 0.5876\n",
            "Epoch 287/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6650 - binary_accuracy: 0.5939 - val_loss: 0.6667 - val_binary_accuracy: 0.5885\n",
            "Epoch 288/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6649 - binary_accuracy: 0.5945 - val_loss: 0.6666 - val_binary_accuracy: 0.5862\n",
            "Epoch 289/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6649 - binary_accuracy: 0.5953 - val_loss: 0.6667 - val_binary_accuracy: 0.5894\n",
            "Epoch 290/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6649 - binary_accuracy: 0.5950 - val_loss: 0.6667 - val_binary_accuracy: 0.5885\n",
            "Epoch 291/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6649 - binary_accuracy: 0.5945 - val_loss: 0.6667 - val_binary_accuracy: 0.5876\n",
            "Epoch 292/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6649 - binary_accuracy: 0.5951 - val_loss: 0.6667 - val_binary_accuracy: 0.5881\n",
            "Epoch 293/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6649 - binary_accuracy: 0.5954 - val_loss: 0.6667 - val_binary_accuracy: 0.5885\n",
            "Epoch 294/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6648 - binary_accuracy: 0.5953 - val_loss: 0.6666 - val_binary_accuracy: 0.5894\n",
            "Epoch 295/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6648 - binary_accuracy: 0.5951 - val_loss: 0.6666 - val_binary_accuracy: 0.5862\n",
            "Epoch 296/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6648 - binary_accuracy: 0.5957 - val_loss: 0.6666 - val_binary_accuracy: 0.5876\n",
            "Epoch 297/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6647 - binary_accuracy: 0.5951 - val_loss: 0.6666 - val_binary_accuracy: 0.5890\n",
            "Epoch 298/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6647 - binary_accuracy: 0.5970 - val_loss: 0.6666 - val_binary_accuracy: 0.5899\n",
            "Epoch 299/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6647 - binary_accuracy: 0.5964 - val_loss: 0.6666 - val_binary_accuracy: 0.5872\n",
            "Epoch 300/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6647 - binary_accuracy: 0.5974 - val_loss: 0.6666 - val_binary_accuracy: 0.5894\n",
            "Epoch 301/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6647 - binary_accuracy: 0.5956 - val_loss: 0.6665 - val_binary_accuracy: 0.5885\n",
            "Epoch 302/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6646 - binary_accuracy: 0.5973 - val_loss: 0.6666 - val_binary_accuracy: 0.5890\n",
            "Epoch 303/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6646 - binary_accuracy: 0.5970 - val_loss: 0.6666 - val_binary_accuracy: 0.5881\n",
            "Epoch 304/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6646 - binary_accuracy: 0.5962 - val_loss: 0.6665 - val_binary_accuracy: 0.5894\n",
            "Epoch 305/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6646 - binary_accuracy: 0.5970 - val_loss: 0.6665 - val_binary_accuracy: 0.5894\n",
            "Epoch 306/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6645 - binary_accuracy: 0.5954 - val_loss: 0.6665 - val_binary_accuracy: 0.5894\n",
            "Epoch 307/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6645 - binary_accuracy: 0.5962 - val_loss: 0.6665 - val_binary_accuracy: 0.5899\n",
            "Epoch 308/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6645 - binary_accuracy: 0.5950 - val_loss: 0.6665 - val_binary_accuracy: 0.5881\n",
            "Epoch 309/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6645 - binary_accuracy: 0.5962 - val_loss: 0.6665 - val_binary_accuracy: 0.5881\n",
            "Epoch 310/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6645 - binary_accuracy: 0.5971 - val_loss: 0.6664 - val_binary_accuracy: 0.5890\n",
            "Epoch 311/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6645 - binary_accuracy: 0.5974 - val_loss: 0.6664 - val_binary_accuracy: 0.5876\n",
            "Epoch 312/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6644 - binary_accuracy: 0.5971 - val_loss: 0.6665 - val_binary_accuracy: 0.5894\n",
            "Epoch 313/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6644 - binary_accuracy: 0.5971 - val_loss: 0.6664 - val_binary_accuracy: 0.5881\n",
            "Epoch 314/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6644 - binary_accuracy: 0.5968 - val_loss: 0.6665 - val_binary_accuracy: 0.5890\n",
            "Epoch 315/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6644 - binary_accuracy: 0.5979 - val_loss: 0.6665 - val_binary_accuracy: 0.5890\n",
            "Epoch 316/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6644 - binary_accuracy: 0.5964 - val_loss: 0.6665 - val_binary_accuracy: 0.5894\n",
            "Epoch 317/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6643 - binary_accuracy: 0.5962 - val_loss: 0.6664 - val_binary_accuracy: 0.5899\n",
            "Epoch 318/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6643 - binary_accuracy: 0.5977 - val_loss: 0.6664 - val_binary_accuracy: 0.5894\n",
            "Epoch 319/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6643 - binary_accuracy: 0.5973 - val_loss: 0.6664 - val_binary_accuracy: 0.5894\n",
            "Epoch 320/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6643 - binary_accuracy: 0.5974 - val_loss: 0.6664 - val_binary_accuracy: 0.5899\n",
            "Epoch 321/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6643 - binary_accuracy: 0.5983 - val_loss: 0.6664 - val_binary_accuracy: 0.5904\n",
            "Epoch 322/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6642 - binary_accuracy: 0.5971 - val_loss: 0.6665 - val_binary_accuracy: 0.5904\n",
            "Epoch 323/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6643 - binary_accuracy: 0.5964 - val_loss: 0.6664 - val_binary_accuracy: 0.5904\n",
            "Epoch 324/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6642 - binary_accuracy: 0.5977 - val_loss: 0.6665 - val_binary_accuracy: 0.5904\n",
            "Epoch 325/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6642 - binary_accuracy: 0.5973 - val_loss: 0.6664 - val_binary_accuracy: 0.5904\n",
            "Epoch 326/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6642 - binary_accuracy: 0.5983 - val_loss: 0.6664 - val_binary_accuracy: 0.5904\n",
            "Epoch 327/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6642 - binary_accuracy: 0.5976 - val_loss: 0.6665 - val_binary_accuracy: 0.5894\n",
            "Epoch 328/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6642 - binary_accuracy: 0.5968 - val_loss: 0.6665 - val_binary_accuracy: 0.5908\n",
            "Epoch 329/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6641 - binary_accuracy: 0.5974 - val_loss: 0.6665 - val_binary_accuracy: 0.5908\n",
            "Epoch 330/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6641 - binary_accuracy: 0.5968 - val_loss: 0.6665 - val_binary_accuracy: 0.5904\n",
            "Epoch 331/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6641 - binary_accuracy: 0.5976 - val_loss: 0.6664 - val_binary_accuracy: 0.5899\n",
            "Epoch 332/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6641 - binary_accuracy: 0.5977 - val_loss: 0.6664 - val_binary_accuracy: 0.5904\n",
            "Epoch 333/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6641 - binary_accuracy: 0.5974 - val_loss: 0.6664 - val_binary_accuracy: 0.5899\n",
            "Epoch 334/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6641 - binary_accuracy: 0.5973 - val_loss: 0.6665 - val_binary_accuracy: 0.5904\n",
            "Epoch 335/1000\n",
            "205/205 [==============================] - 1s 3ms/step - loss: 0.6640 - binary_accuracy: 0.5982 - val_loss: 0.6665 - val_binary_accuracy: 0.5908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F0zbOtolAgF",
        "outputId": "324fa943-5a36-4fa4-fb8a-0022ff9bdd2d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 32)                672       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 4)                 36        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,377\n",
            "Trainable params: 1,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('accuracy:',performance[1], 'loss:', performance[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1C9Hxvtg8lp",
        "outputId": "8e721cb5-b11c-4b7a-c0fe-c1f0f66236cc"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 0s 1ms/step - loss: 0.6660 - binary_accuracy: 0.6041\n",
            "accuracy: 0.6041284203529358 loss: 0.6660483479499817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "plt.plot(hist.history['binary_accuracy'])\n",
        "plt.plot(hist.history['val_binary_accuracy'])\n",
        "plt.title('Accuracy')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "uLVBOKTFg9YT",
        "outputId": "9473d64e-fe1f-4f57-b0b2-c85b6e0730e8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xV9f348df73uxNJpAwguwZMCCOukdcgP1aBEdta8XaavXb1qo/O9TWVttvXXUVrVrrQOukLnCAE5SAjLBDWAkJhJC9x/v3xznEywiEkHAz3s/H4z6493M+59z3Oca88xnnc0RVMcYYYw7G4+8AjDHGdF6WJIwxxrTIkoQxxpgWWZIwxhjTIksSxhhjWmRJwhhjTIssSRhjjGmRJQljDkJEtojI2f6Owxh/syRhjDGmRZYkjGklEQkWkQdFZIf7elBEgt1t8SLytoiUiMgeEflMRDzutltFJE9EykVkvYic5d8zMab1AvwdgDFdyB3AZCANUOAt4DfAb4FfArlAglt3MqAiMgy4AZioqjtEZCDgPbZhG9N21pIwpvWuAO5W1V2qWgjcBVzlbqsH+gADVLVeVT9TZ2G0RiAYGCkigaq6RVU3+SV6Y9rAkoQxrdcX2OrzeatbBvBXIBuYLyI5InIbgKpmAzcDdwK7RGSOiPTFmC7CkoQxrbcDGODzub9bhqqWq+ovVXUQMAX4xd6xB1V9UVVPcfdV4L5jG7YxbWdJwpiWBYpIyN4X8BLwGxFJEJF44HfA8wAicpGIDBYRAUpxupmaRGSYiJzpDnDXANVAk39Ox5gjZ0nCmJa9i/NLfe8rBMgEVgKrgGXAH926Q4APgQpgEfCYqi7AGY+4F9gNFACJwO3H7hSMOTpiDx0yxhjTEmtJGGOMaZElCWOMMS2yJGGMMaZFliSMMca0qEstyxEfH68DBw70dxjGGNOlLF26dLeqJhy+5oG6VJIYOHAgmZmZ/g7DGGO6FBHZevhaB2fdTcYYY1pkScIYY0yLLEkYY4xpUavGJEQkA3gIZx38p1T13v22PwCc4X4MAxJVNcbddjXOmvsAf1TVf7nlxwPPAqE4yx/cpG24/bu+vp7c3FxqamqOdNcuJSQkhJSUFAIDA/0dijGmBzlskhARL/AocA7OQ1WWiMhcVV2zt46q/q9P/RuB8e77WOD3QDrO6pdL3X2LgceBa4GvcJJEBvDekZ5Abm4ukZGRDBw4EGdtte5HVSkqKiI3N5fU1FR/h2OM6UFa0900CchW1RxVrQPmAFMPUX8mzmqZAOcBH6jqHjcxfABkiEgfIEpVF7uth+eAaW05gZqaGuLi4rptggAQEeLi4rp9a8kY0/m0JkkkA9t9Pue6ZQcQkQFAKvDxYfZNdt+35pizRCRTRDILCwsPGmB3ThB79YRzNMZ0Pu09cD0DeFVVG9vrgKo6W1XTVTU9IaFN94JQXFVHUUVte4VkjDE9RmuSRB7Qz+dzilt2MDP4tqvpUPvmue9bc8yjVlpVT1FFXYccu6SkhMcee+yI97vgggsoKSnpgIiMMab9tCZJLAGGiEiqiAThJIK5+1cSkeFAL5wHruw1DzhXRHqJSC/gXGCequYDZSIy2X2S1/eBt47yXFoUFOChrrGJjnh2RktJoqGh4ZD7vfvuu8TExLR7PMYY054OO7tJVRtE5AacX/he4GlVXS0idwOZqro3YcwA5vhOY1XVPSLyB5xEA3C3qu5x3/+Ub6fAvkcbZja1VlCAhyZVGpqUQG/79u3fdtttbNq0ibS0NAIDAwkJCaFXr16sW7eODRs2MG3aNLZv305NTQ033XQTs2bNAr5dYqSiooLzzz+fU045hS+//JLk5GTeeustQkND2zVOY4xpiy71ZLr09HTdf+2mtWvXMmLECADu+u9q1uwoO2C/xialpr6R0CAvniMcAB7ZN4rfXzyqxe1btmzhoosuIisri4ULF3LhhReSlZXVPFV1z549xMbGUl1dzcSJE/nkk0+Ii4vbJ0kMHjyYzMxM0tLSmD59OlOmTOHKK6884Lt8z9UYY1pLRJaqanpb9u1SC/y11d680KTg6eBJQpMmTdrnXoaHH36YN954A4Dt27ezceNG4uLi9tknNTWVtLQ0AI4//ni2bNnSsUEaY0wrdask0dJf/E1NStaOUnpHhZAYFdKhMYSHhze/X7hwIR9++CGLFi0iLCyM008//aD3OgQHBze/93q9VFdXd2iMxhjTWj1i7SaPRwjweKhraGr3Y0dGRlJeXn7QbaWlpfTq1YuwsDDWrVvH4sWL2/37jTGmI3WrlsShBAV4qG1s/yQRFxfHySefzOjRowkNDSUpKal5W0ZGBk888QQjRoxg2LBhTJ48ud2/3xhjOlK3Grg+lO17qqiobWBEn6iOCq/D2cC1MaYtjmbgukd0NwEEB3qob2yisan9WxPGGNNd9ZwkEeAFoLYDxiWMMaa76kFJwjnV2npLEsYY01o9Y+C6roqgpgYEobah3dYeNMaYbq9nJInyfDyN9QQFJFNjLQljjGm1ntHdFBgKDdWEBgo19daSMMaY1uohSSIMgAhvA3XtPMOprUuFAzz44INUVVW1WyzGGNPeekiScFZUDcN58FB7djlZkjDGdGc9Y0zCGwTiJVBrgWCq6xsJD26fU/ddKvycc84hMTGRV155hdraWi655BLuuusuKisrmT59Orm5uTQ2NvLb3/6WnTt3smPHDs444wzi4+NZsGBBu8RjjDHtqXslifdug4JVB99WX4UHOE6D8HoE3PsmDqv3GDj/3hY333vvvWRlZbF8+XLmz5/Pq6++ytdff42qMmXKFD799FMKCwvp27cv77zzDuCs6RQdHc3999/PggULiI+PP8ITNcaYY6NndDcBeLyINuEVoampY5YimT9/PvPnz2f8+PFMmDCBdevWsXHjRsaMGcMHH3zArbfeymeffUZ0dHSHfL8xxrS37tWSOMRf/FTtgZKtVIUNIrdCGdknigBv++ZIVeX222/nuuuuO2DbsmXLePfdd/nNb37DWWedxe9+97t2/W5jjOkIPacl4c5wCvfUAVBV1z5TYX2XCj/vvPN4+umnqaioACAvL49du3axY8cOwsLCuPLKK7nllltYtmzZAfsaY0xn1L1aEocSEAziIaipBiGIqroGokIDj/qwvkuFn3/++Vx++eWceOKJAERERPD888+TnZ3NLbfcgsfjITAwkMcffxyAWbNmkZGRQd++fW3g2hjTKbVqqXARyQAeArzAU6p6QL+OiEwH7gQUWKGql7vl9wEXutX+oKovu+XPAqcBpe62H6jq8kPFcTRLhQOwOxua6tlICh4RjkuIaN1+nYQtFW6MaYsOfca1iHiBR4FzgFxgiYjMVdU1PnWGALcDJ6tqsYgkuuUXAhOANCAYWCgi76lqmbvrLar6alsCb5OQSCjbQWQI7K5uRFUR6eCHXhtjTBfWmjGJSUC2quaoah0wB5i6X51rgUdVtRhAVXe55SOBT1W1QVUrgZVARvuE3gbBzgOHojzVNKnaEh3GGHMYrUkSycB2n8+5bpmvocBQEflCRBa73VMAK4AMEQkTkXjgDKCfz373iMhKEXlARIIP9uUiMktEMkUks7Cw8KABtvrpegEh4AkguLESgIrarpMkutITBI0x3Ud7zW4KAIYApwMzgSdFJEZV5wPvAl8CLwGLgL2/mW8HhgMTgVjg1oMdWFVnq2q6qqYnJCQcsD0kJISioqLW/RIVgeAovPUVBAd4qKxtOLKz9BNVpaioiJCQEH+HYozpYVozuymPff/6T3HLfOUCX6lqPbBZRDbgJI0lqnoPcA+AiLwIbABQ1Xx331oReQb4VVtOICUlhdzcXFpqZRygrhKqiigPrKO8XqjaFdIlxiVCQkJISUnxdxjGmB6mNUliCTBERFJxksMM4PL96ryJ04J4xu1WGgrkuIPeMapaJCJjgbHAfAAR6aOq+eL8hp4GZLXlBAIDA0lNTW39DhW74P/OYsOom5m+dBKvXX8ixw+IbctXG2NMt3fYJKGqDSJyAzAPZwrs06q6WkTuBjJVda677VwRWYPTnXSLmxhCgM/cv9TLgCtVdW8fzwsikgAIsBz4SXuf3EFFJEJyOoOKPkFkEp9vLLIkYYwxLWjVfRKdxcHuk2iTz+6Hj+7iBzH/oio0iVeuO/Hoj2mMMZ3U0dwn0XOW5fA1/CIAZsZk8c224i4zgG2MMcdaz0wSCUMhbjCTahZR36gszinyd0TGGNMp9cwkATD8QmJ2LSYpqIYF63cdvr4xxvRAPThJXIQ0NTAraQML1hXazWrGGHMQPTdJJKdDZF/O9XxNXkk1G3dV+DsiY4zpdHpukvB4YOQUUnZ/QTjVLFhnXU7GGLO/npskAEZORRpruTJ2nY1LGGPMQfTsJNFvMkT05rshmWRuKaaspt7fERljTKfSs5OExwMjLmZw6SICm6r5YuNuf0dkjDGdSs9OEgAjp+JtrOGCkCzrcjLGmP1YkhhwEoTFc3nkN3y8rpDGJpsKa4wxe1mS8HhhxMWMq1pMeUU5y7YV+zsiY4zpNCxJAIy4mIDGak4LWM17qwr8HY0xxnQaliQABn4HgqO5KmYV81YX2N3XxhjjsiQBEBAEQ89lUt1X5JdUsjK31N8RGWNMp2BJYq/hFxJcV8wk70bey7IuJ2OMAUsS3xp8NniDuLrXKt7PyrcuJ2OMwZLEt4IjYdDpnNL4FVuKKllXUO7viIwxxu9alSREJENE1otItojc1kKd6SKyRkRWi8iLPuX3iUiW+7rMpzxVRL5yj/myiAQd/ekcpeEXEVmdx0jPdt5ble/vaIwxxu8OmyRExAs8CpwPjARmisjI/eoMAW4HTlbVUcDNbvmFwAQgDTgB+JWIRLm73Qc8oKqDgWLgmnY5o6Mx7HxAuCZ+NW8u30GT3VhnjOnhWtOSmARkq2qOqtYBc4Cp+9W5FnhUVYsBVHXv+hYjgU9VtUFVK4GVQIaICHAm8Kpb71/AtKM7lXYQkQj9J3O2LmbbnioWb7bHmhpjerbWJIlkYLvP51y3zNdQYKiIfCEii0Ukwy1fgZMUwkQkHjgD6AfEASWq2nCIY/rHqO8SXb6R8SE7+E9mrr+jMcYYv2qvgesAYAhwOjATeFJEYlR1PvAu8CXwErAIaDySA4vILBHJFJHMwsLCdgr3EEZNA/FwU+IK3l2Vb8uHG2N6tNYkiTycv/73SnHLfOUCc1W1XlU3Axtwkgaqeo+qpqnqOYC424qAGBEJOMQxcfefrarpqpqekJDQ2vNqu4hESD2NE6s/obahkbeW7+j47zTGmE6qNUliCTDEnY0UBMwA5u5X502cVgRut9JQIEdEvCIS55aPBcYC89W5CWEBcKm7/9XAW0d5Lu1nzKUEl2/jkoQCXli81e6ZMMb0WIdNEu64wQ3APGAt8IqqrhaRu0VkilttHlAkImtwfvnfoqpFQCDwmVs+G7jSZxziVuAXIpKNM0bxz/Y8saMy4mLwBvOTuG9YV1BO5lZbGdYY0zNJV/orOT09XTMzM4/Nl825At2+hLTKhzhtWG8enjn+2HyvMca0MxFZqqrpbdnX7rhuyZhLkcqd/HLILt7LymdXeY2/IzLGmGPOkkRLhmZAcDTf5WMampR/L9rq74iMMeaYsyTRksBQGH8FEZve5tKhATy3aCsVtQ2H388YY7oRSxKHMvHH0NTAL+MWU1pdz+xPNvk7ImOMOaYsSRxK3HEw+Gx6b3iRqWMTmf1ZDjtKqv0dlTHGHDOWJA5n0iyoKOC3gzbRpPDXeev9HZExxhwzliQOZ/DZ0Gsg8Wue5ZpTUnnjmzy+yrGF/4wxPYMlicPxeGHitbBtET8fWUlKr1Buf2MVtQ1HtASVMcZ0SZYkWmP8lRAUSehXj3DPJWPIKazk0Y+z/R2VMcZ0OEsSrREaA+k/hDVvclqvYr47PplHF27im222XIcxpnuzJNFaJ/0cAsPhwzv5/ZRR9I4K4aY5yym3pcSNMd2YJYnWikiAU26G9e8QvWsJD81II7e4it+/tdrfkRljTIexJHEkJv8UIvvC/N+QPqAXPz9rCK9/k8dbyw/6KAxjjOnyLEkciaAwOPM3kLcUVr/ODWcMJn1AL37zRhbb91T5OzpjjGl3liSO1LgZkDQaPryTAK3nwRlpIHDTnG9oaGzyd3TGGNOuLEkcKY8Xzv0DlGyDr58kpVcY91wyhmXbSnjoo43+js4YY9qVJYm2OO5MOO4s+PSvUF3MlHF9+d7xKTyyIJsvN+32d3TGGNNuLEm01Tl3Q00pLLwXgLumjiI1Ppyb5yynqKLWz8EZY0z7sCTRVr1Hw8Rr4KsnIGchYUEBPDJzAiXV9fzyPytoauo6j4U1xpiWtCpJiEiGiKwXkWwRua2FOtNFZI2IrBaRF33K/+KWrRWRh0VE3PKF7jGXu6/E9jmlY+icP0DcYJh7I9RVMrJvFL+5cAQL1xfy9Beb/R2dMcYctcMmCRHxAo8C5wMjgZkiMnK/OkOA24GTVXUUcLNbfhJwMjAWGA1MBE7z2fUKVU1zX7va4XyOraAwmPJ3ZxB7wZ8AuGryAM4dmcR9769jZW6JnwM0xpij05qWxCQgW1VzVLUOmANM3a/OtcCjqloM4PMLX4EQIAgIBgKBne0ReKcx4CQ4/oew+DHIW4aI8JdLx5IQEcyNL31jy3YYY7q01iSJZGC7z+dct8zXUGCoiHwhIotFJANAVRcBC4B89zVPVdf67PeM29X0273dUPsTkVkikikimYWFha08rWPsnLsgPBHm/hwa64kJC+LhmePJLa7m9tdXoWrjE8aYrqm9Bq4DgCHA6cBM4EkRiRGRwcAIIAUnsZwpIt9x97lCVccA33FfVx3swKo6W1XTVTU9ISGhncJtZyHRcOH/wc5V8NnfAEgfGMsvzhnK2yvzmbNk+2EOYIwxnVNrkkQe0M/nc4pb5isXmKuq9aq6GdiAkzQuARaraoWqVgDvAScCqGqe+2858CJOt1bXNeJiGDMdPvkL5C4F4PrTjuM7Q+K5c+5q1hWU+TlAY4w5cq1JEkuAISKSKiJBwAxg7n513sRpRSAi8TjdTznANuA0EQkQkUCcQeu17ud4t34gcBGQ1Q7n418X/BUi+8Dr10JdJR6PcP/0NKJCA/nZC8uoqmvwd4TGGHNEDpskVLUBuAGYB6wFXlHV1SJyt4hMcavNA4pEZA3OGMQtqloEvApsAlYBK4AVqvpfnEHseSKyEliO0zJ5sn1PzQ9CY+CSx2HPJpj/WwASIoN56LI0cnZX8jtbVtwY08VIVxpUTU9P18zMTH+HcXjz7oBFj8Dl/4Gh5wJw/wcbePijjfzte+P4n+NT/BygMaYnEZGlqpreln3tjuuOcOZvIXEkvPUzqCwC4KazhnBCaiy/fSuL7F0Vfg7QGGNax5JERwgMge/OhpoS+O/PQRWvR3h45nhCAr3c8OIyauob/R2lMcYcliWJjtJ7jPOAonVvw/IXAEiKCuH+6eNYV1DOHW9k2f0TxphOz5JERzrxBhhwCrz7a9jtPGvi9GGJ3Hz2EF5blsu/vtzi3/iMMeYwLEl0JI/X6XYKCIb//BDqawD4+ZlDOHtEEn94Zy2Lc4r8HKQxxrTMkkRHi06GS55w7saefwcAHo/wwGXjGBAXxs9eWMaOkmo/B2mMMQdnSeJYGHqe0/W05ClY8xYAkSGBzL4qndqGJn7y/FIbyDbGdEqWJI6Vs34PfSfAWzdC8RYABidG8MBlaazMLbWBbGNMp2RJ4lgJCIJLnwYUXv0RNNQBcM7IJG46yxnIfm7RVv/GaIwx+7EkcSzFpsKUhyFvKXx8d3PxTWcN4ewRifzh7TU2kG2M6VQsSRxroy6B9Gvgy7/Dxg8AZyD7/svS6B8XxvXPL2Xz7ko/B2mMMQ5LEv5w3p8gaTS8cR2U7QAgKiSQp6+eiIjwg2e+pqii1s9BGmOMJQn/CAyBS59x7pt47VpocmY2DYwP58nvp1NQWsO1z2XajCdjjN9ZkvCXhKFw4d9g6+fwyX3NxccP6MWDl6XxzfYSfvHKcpqabMaTMcZ/LEn4U9pMGHe5kyRW/qe5+PwxfbjjghG8u6qAe99f58cAjTE9XYC/A+jxLnoASrbBmz+BsF4w+GwArjkllW17qpj9aQ79eoVy1YkD/RunMaZHspaEvwWGwMwXIXEEvHI1FKwCQET4/cWjOHtEIr+fu5qP1u70c6DGmJ7IkkRnEBLtPMUuJBpemN4842nvMyhG9Y3mxpe+ISuv1M+BGmN6GksSnUVUH7j8ZagtcxJFjZMQwoIC+OcP0ukVFsSPnl1Cni0GaIw5hlqVJEQkQ0TWi0i2iNzWQp3pIrJGRFaLyIs+5X9xy9aKyMMiIm758SKyyj1mc3mP1nsMTH8OCtfCy1dCg3OvRGJkCM/8cCLVdY388JmvKa2q93Ogxpie4rBJQkS8wKPA+cBIYKaIjNyvzhDgduBkVR0F3OyWnwScDIwFRgMTgdPc3R4HrgWGuK+Mdjifrm/wWTD1Udj8Kbz5U2hqAmBoUiT/uOp4tuyu4pp/LaG6zu6hMMZ0vNa0JCYB2aqao6p1wBxg6n51rgUeVdViAFXd5ZYrEAIEAcFAILBTRPoAUaq6WJ2lT58Dph312XQX42Y4q8ZmvQof/La5+KTB8Tw4I42l24q54cVl1Dc2+TFIY0xP0JokkQxs9/mc65b5GgoMFZEvRGSxiGQAqOoiYAGQ777mqepad//cwxwTABGZJSKZIpJZWFjYmnPqHk75X5g0CxY9AosebS6+YEwf/jhtNB+t28UvX1lBo91sZ4zpQO11n0QATpfR6UAK8KmIjAHigRFuGcAHIvIdoNWjr6o6G5gNkJ6e3nN+I4pAxr1QsRPm/T+ISIIxlwJwxQkDKKtu4L731xEZEsAfp43GhnSMMR2hNUkiD+jn8znFLfOVC3ylqvXAZhHZwLdJY7GqVgCIyHvAicC/+TZxtHRM4/HCJbOhcje88RMIT4BBzpDO9acfR1lNPY8v3ERkSCC3nT/cz8EaY7qj1nQ3LQGGiEiqiAQBM4C5+9V5EychICLxON1POcA24DQRCRCRQJxB67Wqmg+Uichkd1bT94G32uOEup3AEJjxAsQNdmY8uTfbAfz6vGFcObk/T3yyiYc/2ujHII0x3dVhk4SqNgA3APOAtcArqrpaRO4WkSlutXlAkYiswRmDuEVVi4BXgU3AKmAFsEJV/+vu81PgKSDbrfNe+51WNxPaC658DYIj4flLnWU8cO7KvnvKaL47IZn7P9jAYwuz/RyoMaa7ka70XOX09HTNzMz0dxj+s2stPH2eMz7xo3kQFgtAY5Pyi1eW89byHdxxwQiuPXWQnwM1xnQmIrJUVdPbsq/dcd2VJI6AmXOgeCu8NAPqnfF/r0f42/fGceHYPtzz7lqe/nyznwM1xnQXliS6mgEnwf88Cdu/hlevgcYGAAK8Hh68LI2MUb25++01PLdoi1/DNMZ0D5YkuqKRU+H8v8D6d+DdX4HbZRjo9fDwzPGcMzKJ3721mscXbvJzoMaYrs6SRFd1wiznhrulz8CCe5qLgwI8PHbFBKam9eW+99fx53fX0pXGnYwxnYs9dKgrO+v3UFUEn/4VvEFw2q8Bp0XxwPQ0okMD+cenORRX1fGnS8YQ4LW/CYwxR8aSRFcmAhc95IxLLLgHPAHwnV8A4PEId00ZRUxYEA9/tJGy6gYenJFGSKDXz0EbY7oS+9Oyq/N4YOojMGY6fHQXfPFw8yYR4RfnDOV3F43k/dUF/OjZJVTUNvgxWGNMV2NJojvweGHa4zDqEmfV2EWP7bP5R6ekcv/0cXy1eQ9XPLmYPZV1fgrUGNPVWJLoLrwB8N0nYcTFMO92+PLv+2z+7oQU/nHl8awtKGf6PxaRX2pPuDPGHJ4lie7EGwiXPgMjp8H83zgD2j7OHpnEcz+axM7SGi59fBE5hRV+CtQY01VYkuhuvIHwP/+EsZfBx3+Ej/7QfB8FwORBcbw0azI19Y1874lFZOWV+jFYY0xnZ0miO/IGOGMUE74Pn/0fvPfr5segAoxOjuY/PzmRkEAvM2YvZnFOkR+DNcZ0ZpYkuiuPFy5+GE66Eb6eDW9cB431zZsHJUTw6vUn0js6hKuf/pr5qwv8GKwxprOyJNGdicA5f3Buulv1Crw0E+oqmzf3iQ7lletOZHjvSK57fimPLcy2u7ONMfuwJNHdiTg32F38MGz6CJ6bClV7mjfHhgcxZ9aJXDS2L395fz03vvQN1XWNfgzYGNOZWJLoKY6/GqY/B/kr4ekMKNzQvCk0yMvDM9L4dcYw3lmVz6VPfEleiU2RNcZYkuhZRlwMV70OlbvgH6fC2v82bxIRfnr6YP55dTrbiqqY8vfP+XrznkMczBjTE1iS6GkGngLXL4KkUfDyVc7d2T7jEGcOT+KNn51MdGgglz+5mBe+2urHYI0x/mZJoieK6gNX/xdGXOTcnf3uLfvMfBqcGMEbPzuZkwfHc8cbWdzxxirqGpoOcUBjTHfVqiQhIhkisl5EskXkthbqTBeRNSKyWkRedMvOEJHlPq8aEZnmbntWRDb7bEtrv9MyhxUUBt97zpkiu+RJeG4aVBQ2b44ODeTpH0zkutMG8cJX27jiqcUUlNb4MWBjjD/I4aY8iogX2ACcA+QCS4CZqrrGp84Q4BXgTFUtFpFEVd2133FigWwgRVWrRORZ4G1VfbW1waanp2tmZmZrq5vWWvEy/PfnEBbnDG6n7Pu89LeW53Hba6sIDfLyt+njOGNYop8CNca0hYgsVdX0w9c8UGtaEpOAbFXNUdU6YA4wdb861wKPqmoxwP4JwnUp8J6qVrUlUNOBxl0G18x3nkfxdAYs+ec+4xRT05L5742nkBgZzA+fWcKf31tLfaN1PxnTE7QmSSQD230+57plvoYCQ0XkCxFZLCIZBznODOCl/cruEZGVIvKAiAQf7MtFZJaIZIpIZmFh4cGqmPbQZxzMWgjHnQHv/ALevB5qv10AcHBiBG/+7GQuP6E///gkh+n/WERuseV7Y7q79hq4DgCGAKcDM4EnRSRm70YR6QOMAeb57Lb5Zm8AABmZSURBVHM7MByYCMQCtx7swKo6W1XTVTU9ISGhncI1BxUWCzNfhtP/H6yYA49MhO1LmjeHBHr50yVj+PvM8WzcWcEFD33GPFvOw5hurTVJIg/o5/M5xS3zlQvMVdV6Vd2MM4YxxGf7dOANVW2eQqOq+eqoBZ7B6dYy/ubxwOm3Ot1PAUHwr4tg8eP7LBB48bi+vH3jKQyIC+e6fy/lzrmr7S5tY7qp1iSJJcAQEUkVkSCcbqO5+9V5E6cVgYjE43Q/5fhsn8l+XU1u6wIREWAakNWG+E1H6TcJfvwRpJ4K79/mJIs9m5s3D4wP59XrT+SHJw/k2S+3cMb/LWTRJltN1pju5rBJQlUbgBtwuorWAq+o6moRuVtEprjV5gFFIrIGWADcoqpFACIyEKcl8sl+h35BRFYBq4B44I9HfzqmXYXHw+WvwNTHoGAVPH4yfP1kc6siOMDL7y8exX9+ciJhwV6ueGoxjy3MprHJFgk0prs47BTYzsSmwPpRaS7MvRE2fQyDz3YelRoW27y5oraBW19byTsr85mUGsvfvjeOfrFhfgzYGLNXR0+BNQaiU+DK1+HCv8HmT+Hh8ZD5TPNU2YjgAB6ZOZ6/XjqWtTvKyHjwU174aitN1qowpkuzJGFaTwQm/hiuXQC9x8DbN8PLVzYvPS4ifC+9H+//76mk9Y/hjjeymDF7Mdm77FnaxnRVliTMkes9Gr4/F869BzbMg8dPgpyFzZuTY0J5/poT+MulY1m/s5wLHv6MRxdk2w14xnRBliRM23g8cNINcO1HEBzpPMzo2YucAW6cVsX09H588ItTOWt4In+dt55pj37B6h2lfg7cGHMkLEmYo9NnHMz6BM6+C3athX+cBh/8DuqdxQATI0N4/MrjefyKCewsq2XKI19w93/XUFZTf5gDG2M6A5vdZNpP1R748Pew7DmIGwzn/RmGntu8uaSqjvveX8+cJduICw/i1xnDuXRCCh6P+DFoY7o/m91kOoewWJjyd7jyNRAPvPg9eO1aKHGW/ooJC+LP3x3D3J+dQv/YMH796kouefxLlm8v8XPgxpiWWEvCdIyGWvjkPlj0KHiD4dRfwcRrICgcgKYm5Y1v8rj3/XUUltfyPxNS+NV5Q+kTHernwI3pfo6mJWFJwnSsPZudqbI5CyG6H2T8GYZf5EynBcpr6nnk42ye+WILHg/8+JRBXHfaICJDAv0btzHdiCUJ0/lt/RLe+SXsWgPJx8Opv4ah5zUni+17qvjrvPXMXbGDuPAgbj5nKDMm9iPQaz2ixhwtSxKma2ish2+eh8/vh5Jt0CcNzrsHBp7SXGXF9hLueXctX2/ew6CEcG7NGM65I5MQscFtY9rKkoTpWhrrYeUrsOBPUJbrdD+dczfEHQeAqvLh2l38+b215BRWMqJPFDeeOZiMUb1tJpQxbWBJwnRN9dXOwPbnDzgD3eOvgEnXQdJIZ3NjE28t38FjC7PJKaxkTHI0vzh3KKcPTbCWhTFHwJKE6drKd8LCP8OKl6ChBoZmwBl3QJ+xADQ2KW9+k8f9H2wgr6SaUX2juP704zh/dB+81rIw5rAsSZjuoWoPLPknLPo71JQ6YxajLoFR06DXQOoamnhzeR5PLNxEzu5KjksI58Yzh3DR2D4E2AC3MS2yJGG6l+oS+ObfsPoNyFvqlKWeChc/DLGpNDYp72Xl8/ePslm/s5zU+HB+dsZgpqb1tdlQxhyEJQnTfRVvgazX4bP7oaEaRk6FE66HfhNpalLmryngoY+yWZtfRt/oEH50SiqXTexn91kY48OShOn+SnNh8eOw7N9QW+rca3HC9TAsAw2KYOH6Qp74ZBNfbd5DZHAA08YnM218MhP6x9ggt+nxLEmYnqO2whngXvw47NkEnkAYfgEc/0NIPY2VO8p46rPNzF9TQE19E+P6xfDDkwZywZg+BAVYV5TpmTo8SYhIBvAQ4AWeUtV7D1JnOnAnoMAKVb1cRM4AHvCpNhyYoapvikgqMAeIA5YCV6lq3aHisCRhmjU1wZbPYMP7TtKoLoZeqTBuJoydTmV4P15flsszX2whZ3cl8RHBXH5Cf644oT9JUSH+jt6YY6pDk4SIeIENwDlALrAEmKmqa3zqDAFeAc5U1WIRSVTVXfsdJxbIBlJUtUpEXgFeV9U5IvIETmJ5/FCxWJIwB1VfA2vnOoPdmz8DFPqfBONm0DRiKp/l1vOvL7ewYP0uBEgfGMuPTk7ltKEJhAZ5/R29MR2uo5PEicCdqnqe+/l2AFX9s0+dvwAbVPWpQxxnFnCaql4hTidxIdBbVRv2/46WWJIwh1WyHVa+DCvmQNFGCAiB4RfC2BlsjTqe11cV8erSXPJKqpvHLi6b2I9RfaNs7MJ0Wx2dJC4FMlT1x+7nq4ATVPUGnzpv4rQ2TsbpkrpTVd/f7zgfA/er6tsiEg8sVtXB7rZ+wHuqOvog3z8LmAXQv3//47du3dqW8zQ9jSrkLXO6orJedbqjAkJh4Mk0pJ7B8sDxvJATxjtZBdQ1NDEsKZJLJiQzLS2Z3tHWHWW6l86QJN4G6oHpQArwKTBGVUvc7X2AlUBfVa0/kiThy1oSpk0a6iBnAWz62Hnt3uCU90qlZvh3+bJuEP/cmsQXuXWIwOlDE5g5qT9nDE+0+y5Mt3A0SSKgFXXygH4+n1PcMl+5wFeqWg9sFpENwBCc8Qtwkscb7naAIiBGRAJUtaGFYxrTPgKCnGXJh7q9mSXbnWSxYg4hi+7nTJQzvUFUDTuVTwMm87etxzHr34XEhgdx8dg+XDi2L+kDetnigqZHak1LIgCnK+ksnF/kS4DLVXW1T50MnMHsq91WwjdAmqoWudsXA7er6gKfff4DvOYzcL1SVR87VCzWkjDtrrYcdnwDG+Y5g98l21DxUBKfzmdNo3hoZxq5DdFER0ZywZg+nD+6N+kDY23NKNOlHIspsBcAD+KMNzytqveIyN1ApqrOdQei/wZkAI3APao6x913IPAF0E9Vm3yOOQhnCmwsTlK5UlVrDxWHJQnToVShYCWs/S9snA/5KwGlwRvKstDJzCkdzZf1Q2mM7Mv5o3tzwZg+pPWLISTQZkiZzs1upjOmI+zeCFs+dxLH6jeheg8ARQFJvF83js8bRvC1N42zxw3mjOGJnHhcHNGhthyI6XwsSRjT0RobYGcWbFsEWz5Hsz9EGmpokACym/qyrimFjfQnuO9ohh5/Jt8ZN4zw4NYM+RnT8SxJGHOsNdRBXiZsmEfTztXU568muHIHAI0qFBDHzsiRBAw6ldTRk4lMHAAx/f0ctOmpOnp2kzFmfwFBMOAkGHASHiAYoKaUpoLV5C97lz25G0jZ8zWJKz91Jn8DRdGjCU2dRFi/cZA4ChJHQHCEH0/CmMOzloQxHaShoZH1G9ezevkiducs54TaRQyT7URITXMd7TUQSRwF0cnQfzIkjYaYARBoN/SZ9mPdTcZ0cqrKmvwyFq7byZo1WdTnr2Io2xkTmMvYoHwSmnYR0FDl1hYnWUy8BnqPgbjjILSXX+M3XZslCWO6mNKqej7dWMiC9bv4ZH0hJZXVjJbNnBxbxqlxZYwvX0hw8YZvdwiLg8BwiE5xnv2dNMpZ9TbuOIjq678TMV2CJQljurCmJmVlXilfZO9mwbpdZG4tRmhiTHAhGX0qODGmhCHeAiK8DbBnM+xcDfWV3x4gPAECwyA4EuKHQOppEJEEKHgCoM84iOztt/Mz/mdJwphuJL+0ms837mbZtmI+WV/IjlJnDCM5JpTJg+KYnBrDyXGV9GUX7FwDhWud5dJryyF/OZTnH3jQqGS3FZIGHi+ExEBsKjTWOc8UHzUNwuJtLKSbsiRhTDelqmzcVcGiTUUsznFexVXOEmjJMaGk9Yuhb0wIU8YlMzo5CgHYkwO1ZSAeqK+G7V87rY+ibGdxQ1WoK9/3i8QD2uS0SrxBgDhlCcNgyDlQtccZF0kY5rwieoPHFj/sKixJGNNDNDU5SWNvwlhXUE5ecTV1jU1O0ugfQ1pKDGn9YxjdN7rlhyrVV0PJNggIhsZ6+OZ5CAyFsh2gjc7zJZsaIGchVBQcuH9AiJM0xAOxg5y6e1fdiR3ktFi8gdBQ63xHnzSnleINgqoiiO7nzOgyx4QlCWN6sNKqet5Zlc8Xm3azYnsJucXVAHg9wtCkSMYkRzEmOZpRydGM7BN1ZGtNNTVB1W4IjoKaUti9HgrXQ/EW5xkdDbVOYvF4nVdTIxSug8rCwx87MNxJMk0NEJHojJ8MPhuCwpxnmYdEu68o59/QWAiPd5JZyXYnnsY6Z9/+Jzrf2VjvdK157RYwX5YkjDHNCstrWZlbwvLtzisrr7S5i8rrEYYkRjCqbzRjkqMYnRxN7+gQ+kSHtt/KtqpQ4T69OCDISSaF651f6A11zgB74Vqo3O22PgQqdjr1tn7pJI2gcKfL7Ns1QVvPG+Ts7w123ofHQ0q6k4QaapyWTERvSBoJFYVOWUWB07qJGeDMHksY7iTAxjonQVUVOTPMuujTCy1JGGNapKrsKK0hK6+UrLxSVrn/7q6oa64THuRlVHI041KiGZMSw9jkaAbEhR37R7qqOonB43XHTiqdFkNNifOLuqoI6qqcQfiwWOcX/+4NzphLWLzTtbVnk1Onsc55FW+FglXOcQNDnEH78nyo97kvJTzBbf0c5PdhUATUVThTjhvrnAkCSaOcRBTT33mF9nISizZBTRmExjhJr3K3k6hiU50WUGCYc257Njtddk0Nzv51FU79+mrnvMPinO66ukooy3NmqyVPcL6zDSxJGGOOiKqys6yWNfml7CyrZV1+GStyS1mTX0Zdg/PXe1RIAGNTYhiTEs3Y5GhGJ0cTFRJIVGhA138eeGMDlGx17jHxBHw7flKyHbZ+DuU7nYQjHmfAP6qvs3R8cITzS3/PZmfwv2R78+rAHe6nX0Hi8Dbtams3GWOOiIjQOzrkgOd51zc2sb6gnFV5pazMLWVlbglPfppDQ9O3f0wmRgYzJjmafrFh9I0JYWBcOGNSoukdFdJ1koc3wLkR0VdAMMQPdl5HorbCSRQFWc4x9o7fhPVyWjd1FVCWDw3VTkuhodZpPTTVAwKlue6YSy+npSHidNdpo/Nc9qi+TndcbGq7nf6RsJaEMeaQauobWVdQzpodZVTWNrA2v4w1+WXkFVdTXtvQXC8+IpjjEsJJ7hVKv15hjHa7rPrGhBJhy6b7lbUkjDEdJiTQS1q/GNL6xRywrbS6nk2FFazKdVoeW4sqWbSpiDfL8vBpfJAUFczgxAgGJ0RwnPtvXEQwA+PDCA6wJ/t1ZpYkjDFtFh0ayIT+vZjQf98FCKvrGlmTX0peSQ3b91SxqbCCTYWVvLYsjwqf1keQ10Pv6BASIoNJiAimb0woo5OjGBgfzoDYMOIigo/1KZn9tCpJiEgG8BDOM66fUtV7D1JnOnAnzvSAFap6uVveH3gK6Oduu0BVt4jIs8BpQKl7iB+o6vKjOhtjTKcQGuTl+AGxHD9g3/K9A+abCivYXVHLmh1lFJTVUFjulC3csIua+m+nvSZEBjMgNoz4iGCG9Y5kUEI4Kb1CSekVRkJEMJ72mrZrWnTYJCEiXuBR4BwgF1giInNVdY1PnSHA7cDJqlosIok+h3gOuEdVPxCRCMB34vMtqvpqe5yIMabz23/AfGravnddNzYp2bsqyCupYm1+OduKqti8u5INu8qZt6YA3yHU4AAP/WPD6B8bRr/YMAbEhZHSK4zwYC9jkqMJDwqwJNIOWtOSmARkq2oOgIjMAaYCa3zqXAs8qqrFAKq6y607EghQ1Q/c8op2jN0Y0814PcKw3pEM6x3JmcOT9tlWVddAXnE1ucXVbC+uYvueKrbtqWJrURWLc4qorGvcp35wgIcxydEEej0MTYpgeJ8oBsWH0y82jKSokPa7ebCba02SSAa2+3zOBU7Yr85QABH5AqdL6k5Vfd8tLxGR14FU4EPgNlXd+1/zHhH5HfCRW17b5jMxxnRrYUEBDEmKZEhS5AHbVJU9lXXkFldTUl1PVl4pBaU1rCsoo7q+kVeX5u6TRAK9Qt+YUJIiQxCBiQNjSYwKJikqhOG9I+nXK8xaIa72GrgOAIYApwMpwKciMsYt/w4wHtgGvAz8APgnTvdUARAEzAZuBe7e/8AiMguYBdC/vz1I3hhzIBEhLiK4eaD7tKEJ+2xvalLySqrZUlTJ9j3V5BZXsb24ml1lNVTVNfLIgux96ocFeRmaFEl8RBBJUSFEhAQwNDGSIUkRxIYHkdIr7Jidm7+1Jknk4Qw675XilvnKBb5S1Xpgs4hswEkaucByn66qN4HJwD9Vde+i97Ui8gzwq4N9uarOxkkipKend52bOowxnYbHI/Rzxy4Opr6xiZKqenKLq1hfUM66gnLWFZSRV1LD0q3FVNY2Utf47XCqM4AeRm+39bH31TsqhKQoJ1l1l+6s1iSJJcAQEUnFSQ4zgMv3q/MmMBN4RkTicbqZcoASIEZEElS1EDgTyAQQkT6qmi/OLZrTgKz2OCFjjDlSgV6PMw03Mpjx/Q98nnhjk5JTWEHO7kq2FlWydGsx+aU1rC8oo7C8dp97QsAZW0mICCbJJ4n0jg5hRJ9IIoIDGdEnkpBAL4Hezv9MjsMmCVVtEJEbgHk44w1Pq+pqEbkbyFTVue62c0VkDdCIM2upCEBEfgV85CaDpcCT7qFfEJEEQIDlwE/a+dyMMaZdeD3S4nhIQ2MTRZV1FJTWsLOshp3ltex03xeU1bC1qIqvt+yhxF2Jdy8RGNE7ivjIYOLDgwgN8uIRYWjvSEb1jSIhIpjQIC9x4UF+Xe7EluUwxphjoKqugZW5pVTVNbAqt4yahkay8kopq2lgV1kN1fWNNDbqPkudAMSEBZIQEczs76eTGn/sV4G1O66NMeYYCAsKYPKgOIADpvfu5buse2l1PRU1DWQXVlBcWUd4sH+WL7EkYYwxnYSIkBwTSnJMqL9Dadb5R02MMcb4jSUJY4wxLbIkYYwxpkWWJIwxxrTIkoQxxpgWWZIwxhjTIksSxhhjWmRJwhhjTIu61LIcIlIIbG3j7vHA7nYM51jpinF3xZiha8bdFWOGrhl3V4wZnLjDVTXhsDUPoksliaMhIpltXbvEn7pi3F0xZuiacXfFmKFrxt0VY4ajj9u6m4wxxrTIkoQxxpgW9aQkMdvfAbRRV4y7K8YMXTPurhgzdM24u2LMcJRx95gxCWOMMUeuJ7UkjDHGHCFLEsYYY1rUI5KEiGSIyHoRyRaR2/wdT0tEZIuIrBKR5SKS6ZbFisgHIrLR/ffAp7Qf+zifFpFdIpLlU3bQOMXxsHvtV4rIhE4U850ikude7+UicoHPttvdmNeLyHn+iNmNo5+ILBCRNSKyWkRucss77fU+RMyd+nqLSIiIfC0iK9y473LLU0XkKze+l0UkyC0Pdj9nu9sHdqKYnxWRzT7XOs0tP/KfD1Xt1i/AC2wCBgFBwApgpL/jaiHWLUD8fmV/AW5z398G3NcJ4jwVmABkHS5O4ALgPUCAycBXnSjmO4FfHaTuSPfnJBhIdX9+vH6Kuw8wwX0fCWxw4+u01/sQMXfq6+1eswj3fSDwlXsNXwFmuOVPANe7738KPOG+nwG83Ilifha49CD1j/jnoye0JCYB2aqao6p1wBxgqp9jOhJTgX+57/8FTPNjLACo6qfAnv2KW4pzKvCcOhYDMSLS59hE+q0WYm7JVGCOqtaq6mYgG+fn6JhT1XxVXea+LwfWAsl04ut9iJhb0imut3vNKtyPge5LgTOBV93y/a/13v8GrwJniYgco3CBQ8bckiP++egJSSIZ2O7zOZdD/8D6kwLzRWSpiMxyy5JUNd99XwAc/Anq/tdSnJ39+t/gNruf9unK65Qxu90Z43H+WuwS13u/mKGTX28R8YrIcmAX8AFOq6ZEVRsOEltz3O72UiDu2EZ8YMyquvda3+Ne6wdEJHj/mF2HvdY9IUl0Jaeo6gTgfOBnInKq70Z12oudfs5yV4kTeBw4DkgD8oG/+TeclolIBPAacLOqlvlu66zX+yAxd/rrraqNqpoGpOC0Zob7OaTD2j9mERkN3I4T+0QgFri1rcfvCUkiD+jn8znFLet0VDXP/XcX8AbOD+nOvc1B999d/ovwkFqKs9Nef1Xd6f4P1gQ8ybddHJ0qZhEJxPll+4Kqvu4Wd+rrfbCYu8r1BlDVEmABcCJOl0yAu8k3tua43e3RQNExDrWZT8wZbpefqmot8AxHca17QpJYAgxxZygE4QwwzfVzTAcQkXARidz7HjgXyMKJ9Wq32tXAW/6J8LBainMu8H13VsVkoNSnm8Sv9uuLvQTneoMT8wx39koqMAT4+ljHB85sFOCfwFpVvd9nU6e93i3F3Nmvt4gkiEiM+z4UOAdnPGUBcKlbbf9rvfe/waXAx26r7phpIeZ1Pn9ACM4Yiu+1PrKfj2M9Gu+PF86I/gac/sU7/B1PCzEOwpnhsQJYvTdOnD7Oj4CNwIdAbCeI9SWc7oJ6nD7Na1qKE2cWxaPutV8FpHeimP/txrTS/Z+nj0/9O9yY1wPn+/Fan4LTlbQSWO6+LujM1/sQMXfq6w2MBb5x48sCfueWD8JJWtnAf4BgtzzE/Zztbh/UiWL+2L3WWcDzfDsD6oh/PmxZDmOMMS3qCd1Nxhhj2siShDHGmBZZkjDGGNMiSxLGGGNaZEnCGGNMiyxJGGOMaZElCWOMMS36/2mNDeQCzAEHAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyyaml h5py\n",
        "import os\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "model.save('0.604.h5')"
      ],
      "metadata": {
        "id": "ke22j7CJmkx-"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#train,val,test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "\n",
        "import tensorflow as tf\n",
        "input_shape = [X_train.shape[1]]\n",
        "model = tf.keras.models.Sequential([\n",
        "    #tf.keras.layers.Flatten(input_shape = input_shape),\n",
        "    #tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(32,activation='relu'),\n",
        "    tf.keras.layers.Dense(32,activation='relu'),\n",
        "    #tf.keras.layers.Dense(10,activation='relu'),\n",
        "    #tf.keras.layers.Dense(4,activation='relu'),\n",
        "    #tf.keras.layers.Dense(10,activation='relu'),\n",
        "    #tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid'),])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['binary_accuracy'])\n",
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(patience=10)\n",
        "hist = model.fit(X_train, y_train, epochs=1000, validation_data=(X_val,y_val), callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbSyS6KgE2qF",
        "outputId": "fec8e88a-aa31-47a2-a54e-03cdc4e5dbc1"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5230, 20) (5230, 1)\n",
            "(1744, 20) (1744, 1)\n",
            "(1744, 20) (1744, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 5230 samples, validate on 1744 samples\n",
            "Epoch 1/1000\n",
            "5120/5230 [============================>.] - ETA: 0s - loss: 0.6958 - binary_accuracy: 0.4963"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5230/5230 [==============================] - 1s 254us/sample - loss: 0.6957 - binary_accuracy: 0.4977 - val_loss: 0.6924 - val_binary_accuracy: 0.5109\n",
            "Epoch 2/1000\n",
            "5230/5230 [==============================] - 0s 68us/sample - loss: 0.6912 - binary_accuracy: 0.5298 - val_loss: 0.6887 - val_binary_accuracy: 0.5482\n",
            "Epoch 3/1000\n",
            "5230/5230 [==============================] - 0s 65us/sample - loss: 0.6878 - binary_accuracy: 0.5623 - val_loss: 0.6857 - val_binary_accuracy: 0.5545\n",
            "Epoch 4/1000\n",
            "5230/5230 [==============================] - 0s 67us/sample - loss: 0.6845 - binary_accuracy: 0.5771 - val_loss: 0.6827 - val_binary_accuracy: 0.5614\n",
            "Epoch 5/1000\n",
            "5230/5230 [==============================] - 0s 65us/sample - loss: 0.6813 - binary_accuracy: 0.5836 - val_loss: 0.6796 - val_binary_accuracy: 0.5751\n",
            "Epoch 6/1000\n",
            "5230/5230 [==============================] - 0s 64us/sample - loss: 0.6787 - binary_accuracy: 0.5843 - val_loss: 0.6775 - val_binary_accuracy: 0.5791\n",
            "Epoch 7/1000\n",
            "5230/5230 [==============================] - 0s 67us/sample - loss: 0.6765 - binary_accuracy: 0.5868 - val_loss: 0.6756 - val_binary_accuracy: 0.5803\n",
            "Epoch 8/1000\n",
            "5230/5230 [==============================] - 0s 67us/sample - loss: 0.6748 - binary_accuracy: 0.5889 - val_loss: 0.6741 - val_binary_accuracy: 0.5757\n",
            "Epoch 9/1000\n",
            "5230/5230 [==============================] - 0s 69us/sample - loss: 0.6730 - binary_accuracy: 0.5945 - val_loss: 0.6725 - val_binary_accuracy: 0.5854\n",
            "Epoch 10/1000\n",
            "5230/5230 [==============================] - 0s 71us/sample - loss: 0.6714 - binary_accuracy: 0.5943 - val_loss: 0.6714 - val_binary_accuracy: 0.5872\n",
            "Epoch 11/1000\n",
            "5230/5230 [==============================] - 0s 67us/sample - loss: 0.6703 - binary_accuracy: 0.5977 - val_loss: 0.6704 - val_binary_accuracy: 0.5877\n",
            "Epoch 12/1000\n",
            "5230/5230 [==============================] - 0s 66us/sample - loss: 0.6694 - binary_accuracy: 0.5943 - val_loss: 0.6695 - val_binary_accuracy: 0.5894\n",
            "Epoch 13/1000\n",
            "5230/5230 [==============================] - 0s 69us/sample - loss: 0.6680 - binary_accuracy: 0.5967 - val_loss: 0.6689 - val_binary_accuracy: 0.5906\n",
            "Epoch 14/1000\n",
            "5230/5230 [==============================] - 0s 68us/sample - loss: 0.6673 - binary_accuracy: 0.6008 - val_loss: 0.6684 - val_binary_accuracy: 0.5877\n",
            "Epoch 15/1000\n",
            "5230/5230 [==============================] - 0s 70us/sample - loss: 0.6664 - binary_accuracy: 0.5954 - val_loss: 0.6679 - val_binary_accuracy: 0.5877\n",
            "Epoch 16/1000\n",
            "5230/5230 [==============================] - 0s 70us/sample - loss: 0.6659 - binary_accuracy: 0.5998 - val_loss: 0.6677 - val_binary_accuracy: 0.5837\n",
            "Epoch 17/1000\n",
            "5230/5230 [==============================] - 0s 71us/sample - loss: 0.6653 - binary_accuracy: 0.6057 - val_loss: 0.6675 - val_binary_accuracy: 0.5894\n",
            "Epoch 18/1000\n",
            "5230/5230 [==============================] - 0s 76us/sample - loss: 0.6650 - binary_accuracy: 0.6034 - val_loss: 0.6669 - val_binary_accuracy: 0.5940\n",
            "Epoch 19/1000\n",
            "5230/5230 [==============================] - 0s 69us/sample - loss: 0.6643 - binary_accuracy: 0.6046 - val_loss: 0.6672 - val_binary_accuracy: 0.5843\n",
            "Epoch 20/1000\n",
            "5230/5230 [==============================] - 0s 71us/sample - loss: 0.6643 - binary_accuracy: 0.6054 - val_loss: 0.6668 - val_binary_accuracy: 0.5849\n",
            "Epoch 21/1000\n",
            "5230/5230 [==============================] - 0s 74us/sample - loss: 0.6639 - binary_accuracy: 0.6073 - val_loss: 0.6665 - val_binary_accuracy: 0.5900\n",
            "Epoch 22/1000\n",
            "5230/5230 [==============================] - 0s 69us/sample - loss: 0.6636 - binary_accuracy: 0.6075 - val_loss: 0.6665 - val_binary_accuracy: 0.5894\n",
            "Epoch 23/1000\n",
            "5230/5230 [==============================] - 0s 68us/sample - loss: 0.6633 - binary_accuracy: 0.6031 - val_loss: 0.6665 - val_binary_accuracy: 0.5917\n",
            "Epoch 24/1000\n",
            "5230/5230 [==============================] - 0s 80us/sample - loss: 0.6632 - binary_accuracy: 0.6082 - val_loss: 0.6663 - val_binary_accuracy: 0.5866\n",
            "Epoch 25/1000\n",
            "5230/5230 [==============================] - 0s 69us/sample - loss: 0.6627 - binary_accuracy: 0.6061 - val_loss: 0.6664 - val_binary_accuracy: 0.5929\n",
            "Epoch 26/1000\n",
            "5230/5230 [==============================] - 0s 77us/sample - loss: 0.6626 - binary_accuracy: 0.6054 - val_loss: 0.6663 - val_binary_accuracy: 0.5837\n",
            "Epoch 27/1000\n",
            "5230/5230 [==============================] - 0s 68us/sample - loss: 0.6625 - binary_accuracy: 0.6084 - val_loss: 0.6662 - val_binary_accuracy: 0.5854\n",
            "Epoch 28/1000\n",
            "5230/5230 [==============================] - 0s 68us/sample - loss: 0.6623 - binary_accuracy: 0.6071 - val_loss: 0.6661 - val_binary_accuracy: 0.5917\n",
            "Epoch 29/1000\n",
            "5230/5230 [==============================] - 0s 68us/sample - loss: 0.6621 - binary_accuracy: 0.6076 - val_loss: 0.6664 - val_binary_accuracy: 0.5837\n",
            "Epoch 30/1000\n",
            "5230/5230 [==============================] - 0s 73us/sample - loss: 0.6622 - binary_accuracy: 0.6042 - val_loss: 0.6662 - val_binary_accuracy: 0.5820\n",
            "Epoch 31/1000\n",
            "5230/5230 [==============================] - 0s 69us/sample - loss: 0.6618 - binary_accuracy: 0.6046 - val_loss: 0.6662 - val_binary_accuracy: 0.5917\n",
            "Epoch 32/1000\n",
            "5230/5230 [==============================] - 0s 71us/sample - loss: 0.6620 - binary_accuracy: 0.6076 - val_loss: 0.6662 - val_binary_accuracy: 0.5935\n",
            "Epoch 33/1000\n",
            "5230/5230 [==============================] - 0s 78us/sample - loss: 0.6617 - binary_accuracy: 0.6065 - val_loss: 0.6667 - val_binary_accuracy: 0.5900\n",
            "Epoch 34/1000\n",
            "5230/5230 [==============================] - 0s 73us/sample - loss: 0.6616 - binary_accuracy: 0.6059 - val_loss: 0.6663 - val_binary_accuracy: 0.5808\n",
            "Epoch 35/1000\n",
            "5230/5230 [==============================] - 0s 77us/sample - loss: 0.6614 - binary_accuracy: 0.6033 - val_loss: 0.6662 - val_binary_accuracy: 0.5872\n",
            "Epoch 36/1000\n",
            "5230/5230 [==============================] - 0s 74us/sample - loss: 0.6614 - binary_accuracy: 0.6080 - val_loss: 0.6661 - val_binary_accuracy: 0.5894\n",
            "Epoch 37/1000\n",
            "5230/5230 [==============================] - 0s 91us/sample - loss: 0.6612 - binary_accuracy: 0.6036 - val_loss: 0.6662 - val_binary_accuracy: 0.5958\n",
            "Epoch 38/1000\n",
            "5230/5230 [==============================] - 1s 160us/sample - loss: 0.6613 - binary_accuracy: 0.6052 - val_loss: 0.6665 - val_binary_accuracy: 0.5900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('accuracy:',performance[1], 'loss:', performance[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcuO42HnFzbj",
        "outputId": "4ef7410f-1ae2-4896-fee8-3741677418f2"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.5888761 loss: 0.6674850391685416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "plt.plot(hist.history['binary_accuracy'])\n",
        "plt.plot(hist.history['val_binary_accuracy'])\n",
        "plt.title('Accuracy')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "1rMU6ZvZF1Xl",
        "outputId": "b940d8c1-4afa-48da-ed8f-70cf9a2e6f1a"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3yUVdbA8d9JIwkJkISAQIDQEQWRpggoWLFhQRErrAq6yqpreRfftW/R9d112bUjiohiYy2ouIAurIUapHcICQkllYT0et8/7gSGkDJJJslk5nw/n3wy88zzzHNnIGfunHuee8UYg1JKKe/l19wNUEop1bg00CullJfTQK+UUl5OA71SSnk5DfRKKeXlNNArpZSX00CvlFJeTgO98ioiskJEjopIq+Zui1KeQgO98hoiEguMAQwwoQnPG9BU51KqPjTQK29yB7AaeBeYUrFRRLqKyGcikiYiGSLyitNj00Rkh4jkiMh2ERni2G5EpLfTfu+KyB8dt8eKSLKI/E5EjgBzRSRCRL52nOOo43aM0/GRIjJXRA45Hv/CsX2riFzttF+giKSLyNmN9i4pn6OBXnmTO4APHD+XiUhHEfEHvgYSgVigC/ARgIjcCDzjOK4N9ltAhovnOg2IBLoD07F/S3Md97sBBcArTvvPB0KBM4AOwN8d298DbnPa7wrgsDFmg4vtUKpWonPdKG8gIqOB5UAnY0y6iOwE3sT28Bc5tpdWOmYJsNgY848qns8AfYwxex333wWSjTFPiMhYYCnQxhhTWE17BgPLjTERItIJOAhEGWOOVtqvM7AL6GKMOSYiC4G1xpgX6/1mKFWJ9uiVt5gCLDXGpDvuL3Bs6wokVg7yDl2BffU8X5pzkBeRUBF5U0QSReQY8APQzvGNoiuQWTnIAxhjDgE/AxNFpB1wOfYbiVJuo4NIqsUTkRBgEuDvyJkDtALaASlANxEJqCLYJwG9qnnafGyqpcJpQLLT/cpfhR8B+gHnGGOOOHr0GwBxnCdSRNoZY7KqONc84G7s3+MqY8zB6l+tUnWnPXrlDa4FyoABwGDHz+nAj47HDgMviEhrEQkWkVGO4+YAj4rIULF6i0h3x2MbgVtExF9ExgMX1NKGcGxePktEIoGnKx4wxhwGvgVecwzaBorI+U7HfgEMAR7E5uyVcisN9MobTAHmGmMOGGOOVPxgB0NvBq4GegMHsL3ymwCMMZ8Cf8KmeXKwATfS8ZwPOo7LAm51PFaTWUAIkI4dF/h3pcdvB0qAnUAq8FDFA8aYAuBfQA/gszq+dqVqpYOxSnkAEXkK6GuMua3WnZWqI83RK9XMHKmeu7C9fqXcTlM3SjUjEZmGHaz91hjzQ3O3R3knTd0opZSX0x69Ukp5OY/L0bdv397ExsY2dzOUUqpFWb9+fboxJrqqxzwu0MfGxhIXF9fczVBKqRZFRBKre0xTN0op5eU00CullJfTQK+UUl7O43L0VSkpKSE5OZnCwipnhPUqwcHBxMTEEBgY2NxNUUp5iRYR6JOTkwkPDyc2NhYRae7mNBpjDBkZGSQnJ9OjR4/mbo5Syku0iNRNYWEhUVFRXh3kAUSEqKgon/jmopRqOi0i0ANeH+Qr+MrrVEo1nRYT6JVSpzpWWEJhSVmjPX9WfjHzVibw8950ikvLG+08qnG1iBy9J8jKymLBggXcd999dTruiiuuYMGCBbRr166RWqZ8VXxaLje+sQoD3DGyO3eMjCWydZDbnn/Z9hT+9/MtpOUUAdA6yJ/Rfdozrl8HxvXvQMc2wbU+hzGG9Nxi2oQE0CrA321tqyynsISQQH8C/Jun7xqflsszX23nnvN7Mqp3+2ZpQ0000LsoKyuL11577ZRAX1paSkBA9W/j4sWLG7tpygMZY1iXcJR1CZkUFJeRX1xGQUkZBcWlFJTY+4UlZQQH+vPshDPoGR1Wp+dPzSlkyty1AAzu2o5Z3+3hjf/u44ahMdw9uiex7VvXu+1Z+cU8s2gbX2w8RP/Twnn91iFk5Zfwn12pLN+ZypJtKQAM6NSGcf2jGduvAwF+QvLRAsdP/vHfB7MKKCwpp3PbYF6+ZQhDu0fUu11VKSot4+Xv9/L6f/cREujPsNgIzu0ZxTk9IhnYpW2TBP4DGfnc8tYajhwrZHV8Bq/dMoSLB3Rs9PPWhcfNXjls2DBTeQqEHTt2cPrppzdTi6zJkyfz5Zdf0q9fPwIDAwkODiYiIoKdO3eye/durr32WpKSkigsLOTBBx9k+vTpwIkpHXJzc7n88ssZPXo0K1eupEuXLnz55ZeEhIScci5PeL2qfnKLSvl8w0HeX5XIrpQcAPwEQoMCCA70JzTI/lTc3nH4GP5+frx/9wj6n9bG5XNMnr2Kfal5fDT9XM7q2o49KTm89WM8X2w4REl5OePPOI3p5/fk7G51C6xLth3h959vJSu/mPvH9eb+cb0JCjgRLI0x7ErJYfnONJbvTGX9gaOUlZ8cQyJCA4mJCKVLuxBiIkLo2CaY91YncDirkMcu68e0MT3x82v4WNTm5Cwe+3Qzu1JyuGZwZ8KDA1gdn8ne1FzAfgMZFhvJOT0jObdnFAM6tSE40L3fKg5lFTDpzVXkFpXy+q1DeeHbHWw7dIxZkwdz1aDObj1XbURkvTFmWJWPtbRA/+xX29h+6JhbzzmgcxuevvqMGvdJSEjgqquuYuvWraxYsYIrr7ySrVu3Hi+DzMzMJDIykoKCAoYPH85///tfoqKiTgr0vXv3Ji4ujsGDBzNp0iQmTJjAbbeduqCQBvqWZ3dKDu+vTuSzXw6SW1TKGZ3bcMfI7lwxsBNhrQKqHWTfm5rDrXPWUFRaznt3jmBQTM0pvuLScu6at46V+zKYM2UY4/p1OOnx1GOFzF2ZwPurE8kpLGVEbCQ3De9K/07h9IoOqzbQHc0r5ulF21i06RCnd2rDX28cxBmd29b6urPzS1gVn0Ggv9jgHhFCWKtTv+FmF5Qw81+b+XbrEcb1i+ZvkwbXO81UVFrGP77bw5s/xNM+LIjnrx/Ihf1P9KDTcopYsz+DNfGZrI7PYI8j8ANEh7ciJiKEmIhQx+8Tt7tGhJ70oVab1GOFTHpzFRm5xSyYdi4DY9qSU1jCne+uY33iUf4ycRA3Dutar9dYHzUFek3d1NOIESNOqnX/5z//yeeffw5AUlISe/bsISoq6qRjevToweDBgwEYOnQoCQkJTdZeX7MmPoOP1yVx+8jude7VuqqkrJyl21KYvzqB1fGZBPn7cdWgTtw2sjtnd23nUgVV7w7hfHrPedwyZzW3vLWGub8azvDYyCr3NcYw81+b+XFPOi/eMOiUIA/QoU0wvxvfn/vH9ebjdUm889N+Hvl0E2C/WXSLDKV3h3D6dgyjT8cw+nQIJykznye/3EpWfgm/vbgvvx7by+WA1zY0kPFnnlb7fiGBvHbrEOavTuSPX+/gin/8yMu3nF3ta63OpqQsHv10E3tSc5k0LIbfXzmAtiEnX1wYHd6KqwZ1Pt6jTsspYl2C7ekfPFpAclY+m5Oz+PfWw5SUnejotg8L4tFL+3HjsK741/KNIyO3iFvnrCE1p4j5d41gYIz9UAwPDmTenSO4Z/56Hlu4mcKSMm4fGVun19gYWlygr63n3VRatz6RA12xYgXfffcdq1atIjQ0lLFjx1ZZC9+qVavjt/39/SkoKGiStvqa5KP53PP+erLyS/hsw0Eu6BvNgxf3YUg9A35pWTmJmfnsScllT0oOe1Jz2Z2SQ3x6HsWl5cREhDDz8v7cODSGqLBWtT9hJd2iQvn03pHc+tYa7nh7LW/dMYzRfU4d0HtxyS4+23CQRy7py6RaeophrQK4a3QPpozsTnx6HrtTcmz7U+3vFbtSKXVKuZzRuQ3v3XkOAzq7lj6qDxHhjpGxDOkWwf0LfmHy7NU8cmlf7j2/V62pnMKSMmZ9t4fZP+yjY5tg3v3VcMZW8UFXlejwVlwxsNMp28vKDak5hSQfLSApM58Faw4w87MtvL8mkWeuPoNh1XwIZeeXcPvbazmQmc+7vxrB0O4n7xcaFMBbdwxjxoINPPnlNvKLy7jngl7Vtq+83BCXeJTFWw4T4Cc8cdUAl15XXbS4QN9cwsPDycnJqfKx7OxsIiIiCA0NZefOnaxevbqJW6cqFJWWcd8Hv1BWZvj6N6P5cU86s3/Yx/WvreT8vtE8eFGfGgcEjTHsT89jdXwm6xIy2XH4GPFpeRSXnSgtjIkIoU+HMM7vG825PSO5oG+HWnuAtenUNoSP7xnJ7W+v4c55604Z0Ju3MoHXV+zj1nO6MePC3i4/b4C/H307htO3Y/hJ20vKyklIz2NPai5FpWVcNagzgU1UsXJml7Z8/ZvRzPxsCy/+exdr4jP5y8RBAKTnFpGZV0xmXjEZecVkOO6v3Z9JfHoek4d35X+vPJ02wQ2fIsTfT+jUNoRObUMYHhvJdWd3YdGmQ7zw7U5ueGMVE87qzONX9KdT2xPjaDmFJdwxdy17U3N5a8owRvaKqvK5gwP9ef22ITz8ySae/3YnecVl/PbiPse/5ZWVG+ISMlm85TDfbj1Cak4RQQH2G2Fj0EDvoqioKEaNGsWZZ55JSEgIHTue+CMcP348b7zxBqeffjr9+vXj3HPPbcaW+rZnv9rO5uRs3rx9KGd2acuZXdpyx8juvLcqkbd+jGfi6ysZ06c9D13ch6HdIzHGEJ+ex+r4EzndVEc5YXR4KwZ2acsF/aLp40h39IoOo3UVOWh3iA5vxUfTz2XKO2u59/31xwf0vt1ymGe+2sYlAzry3DVnuuWiukB/P/p0DKdPpQ+AphIeHMgrN5/NyJ5RPPf1ds59/vsq9/P3EyJbB9G5XQjz7hzBBX2rXFfDLUSEawZ34ZIBHXljxT7e+CGeZdtTuG9sL6ad35NyY7jz3XVsO5jN67cNrbUtgf5+zLppMCGBfvzz+z0UFJdy0ekdjwf3tJwiWgX4MbZfNFcM7MRFp3escnzDLa+tpQ3G+gJfe73usnB9Mo9+uol7L+jFzMv7n/J4XlEp81cnMvuHeDLzijkrpi2HsguP14l3CG/FuT2jHD+R9GjfulmuVM4pLOGud+OIS8xk2piezF2ZwMAubfng7nPcXjXiCXYeOcZ/dqbSLiSIyNZBRIU5frcOok1woFsqdOojKTOfPy/ewbdbjxATEUKH8FZsTMri5ZuHcGUdet7l5Ybnvt7OuysTAGgV4Me4fh24YlAnLuzfwW3B3auqbnyBr71ed9h2KJvrX1vJkG4RzL9rRI3103lFpby/OpFFmw7Ru0PY8eAeGxXqMVNQFBSXMX1+HD/uSadXdGsW3nseEW68GEq5buW+dJ5dtJ3dqTn87cazuH5ITJ2fwxjDp3HJhAT5c2H/Do3yrVADfQvja6+3obLzS7j6lZ8oLi3n6wdG074eA6KeqKi0jPdXH+CKgaedlCdWTa+0rJzUnCI6t/Pcfwctr1Req7zc8PAnGzmUVcDH94z0miAP0CrAn7tG63TVniDA38+jg3xtXBpmF5HxIrJLRPaKyMxq9pkkIttFZJuILHDaPkVE9jh+prir4UoBvLZiL9/vTOWJK093++X1SnmLWgO9iPgDrwKXAwOAm0VkQKV9+gCPA6OMMWcADzm2RwJPA+cAI4CnRUT/Gn3ctkPZTJ69ip/3pjfoeX7ck8bflu1mwlmdmXJerHsap5QXcqVHPwLYa4yJN8YUAx8B11TaZxrwqjHmKIAxJtWx/TJgmTEm0/HYMmC8e5quWqIVu1KZ9MYqVsdncu/89ew6UvW1CbU5mFXAAx9uoE+HMF6YONBjBlGV8kSuBPouQJLT/WTHNmd9gb4i8rOIrBaR8XU4FhGZLiJxIhKXlpbmeuubUMXslfUxa9Ys8vPz3dyiluejtQe4a14c3aNa8/l95xES5M+d764j9VjdVtRKzSnkV3PXUlJmeOO2oYQG6VCTUjVx16VwAUAfYCxwM/CWiLg8AbsxZrYxZpgxZlh0dONdENEQGujrzxjD/y3ZyczPtjC6d3s+uXckZ3eL4J2pwzmaX8zd78WRX1zq0nMdzCpg0hurSD5awOw7htZ5el+lfJErXaGDgPPEGjGObc6SgTXGmBJgv4jsxgb+g9jg73zsivo2tjnNnDmTffv2MXjwYC655BI6dOjAJ598QlFREddddx3PPvsseXl5TJo0ieTkZMrKynjyySdJSUnh0KFDjBs3jvbt27N8+fLmfilNqqi0jP9ZuJkvNx7i5hFd+cM1Zx6vcT+zS1tevvlspr0Xx4MfbeSN24bWOJVAQnoet85Zw7HCEubfdeocI0qpqrkS6NcBfUSkBzZwTwZuqbTPF9ie/FwRaY9N5cQD+4A/Ow3AXoodtK2/b2fCkS0NeopTnDYQLn+hxl1eeOEFtm7dysaNG1m6dCkLFy5k7dq1GGOYMGECP/zwA2lpaXTu3JlvvvkGsHPgtG3blpdeeonly5fTvr3nrTxTlU1JWbRuFUDvDg3rLWflFzN9/nrW7s/kscv6cd/YXqfk0i86vSNPXTWAZ77azp8X7+DJaiZ02p1ip/MtLSvnw2nncmaX2qfQVUpZtQZ6Y0ypiMwAlgD+wDvGmG0i8hwQZ4xZ5HjsUhHZDpQBjxljMgBE5A/YDwuA54wxmY3xQprS0qVLWbp0KWeffTYAubm57NmzhzFjxvDII4/wu9/9jquuuooxY8Y0c0vrprSsnH98v4dXlu8l0N+Pp68ewC0jutVroDMpM5+pc9eSlFnAPyYP5prBpwzNHDd1VA8SMvJ5+6f9dI8K5Y5K07puPZjN7W+vIdDfj4/vGXnKBF1KqZq5NIpljFkMLK607Smn2wZ42PFT+dh3gHca1kwntfS8m4Ixhscff5x77rnnlMd++eUXFi9ezBNPPMFFF13EU089VcUzeJ6UY4X85sMNrN2fyQ1DY0jNKeL3n29l1b4Mnr9+IOEuzhZojGHp9hR+//kWSsoM8+8awTk9q57hz9mTVw0g+Wg+zyzaRteIUMb1t1PQrk88ytS5a2kTHMgHd5/ToCXylPJVWq7gIudpii+77DKefPJJbr31VsLCwjh48CCBgYGUlpYSGRnJbbfdRrt27ZgzZ85Jx3pq6ua/u9N4+OON5BeX8dIkO5dHebnh9f/u46Vlu9l6MJtXbhlSa7pkXUImL3y7k/WJR+kV3Zo3bx/mcvrH30/4x+SzuWn2KmYs+IVP7h1JdkEJd8+Lo0N4Kz6Ydi5dWvCViUo1Jw30LnKepvjyyy/nlltuYeTIkQCEhYXx/vvvs3fvXh577DH8/PwIDAzk9ddfB2D69OmMHz+ezp07e9RgbGlZOS8t281rK/bRr2M4r956Nr072LSIn59w/7jejOgRyW8WbOD611by5NUDuO2cU1M5u1NyePHfu/huRwodwlvx/PUDuXFoTJ0XZm7dKoC3pwzn2ld/Zso768gpLKF7VCjv33UOHdoEu+11K9XkivPg49ug98Uw8v4mP71OauaBmuL1Hs62FxytSzjK5OFdefrqMwgJqnoK3My8Yh7+ZCMrdqVx5cBOPD9xIG2CAzmcXcDfl+1m4fpkWgcFcO/YXtw5qke1z+OqHYePceMbq4htH8p7d55T77VFlfIYX86ADfPt7ckfQv8r3H4KndTMh2TmFTPnx3hKyw3Bgf6EBvkTEuhPiON3aJA/Wfkl/PGb7RSVljPrpsFce3b1A6UAka2DeGfKcGb/GM//LdnFloPZXNi/Ax+uPYAx8KtRPZgxrrfbptE9vVMb/vvYWMKDA+u0WLNSHmnrv2yQHzkDEn+Gz6bDtP9AdN8ma4IGei9SXFrOvfPXE5eYSasAfwpKyqrdt/9p4bx66xB6uXjBkZ+fcO8FvRjWPYLffLiBeasSuG5wF357SV+6Roa66RWcUJ+1V+vk4HpY/me48m8QEdu451K+62gCfPUQxAyHi5+B3BSYPRY+utkG++CmKRNuMYHeGOMT85nUN5VmjOGJL7awNiHzeDljebmhsLSMguIy8ovLKCixt4vLyhnYpW29VisaFhvJkt+ez9G8YrpHtdAKmOT1MP86KMqG//4fXPtqc7dI1VdeBmz5FPZ+BwOugbNvA0+JE2UlsPAuQGDi2+AfCG1jYNJ7MO9q27Of/CH4Nf631hYR6IODg8nIyCAqKsqrg70xhoyMDIKD6z7w+PZP+/kkLpnfXNj7eM26n58QGhRAaFAAtRc4uq5NcKBbFmduFslxNsiHRkLvC2HzRzDucfsH6I3Wz4NjB2Hc/zZ3S9ynrAT2LIWNC2D3EigvgdYdYO8y2P8DXPV3aOUBU2P8549wMA5ufBciup/Y3v08GP8CLH4UVjwPF/6+0ZvSIgJ9TEwMycnJeOqEZ+4UHBxMTEzdgs7yXan8efEOxp9xGr+9uOnyfi1O0jp4/3ob5Kd+A6YcdnwFK1/xiOsz3C7hJ/j6Ifs6+46HLkOau0UNc3izDe5bPoH8DBvcz7kHBt8C0f3hx7/ZwHnoF7hxHpx2ZvO1dd9/4OdZMGQKnHHdqY8PvxsOb4IfXrRX5g+Y0KjNaRFVN6p6e1JyuP61lXSNDGXhr0fqTI7VSVpne/Kt28PUr0/04D+/F7Z/CQ9thdbu/N7TQMZA/Ar45T049z7oOrxux+dnwuujIDAECjIhZgTc+on721lWAkufgP5XQY9GuhI86wB8dCsc2Qz+QdDvchh8K/S6CPwr/X/f/yP8624ozLK95qFTmz6Vk5sGb4yCkAiYthyCqhnDKi2CuVdA6g6Y9j10aFilXU1VN1rS0IIdzbMzP7YK9GfOlGEa5KuTtNYG+bBo25N3TtOMeghK8mHNG83XPmfG2N7gO+Nh/rWw7TP44AZI21W35/jyfshPhxvn2mqPPUvs2IS7Lf+zfe8+vxeKG2mG1hV/gfTdcMVf4ZFdNsfd97JTgzzYD5t7f7Lpka8fgn/dBYXHGqddVSkvhy/uhcJsuOGd6oM8QEAruGm+TTN9dAsUHG20Zmmgb6GKS8v59QfrOZxdyOw7hnrGepYlBTZHuvx5Wzdcl+DUWA6sgfnXOwX5SqWkHfrb3ujaN6GofouguIUxsPd7eOcy+6GUnWQrgu5fZ3ux70+EY4dde661b8GuxXDJc9DpLJveCImA/7o5PRW/An76O3QfBceSYeXL7n1+gOxkO44y5A4YMc2m3WoTFg23/gsufBK2fQ6zL7Bpkqaw+lU7MHzZn6DjGbXv36YzTJoPWUn2m0h59ZVyDaGBvgUyxvD0om2sjs/kLxMHMqRbM63OWFIA8f+F//zJfgV9oZutJvjhRVs7/PooOyBVUtA87Tuw2ubkwzrYIN+mc9X7jX7Y9sDi5rr3/PEr4Iv74Ps/2EHRfcshY5/9yl7BGBsY3r7UtjX7IFz5EjywweZxo/vCbQttb++DG2w7a3J4Myz9vc3Jn3Ov3dYqHM77jR3ATHZTWjQvHT67B9r3gVs/tRUvP8+y7Xenla/Y3+f9pm7H+fnB+Y/af/eSQphziQ36jengL/Dds7bjMOwu14/rdg5c8X/2/8F//tAoTdMcfQv07s/7eear7fx6bC9+N75/05485whs/gR2fWsrCsqKQfxszzF2NMSOgW7nQmmxDTibP4bInjZ49RrXdO1MjoP3roGwjjYnX12QrzDvakjbDQ9ttl+pG+rAant+v0CbGjLOPTWB8E7QriuUFtreZtuuMOZhm3uu6vz7/gMf3AjdRsJt/6p6n+I8ePMCKM6Fe38+ecyhKAdmDYIuQ+0HR0OUl8OHN9kP+Wn/sYOeRxPhleFwxrVw/eyGPX+FvAyYdab9ELmuAam1vAz7IZmdBA9ugqBGKAs+tAE+nQplpXDvj65986jsq4fs2MLEd+pVcqlXxnqJguIyPlx7gD9+s51LBnTksUv7Nc2JSwptKmDTh7bXYcodKYF7HYH9nKov/Lh+tq2I+Pphm28eeCNc9mfbw25Mxw7bnGfr9o6efKfajxntaOPGBTDsVw07f9ouWHATtOkCdy2z703OITuomHXAfk3POgBZifaD8qpZjgBfw5XFvS6Ea16Dz6fDF7+G6+ecGgwW/w9k7IUpi04dWG4VDqMegO+esQPTdR3cdbbmdfvt4Iq/nqhsiegO582wlS/DpzXs+Y+f5w37ITnqoYY9T+soOzD7zqWw7m37PrjLwfV2DGHPEpseu/nj+gV5sO+nn3+jDB5rj74FSM8t4r2VCcxfncjR/BJG9ozirSnDCGvViJ/Txtj/xBs/sGmYwmwbuM6aDGfdbL+yu6qkEH56yeZzA0Pg4mdt2VljXChSWgTvXgkp2+Hu76Bj1QuZnMIYeGscFGTBjLiqB/pccewwvH2Jbcfdy9x/1e1Ps+C7p+0A62V/OrF9y0I78Hj+Y3DhE1UfW5QL/xgEnQbD7Z/V7/yHNtg0SN/L4Kb3Tw5KRbnw8lA72H3Xsob9+xblwN/PsB2JyR/U/3mczb/OprYe2tzwXn3yejvmsWepDfAjZ8CI6RDcxj1trQft0bdQ+9PzeOvHeP61Ppmi0nIuPr0j91zQk2HdI9x74VhJwcm9zKMJsPvfttIhIAROv9r2zHucb3scdRUYbC/YOfMG+Pq3thpi4wfQ+ewaDhJbf9x9pOvnMQa+eQSS19nKDFeDPNiANfph+OR22P4FDLzB9WMrFGbbFEHBUfjV4saZWmHUg3DsEKx6xaajRt4PmfH2a3/Xc+CCmdUf2yoMznvAflAkrYWuI+p27qIcWHin/UY24eVTe56twuDip+03ji2fwlk31f31VYiba9/P0acscVF/Yx+3H8Lr5tj3sT6S42DFC/birJBIuOgpG+BbefZiONqj90DrE48y+4d9LN2eQqC/HxOHdOHuMT1dnpemRmm7bQ89fdeJVEJepQvR/AIhZpgN7gOudW8vxRibAlrxAhTVUPZWWmTTGhNetu1wxbo5NtCPeRQuerLubSsvh9fOAf9WNs9alw/T0iJbGXNglR2c7HVh3c/vcjvLYOGvbP3/dW/Cmjchc58tK2zXreZjj/fqz4Lb6zg4+dk99mKlqd/Y8sUq21YOcy6yYzm/iatfz7m0yI4nRPeFKV/V/fiazL8eDm+Eh7bUrW3ZyfYclUwAAB8MSURBVPDVgzZ1GRJpB4dHTPOoAK89+hZiw4Gj/OXfO1kdn0nbkEDuH9ubKefFEh3ewMHBgqM2uG/80A6gip/tbbbrZi8+adcN2nV3/O4GYac13vwbIjZw1xa8C7Ph49tt7zDrAFzwu5oDb+JK+PZ30OfS+l/u7+dn88Ff3gd7lkHfS107rrzctjPhR7huduMGebDfqq6bbS/M+dyxytmk92oP8mB73aMehGVP2dLTbue4ds5NH9kyx7GPVx/kwb6HFfnwn2bV7/L+jQsg90jDBmCrM/ZxePtiW4I62sXcf1kJfDIF0nbaicmGT/OMKRbqQHv0HmBfWi5/XbKLb7ceoX1YEPeN7c1Nw7vSuiE5+LJSW6mx8QM7kFpWDB0G2AA7cBKEd3TfC2gspcW2F7VpgR2svGpW1QOW2QdtrXSrNrYKJKRdw875z7NtRcyd/3btmCW/t6mUi591PXi4Q8FRWDDZButLnnP9uOI822M+bSDc8UXt+2fsgzfGQOfBtoftSvpu4V2w82uYsc61D6AKZaXwyjD7bzhteeNc1fr+RDvW8OBm1wL2sqdt6eiN71Y9nYGH0B69h0o9Vsis7/fw8bokggP8eOjiPkwb07NhAb6k0M73selDOyVqSCQMu9MOoHY6y3Nm9nNFQBBc+5qt6FjxvP36fNP8kyt8Sgrtyj0lBTDl64YF+Ypznvcb+PfvIHFV7WMEK1+xQX7EPfXP+9ZXSATctaTuxwW1dvTqn7RloN3OrX7fjH02TRQQBNe/5foYzSXPws5vbJC8sQ7XJ2z/Ao7uh0vmN97/1bGP2/TSurdg9G9r3re2OWtaCO3RN4OcwhJm/xDPnB/3U1JWzq3ndGPGhX0anqIB+PEl+P5Z6HeF7QX3ubTmsr2WYuMCWPQbiHJcoNOuq833f3Gf7fHf9AGcfpV7zlWcb+u3uwy153LmPHB9cD2s+LOt875hbv0GqptLcR784yx79eYdX578WEGWvbho04eQtAb8AmyFTb/L63aO5c/bypRf/du1QXVj7DeHsiK4b03jTt/7/g323++hzdXn2XNT7UV/oZE1z1njIbRH38yMMRzMKmBPai5bkrN5d2UCmXnFXDWoE49e2o/Y9m66gKOkAFa/ZnPEN3/onuf0FINvsVUmH99ue2O3fGKD0KYFttLEXUEe7B/0Ob+G5X+ExY/ZweqK4J6XevK+PS6w+fKWFOThRK9+6RP2m0vXERC/3H6g7vzGXsgV3d+mowbd5Nq1CJWNetCurPTvmTZQ1ha49yyDlC32eoHGnqN97OMw50Kbqx9TRWVPebmdv6fomE1veXiQr4326N0s5Vgh2w8dY3dKDntSc9mTksPe1Fzyik9cGTmqdxS/G9+fQTENTDNUVlF1MuXrxptJsLmlbLdXiBYctcGo72W2N+/uwFBwFF4eZv/Q23Z1DFR3PXXgOrxTy0qHOSvOtxU4rcJtJyHnMAS3sxe2Db4ZOg9p+Gvb/Cl8djdc+ic499c1fyC+M95+oD6woWm+hX5woy3FfWjLqb36n/9pU1tX/s1ORdEC1NSj10DvRj/tSWfq3LWUltv3NDq8FX07htGnQzh9OobRt2M4fTqE0S60Ef4Tl5XCy0OgdbS9UKilBh9XHDsMH062A8x3Lmm8i1TKSkD8m2QFoGaz9i1HtdIl9ltT3/HumQKigjHw7lWQ+BOEd7a19Wfdcup6qYmrYO54GP8XOPde952/Jsnrba/+oqdgzCMnth9cb+ce6jv+1IvCPJgG+iZwNK+Yy2b9QJuQQJ6/fmDjBfTqbP4EPpsGkxdA/yub7rzNxRgoL7XLs6mGKS1yb3Cv6vl3fWvTQnu/s/P+dHFcp3Hm9XZQ+YMbHTnzrU2bJvlgEiSvtRU4wW3slMZvnm8/5Os7Z00z0fnoG5kxhpmfbeZofjH/mDyY4bGRTRvky8vt9ALR/aFvHQfMWioRDfLu0phBvuL5z7jWLnzy8A649I92DptvHoa/9rMlonuW2nGRps6Fj51p03RrZ5+4sjorESbOaVFBvjY6GOsGn8QlsWRbCo9f3p8zOjfNqu4n2bMEUrfbqyS9Oc2gWr7wjrZ8deQMO2tnxdKAwe1gRDPkwrsMsSmalS/bPP2WT2Dc7+s29UYL4FJUEJHxIrJLRPaKyCmTaYjIVBFJE5GNjp+7nR57UUS2icgOEfmneNnq3vvT83j2q+2c1yuKaWN6Nn0DjLEllW27wZkTm/78StWHiL0A64oX4ZHddvrgkGZaV2HsTDs98Lf/YydRc87Xe4laA72I+AOvApcDA4CbRaSq2aI+NsYMdvzMcRx7HjAKGAScCQwHLnBX45tbSVk5D320gUB/P/426Sz8/Br4GWYMpO+x6326KvFnm2Mc9YCmMlTLFBDU8AvdGqLz2XbivtAoO7V2SyuVdYErqZsRwF5jTDyAiHwEXANsd+FYAwQDQYAAgUBK/Zrqef75/R42JWfz6i1D6NS2Hkv5GWPnLk/4ERJ+skE7L81ezTplkb1EvTY/vmQrbc6+re7nV0pZN8y1F5E15wdOI3Il0HcBkpzuJwNVzYQ0UUTOB3YDvzXGJBljVonIcuAwNtC/YozZUflAEZkOTAfo1q0O82I0o3UJmby6fC83DI3hykF1uJgkc7+tPEj4ERJ+tgs4g53rvdeFEDPcDqzOuxruWASdBlX/XIc2wr7vbXlYoAesGatUS+Uf6LVBHtw3GPsV8KExpkhE7gHmAReKSG/gdCDGsd8yERljjPnR+WBjzGxgNtjySje1qdEcKyzhoY82EhMRyjMTXFgAuMLWf9mr7cqKoU2MrV3uPsouwRcRe6Jet/dF8O7V8N4Ee3l6p7Oqfr6f/m4n8mohF3QopZqHK4OxB4GuTvdjHNuOM8ZkGGMqVjyeAwx13L4OWG2MyTXG5ALfAi1+OPvpL7dx5FghsyYPdm2VJ2NsUF54p60ffmAD/HarnYZ1yO0Q2ePkizIie9p1ToPCYN6EqlewT99r5yMfflfVy/gppZSDK4F+HdBHRHqISBAwGVjkvIOIOOcuJgAV6ZkDwAUiEiAigdiB2FNSNy3JlxsP8vmGgzxwYR+GdHOhSqCs1K6q9N0ztirm9s9tIK+t+Ciyhw32rcJtsD+08eTHf55l65PPva/er0Up5RtqDfTGmFJgBrAEG6Q/McZsE5HnRGSCY7cHHCWUm4AHgKmO7QuBfcAWYBOwyRjj5iVjms7BrAKe+GIrQ7tHcP+4XrUfUJRjL9VfP9dOh3r9HLusnqsiYh3Bvg28d82JYJ990C4EcfZtjb/QtlKqxdMpEOrgL//eyewf4ln+yFi6RdVyBd+xw7BgEqRssxMjDftV/U98NNHOF1KUbXP2mz+FNW/YFFBE9/o/r1LKa+g0xW6ydNsRzu0ZWXuQd55h8ZaP7aBrQ0R0tz37eVfZnn1ZiV28WoO8UsoFer28i/am5rIvLY9LB5xW847xK+Cdy+yEW3d+2/AgXyGiu12UObitnSdkVBMuWaeUatG0R++iZdvtdV6XDKhhrdWMfXblmvZ97MIY7bpWv299tOsGd30H6buhY1UXJyul1Kk00Lto6fYjDOzSls7targwactC25O/dSG07dI4DQnv2DIW9lZKeQxN3bgg9VghGw5kcWlNvXmwCxt3G9l4QV4ppepBA70Llu2waZtLz6ghP5+6004V3IJXildKeScN9C5Yui2F2KhQ+nYMq36n7V8AAgMmVL+PUko1Aw30tcgpLGHlvnQuPeM0apxKf9sX0P08CK+lKkcppZqYBvparNiVRkmZqTk/n7oD0nZo2kYp5ZE00Ndi6fYU2ocFcXZN89psc6RtTte0jVLK82igr0FRaRnLd6Zy8ekd8a9p9ajtX9jphrXsUSnlgTTQ12DVvgxyi0q59Iza0jY77Sr3SinlgTTQ12Dp9hRCg/w5r1f76nfa9jmatlFKeTIN9NUoLzcs257C2H7RBAdWs1iwMTY/Hzta0zZKKY+lgb4aG5OzSMspqnkSs9QdkL5L0zZKKY+mgb4aS7elEOAnjOtXw8Ie2z4H8dO0jVLKo2mgr8bS7UcY2SuKtqGBVe9gzIlqG13lSSnlwTTQV2Fvai7xaXm1XCS13U4XrBdJKaU8nAb6KizdfgSAi2sK9Jq2UUq1EBroq7B0WwpnxbSlU9tq5p53rrYJi27aximlVB1poK8k5VghG5Oyap6SOGUbZOzRtI1SqkXQQF9JxZKBNebnNW2jlGpBNNBXsmTbEXq0b03vDtXMPV9RbRM7BlrXcMWsUkp5CA30TrILSli1L4NLB3Ssfu75lK2QsVfTNkqpFkMDvZMVu1IpLTc1T2K27XMQfzj96qZrmFJKNYAGeic/7E4nqnUQg7tWM/e8MTbQ99C0jVKq5dBA7yQ+PZd+p4VXP/f8kS2QGa9pG6VUi+JSoBeR8SKyS0T2isjMKh6fKiJpIrLR8XO302PdRGSpiOwQke0iEuu+5rtXYkY+3aNaV/2gMfD9cxAYCv01baOUajkCattBRPyBV4FLgGRgnYgsMsZsr7Trx8aYGVU8xXvAn4wxy0QkDChvaKMbQ3ZBCZl5xcRGhVa9w4b3Ye8yuPxFaB3VtI1TSqkGcKVHPwLYa4yJN8YUAx8B17jy5CIyAAgwxiwDMMbkGmPy693aRpSYkQdAbPsqevTZybDkf6H7aBg+rYlbppRSDeNKoO8CJDndT3Zsq2yiiGwWkYUi0tWxrS+QJSKficgGEfk/xzeEk4jIdBGJE5G4tLS0Or8Id0jIsJ8/sZVTN8bAogegvAyueQX8dFhDKdWyuCtqfQXEGmMGAcuAeY7tAcAY4FFgONATmFr5YGPMbGPMMGPMsOjo5pk7JjHd9ui7RVZK3fzyHuz7Hi55FiJ7NEPLlFKqYVwJ9AeBrk73YxzbjjPGZBhjihx35wBDHbeTgY2OtE8p8AUwpGFNbhz7M/Lo1DaYkCCnLxxZSbDk9/Yq2GF3NV/jlFKqAVwJ9OuAPiLSQ0SCgMnAIucdRKST090JwA6nY9uJSEU3/UKg8iCuR7AVN069eWNg0Qww5ZqyUUq1aLVW3RhjSkVkBrAE8AfeMcZsE5HngDhjzCLgARGZAJQCmTjSM8aYMhF5FPhe7JwC64G3GuelNExiRh4Xn+50Rez6uRC/Aq58CSJim6tZSinVYLUGegBjzGJgcaVtTzndfhx4vJpjlwGDGtDGRpdTWEJ6bvGJGvqjibD0SehxAQy7s3kbp5RSDaT5CGzaBqBH+1AoL7cpG7Apm+omN1NKqRbCpR69t0tw1NB3j2oN69+B/T/AVbOgXbdmbplSSjWc9ug50aOP9U+DpU9Bz3EwdGrzNkoppdxEAz2wPz2PzuEBhHx9v105asLLmrJRSnkNTd1gK25+2+pLOLAKrpsN7brWfpBSSrUQGuiByLR1TCz7EM66Gc66qbmbo5RSbuXzqZvco6k8UzqLYyExcMVfm7s5Sinldr4d6I2h/PNfE0U2W0f+HVpVsyC4Ukq1YL4d6NfOps2B73ih9BYieg9v7tYopVSj8N1Af3gzLH2ChMjRvFM2vvqVpZRSqoXzzcHY4jxYeCeERDKvw/8QnVNCWCvffCuUUt7PN3v0i/8HMvbCxLfYlh1U/fKBSinlBXwv0G9ZCBvfhzGPQI/zSczI07SNUsqr+Vagz9wPXz0EXc+BsY+TX1xKyrEi7dErpbyabwX6rx+yC4hMnAP+ASfmuKlqQXCllPISvhPojYHkOBg0+fislImOWStPWRBcKaW8iO8E+oKjUJwLEd2Pb0pw9Oi7a+pGKeXFfCfQZx2wv53mmE9Iz6N9WBDhwYHN1CillGp8vh3oteJGKeUDfC/Qtz0xBXFiRr6mbZRSXs93An12EgSFQ0gEAAXFZRzOLtSBWKWU1/OdQJ91wKZtHCtHHcjU0kqllG/wsUB/Im2TcLy0UlM3Sinv5kOBPumkgdiKGnodjFVKeTvfCPQFWVCUfVKg35+eT2TrINqGaGmlUsq7+Uagr7LiJk8rbpRSPsGlQC8i40Vkl4jsFZGZVTw+VUTSRGSj4+fuSo+3EZFkEXnFXQ2vk+wk+/uk1E2+VtwopXxCrattiIg/8CpwCZAMrBORRcaY7ZV2/dgYM6Oap/kD8EODWtoQlS6WKiwp41B2gfbolVI+wZUe/QhgrzEm3hhTDHwEXOPqCURkKNARWFq/JrpBVhIEhkJoFABJmfkYAz20tFIp5QNcCfRdgCSn+8mObZVNFJHNIrJQRLoCiIgf8Dfg0ZpOICLTRSROROLS0tJcbHodZCWeVEN/YjIzDfRKKe/nrsHYr4BYY8wgYBkwz7H9PmCxMSa5poONMbONMcOMMcOio6Pd1CQnWQdOGYgFraFXSvkGV1bEPgh0dbof49h2nDEmw+nuHOBFx+2RwBgRuQ8IA4JEJNcYc8qAbqPKToKY4cfv7k/Po11oIO1Cg5q0GUop1RxcCfTrgD4i0gMb4CcDtzjvICKdjDGHHXcnADsAjDG3Ou0zFRjW5EG+8Jidi75SxY2mbZRSvqLWQG+MKRWRGcASwB94xxizTUSeA+KMMYuAB0RkAlAKZAJTG7HNdXO8tPLk6Q+Gdo9opgYppVTTcqVHjzFmMbC40rannG4/Djxey3O8C7xb5xY2VFZFoLcrSxWVlnEoq4CJQ2KavClKKdUcvP/K2Eo19EmZBZQbiG2vA7FKKd/gA4E+EQKCobWt5tHJzJRSvsb7A312ki2trFRDr9MfKKV8hfcH+ooFRxwS0vNoExxARKjOWqmU8g0+EOiTTqm4iW3fGnH08JVSytt5d6AvzoP8dK2hV0r5NO8O9BWllW1toC8uLSf5aD49dOoDpZQP8e5AX2ke+uSj+ZQbrbhRSvkW7w70WYn2tyPQJ1ZU3GgNvVLKh3h5oD8A/kEQ1hGwA7GgPXqllG/x8kCfBG1jwM++zIT0PMJbBRDVWmetVEr5Di8P9JVq6DPy6d4+VEsrlVI+xfsDfduTa+g1baOU8jXeG+hLCiAv9fislSVl5SQfLaCHBnqllI/x3kCf7Vi98HhpZQFl5YbuWkOvlPIx3hvoj09PbFM3Cem24qZHe+3RK6V8iw8EetujryitjNVAr5TyMd4d6P0CILwToKWVSinf5b2BPjsJ2nQBP38A9mtppVLKR3lvoK9iHnpdbEQp5Yt8ItAfn7VS8/NKKR/knYG+tAhyjuislUophbcG+uxkwJxScdNDZ61USvkg7wz0FaWVbStq6HVBcKWU7/LOQF9pwZGEjDzCgwOI1NJKpZQP8s5An3UAxN+WVwL7HRU3WlqplPJFXhrok6BNZ/APAGyPXq+IVUr5KpcCvYiMF5FdIrJXRGZW8fhUEUkTkY2On7sd2weLyCoR2SYim0XkJne/gCpVKq08eLRAFwRXSvmsgNp2EBF/4FXgEiAZWCcii4wx2yvt+rExZkalbfnAHcaYPSLSGVgvIkuMMVnuaHy1sg5AjzEAJGlppVLKx7nSox8B7DXGxBtjioGPgGtceXJjzG5jzB7H7UNAKhBd38a6pKwEcg45VdzoZGZKKd/mSqDvAiQ53U92bKtsoiM9s1BEulZ+UERGAEHAvioemy4icSISl5aW5mLTq3HsIJhyp4obW1qpV8UqpXyVuwZjvwJijTGDgGXAPOcHRaQTMB/4lTGmvPLBxpjZxphhxphh0dEN7PBXMQ99m+AAIkIDG/a8SinVQrkS6A8Czj30GMe244wxGcaYIsfdOcDQisdEpA3wDfB7Y8zqhjXXBVmn1tDHttfSSqWU73Il0K8D+ohIDxEJAiYDi5x3cPTYK0wAdji2BwGfA+8ZYxa6p8m1yDoACLSJAU7U0CullK+qNdAbY0qBGcASbAD/xBizTUSeE5EJjt0ecJRQbgIeAKY6tk8CzgemOpVeDnb7q3CWdcAuNhIQRFFpGYeyCnQgVinl02otrwQwxiwGFlfa9pTT7ceBx6s47n3g/Qa2sW6yk46nbZIyCyg3EKs19EopH+Z9V8ZmJZ7Iz2tppVJKeVmgLyuF7IMnKm4qpifWHL1Syod5V6DPOQym7KSKm7YhgUTorJVKKR/mXYH+eA19ReomX/PzSimf512BvmIe+rY20O9P11krlVLKuwL98ZWlYmxpZXaB1tArpXyelwX6RAg7DQKDScrMxxiI1XVilVI+zssCfdLxipv9uk6sUkoBXhfoTyw4klhRWqk5eqWUj/OeQF9eDtnJx+eh35+eR7vQQNqFammlUsq3eU+gzz0C5SUn1dDrqlJKKeXiXDctQthp8PBOCAwBbA398NiIZm6UUko1P+8J9H5+0MbOllxY4iitbB/TzI1SSqnm5z2pGyfHSys1daOUUt4Z6PfrrJVKKXWcVwb6xIoFwbVHr5RS3hno92fkEREaSFtdEFwppbwz0Ceka2mlUkpV8NpAr1fEKqWU5XWB3pZWFmrFjVJKOXhdoD+Q6ZjMTGetVEopwAsD/fHSSu3RK6UU4IWBvmLWSq2hV0opy+sC/f70fCJbB9E2REsrlVIKvDDQ29JKzc8rpVQF7wv0GXl6RaxSSjnxqkBfWFLG4exCzc8rpZQTlwK9iIwXkV0isldEZlbx+FQRSRORjY6fu50emyIiexw/U9zZ+Moq5rjR1I1SSp1Q63z0IuIPvApcAiQD60RkkTFme6VdPzbGzKh0bCTwNDAMMMB6x7FH3dL6SipKK/WqWKWUOsGVHv0IYK8xJt4YUwx8BFzj4vNfBiwzxmQ6gvsyYHz9mlo7La1USqlTuRLouwBJTveTHdsqmygim0VkoYh0rcuxIjJdROJEJC4tLc3Fpp8qISOPqNZBtAnW0kqllKrgrsHYr4BYY8wgbK99Xl0ONsbMNsYMM8YMi46Orncj9mtppVJKncKVQH8Q6Op0P8ax7ThjTIYxpshxdw4w1NVj3SkhPV/TNkopVYkrgX4d0EdEeohIEDAZWOS8g4h0cro7AdjhuL0EuFREIkQkArjUsc3tCorLOHKsUGvolVKqklqrbowxpSIyAxug/YF3jDHbROQ5IM4Yswh4QEQmAKVAJjDVcWymiPwB+2EB8JwxJrMRXgf5xaVMOKszg7u1a4ynV0qpFkuMMc3dhpMMGzbMxMXFNXczlFKqRRGR9caYYVU95lVXxiqllDqVBnqllPJyGuiVUsrLaaBXSikvp4FeKaW8nAZ6pZTychrolVLKy2mgV0opL+dxF0yJSBqQ2ICnaA+ku6k5jUXb6B7aRvfQNrpPc7azuzGmylkhPS7QN5SIxFV3dZin0Da6h7bRPbSN7uOp7dTUjVJKeTkN9Eop5eW8MdDPbu4GuEDb6B7aRvfQNrqPR7bT63L0SimlTuaNPXqllFJONNArpZSX85pALyLjRWSXiOwVkZnN3Z6qiEiCiGwRkY0i4jGrq4jIOyKSKiJbnbZFisgyEdnj+B3hgW18RkQOOt7PjSJyRTO3sauILBeR7SKyTUQedGz3mPeyhjZ6zHspIsEislZENjna+Kxjew8RWeP4G//YsbSpp7XxXRHZ7/Q+Dm6uNp7EGNPif7BLHO4DegJBwCZgQHO3q4p2JgDtm7sdVbTrfGAIsNVp24vATMftmcBfPLCNzwCPNvf759SeTsAQx+1wYDcwwJPeyxra6DHvJSBAmON2ILAGOBf4BJjs2P4G8GsPbOO7wA3N/R5W/vGWHv0IYK8xJt4YUwx8BFzTzG1qMYwxP2DX+nV2DTDPcXsecG2TNqqSatroUYwxh40xvzhu5wA7gC540HtZQxs9hrFyHXcDHT8GuBBY6Nje3O9jdW30SN4S6LsASU73k/Gw/7wOBlgqIutFZHpzN6YWHY0xhx23jwAdm7MxNZghIpsdqZ1mTS85E5FY4GxsT88j38tKbQQPei9FxF9ENgKpwDLsN/YsY0ypY5dm/xuv3EZjTMX7+CfH+/h3EWnVjE08zlsCfUsx2hgzBLgcuF9Ezm/uBrnC2O+nnthbeR3oBQwGDgN/a97mWCISBvwLeMgYc8z5MU95L6too0e9l8aYMmPMYCAG+429f3O2pyqV2ygiZwKPY9s6HIgEfteMTTzOWwL9QaCr0/0YxzaPYow56PidCnyO/Q/sqVJEpBOA43dqM7fnFMaYFMcfWznwFh7wfopIIDaAfmCM+cyx2aPey6ra6InvJYAxJgtYDowE2olIgOMhj/kbd2rjeEdqzBhjioC5eMj76C2Bfh3QxzEqHwRMBhY1c5tOIiKtRSS84jZwKbC15qOa1SJgiuP2FODLZmxLlSqCp8N1NPP7KSICvA3sMMa85PSQx7yX1bXRk95LEYkWkXaO2yHAJdixhOXADY7dmvt9rKqNO50+0AU7huARf+Nec2WsoxxsFrYC5x1jzJ+auUknEZGe2F48QACwwFPaKCIfAmOxU6ymAE8DX2CrHLphp42eZIxptsHQato4FptqMNiKpnuccuFNTkRGAz8CW4Byx+b/xebAPeK9rKGNN+Mh76WIDMIOtvpjO6OfGGOec/wNfYRNiWwAbnP0nD2pjf8BorFVORuBe50GbZuN1wR6pZRSVfOW1I1SSqlqaKBXSikvp4FeKaW8nAZ6pZTychrolVLKy2mgV0opL6eBXimlvNz/A0ozlGjQ2Xz8AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
        "# 예측하기, 확률값으로 반환됨\n",
        "y_pred_probs = model.predict(X_test)\n",
        "\n",
        "# 0또는 1로 변경\n",
        "y_preds = [1 if x>0.5 else 0 for x in y_pred_probs]\n",
        "\n",
        "#성능 평가\n",
        "print(confusion_matrix(y_test, y_preds))\n",
        "print(classification_report(y_test, y_preds))\n",
        "print(roc_auc_score(y_test, y_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNrLteMjI2Ub",
        "outputId": "8cdcf7b4-ba6f-46bd-b497-4b7b51a6c49e"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[523 358]\n",
            " [359 504]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.59      0.59      0.59       881\n",
            "         1.0       0.58      0.58      0.58       863\n",
            "\n",
            "    accuracy                           0.59      1744\n",
            "   macro avg       0.59      0.59      0.59      1744\n",
            "weighted avg       0.59      0.59      0.59      1744\n",
            "\n",
            "0.5888264284107784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#train,val,test split\n",
        "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "#X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
        "\n",
        "\n",
        "n_fold = 5\n",
        "skf = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state =seed)\n",
        "accuracy = []\n",
        "performance = []\n",
        "binary_accuracy = []\n",
        "val_binary_accuracy = []\n",
        "loss = []\n",
        "val_loss = []\n",
        "for train, test in skf.split(X,y):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(32,activation='relu'))\n",
        "  model.add(Dense(16,activation='relu'))\n",
        "  model.add(Dense(8,activation='relu'))\n",
        "  model.add(Dense(4,activation='relu'))\n",
        "  model.add(Dense(1, activation = 'sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001), metrics = ['binary_accuracy'])\n",
        "\n",
        "  print(X[train].shape)\n",
        "  print(X[test].shape)\n",
        "\n",
        "  from keras.callbacks import EarlyStopping\n",
        "\n",
        "  hist = model.fit(X[train], y[train], epochs = 1000, validation_data=(X[test],y[test]), callbacks= [EarlyStopping(patience=10)])\n",
        "  binary_accuracy.append(hist.history['binary_accuracy'])\n",
        "  val_binary_accuracy.append(hist.history['val_binary_accuracy'])\n",
        "  loss.append(hist.history['loss'])\n",
        "  val_loss.append(hist.history['val_loss'])\n",
        "  k_accuracy = \"%.4f\" %(model.evaluate(X[train], y[train])[1])\n",
        "  accuracy.append(k_accuracy)\n",
        "\n",
        "  perform = model.evaluate(X[test],y[test])\n",
        "  performance.append(perform)\n",
        "\n",
        "print(\"\\n %.f fold accuracy : \"%(n_fold), accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2lsSFunmt7N",
        "outputId": "288e76da-18ec-4bff-fbc0-8880174e99d1"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6974, 20)\n",
            "(1744, 20)\n",
            "Train on 6974 samples, validate on 1744 samples\n",
            "Epoch 1/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6912 - binary_accuracy: 0.5191 - val_loss: 0.6917 - val_binary_accuracy: 0.5229\n",
            "Epoch 2/1000\n",
            "2592/6974 [==========>...................] - ETA: 0s - loss: 0.6913 - binary_accuracy: 0.5258"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6974/6974 [==============================] - 0s 48us/sample - loss: 0.6909 - binary_accuracy: 0.5271 - val_loss: 0.6914 - val_binary_accuracy: 0.5275\n",
            "Epoch 3/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6906 - binary_accuracy: 0.5297 - val_loss: 0.6911 - val_binary_accuracy: 0.5241\n",
            "Epoch 4/1000\n",
            "6974/6974 [==============================] - 0s 51us/sample - loss: 0.6903 - binary_accuracy: 0.5334 - val_loss: 0.6908 - val_binary_accuracy: 0.5287\n",
            "Epoch 5/1000\n",
            "6974/6974 [==============================] - 0s 51us/sample - loss: 0.6899 - binary_accuracy: 0.5344 - val_loss: 0.6905 - val_binary_accuracy: 0.5304\n",
            "Epoch 6/1000\n",
            "6974/6974 [==============================] - 0s 48us/sample - loss: 0.6896 - binary_accuracy: 0.5363 - val_loss: 0.6902 - val_binary_accuracy: 0.5344\n",
            "Epoch 7/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6893 - binary_accuracy: 0.5410 - val_loss: 0.6899 - val_binary_accuracy: 0.5321\n",
            "Epoch 8/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6890 - binary_accuracy: 0.5432 - val_loss: 0.6896 - val_binary_accuracy: 0.5333\n",
            "Epoch 9/1000\n",
            "6974/6974 [==============================] - 1s 126us/sample - loss: 0.6887 - binary_accuracy: 0.5469 - val_loss: 0.6893 - val_binary_accuracy: 0.5378\n",
            "Epoch 10/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6884 - binary_accuracy: 0.5495 - val_loss: 0.6890 - val_binary_accuracy: 0.5390\n",
            "Epoch 11/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6881 - binary_accuracy: 0.5523 - val_loss: 0.6888 - val_binary_accuracy: 0.5384\n",
            "Epoch 12/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6878 - binary_accuracy: 0.5536 - val_loss: 0.6885 - val_binary_accuracy: 0.5419\n",
            "Epoch 13/1000\n",
            "6974/6974 [==============================] - 0s 48us/sample - loss: 0.6876 - binary_accuracy: 0.5561 - val_loss: 0.6883 - val_binary_accuracy: 0.5459\n",
            "Epoch 14/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6873 - binary_accuracy: 0.5569 - val_loss: 0.6881 - val_binary_accuracy: 0.5499\n",
            "Epoch 15/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6871 - binary_accuracy: 0.5574 - val_loss: 0.6879 - val_binary_accuracy: 0.5550\n",
            "Epoch 16/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6868 - binary_accuracy: 0.5599 - val_loss: 0.6876 - val_binary_accuracy: 0.5539\n",
            "Epoch 17/1000\n",
            "6974/6974 [==============================] - 0s 48us/sample - loss: 0.6865 - binary_accuracy: 0.5622 - val_loss: 0.6874 - val_binary_accuracy: 0.5539\n",
            "Epoch 18/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6863 - binary_accuracy: 0.5638 - val_loss: 0.6872 - val_binary_accuracy: 0.5539\n",
            "Epoch 19/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6860 - binary_accuracy: 0.5640 - val_loss: 0.6870 - val_binary_accuracy: 0.5556\n",
            "Epoch 20/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6858 - binary_accuracy: 0.5635 - val_loss: 0.6868 - val_binary_accuracy: 0.5573\n",
            "Epoch 21/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6855 - binary_accuracy: 0.5660 - val_loss: 0.6866 - val_binary_accuracy: 0.5568\n",
            "Epoch 22/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6853 - binary_accuracy: 0.5654 - val_loss: 0.6864 - val_binary_accuracy: 0.5591\n",
            "Epoch 23/1000\n",
            "6974/6974 [==============================] - 0s 48us/sample - loss: 0.6850 - binary_accuracy: 0.5670 - val_loss: 0.6862 - val_binary_accuracy: 0.5636\n",
            "Epoch 24/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6848 - binary_accuracy: 0.5675 - val_loss: 0.6859 - val_binary_accuracy: 0.5636\n",
            "Epoch 25/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6845 - binary_accuracy: 0.5688 - val_loss: 0.6857 - val_binary_accuracy: 0.5654\n",
            "Epoch 26/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6843 - binary_accuracy: 0.5694 - val_loss: 0.6855 - val_binary_accuracy: 0.5659\n",
            "Epoch 27/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6840 - binary_accuracy: 0.5701 - val_loss: 0.6853 - val_binary_accuracy: 0.5677\n",
            "Epoch 28/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6838 - binary_accuracy: 0.5714 - val_loss: 0.6851 - val_binary_accuracy: 0.5659\n",
            "Epoch 29/1000\n",
            "6974/6974 [==============================] - 0s 51us/sample - loss: 0.6836 - binary_accuracy: 0.5718 - val_loss: 0.6849 - val_binary_accuracy: 0.5711\n",
            "Epoch 30/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6834 - binary_accuracy: 0.5728 - val_loss: 0.6847 - val_binary_accuracy: 0.5711\n",
            "Epoch 31/1000\n",
            "6974/6974 [==============================] - 0s 51us/sample - loss: 0.6831 - binary_accuracy: 0.5740 - val_loss: 0.6846 - val_binary_accuracy: 0.5728\n",
            "Epoch 32/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6829 - binary_accuracy: 0.5746 - val_loss: 0.6844 - val_binary_accuracy: 0.5717\n",
            "Epoch 33/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6827 - binary_accuracy: 0.5753 - val_loss: 0.6842 - val_binary_accuracy: 0.5734\n",
            "Epoch 34/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6825 - binary_accuracy: 0.5721 - val_loss: 0.6840 - val_binary_accuracy: 0.5740\n",
            "Epoch 35/1000\n",
            "6974/6974 [==============================] - 0s 48us/sample - loss: 0.6823 - binary_accuracy: 0.5730 - val_loss: 0.6839 - val_binary_accuracy: 0.5722\n",
            "Epoch 36/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6821 - binary_accuracy: 0.5733 - val_loss: 0.6837 - val_binary_accuracy: 0.5740\n",
            "Epoch 37/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6819 - binary_accuracy: 0.5753 - val_loss: 0.6835 - val_binary_accuracy: 0.5734\n",
            "Epoch 38/1000\n",
            "6974/6974 [==============================] - 1s 111us/sample - loss: 0.6818 - binary_accuracy: 0.5759 - val_loss: 0.6834 - val_binary_accuracy: 0.5722\n",
            "Epoch 39/1000\n",
            "6974/6974 [==============================] - 1s 99us/sample - loss: 0.6816 - binary_accuracy: 0.5771 - val_loss: 0.6832 - val_binary_accuracy: 0.5734\n",
            "Epoch 40/1000\n",
            "6974/6974 [==============================] - 1s 84us/sample - loss: 0.6814 - binary_accuracy: 0.5777 - val_loss: 0.6830 - val_binary_accuracy: 0.5757\n",
            "Epoch 41/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6812 - binary_accuracy: 0.5766 - val_loss: 0.6829 - val_binary_accuracy: 0.5763\n",
            "Epoch 42/1000\n",
            "6974/6974 [==============================] - 1s 86us/sample - loss: 0.6810 - binary_accuracy: 0.5767 - val_loss: 0.6827 - val_binary_accuracy: 0.5774\n",
            "Epoch 43/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6808 - binary_accuracy: 0.5773 - val_loss: 0.6825 - val_binary_accuracy: 0.5774\n",
            "Epoch 44/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6806 - binary_accuracy: 0.5792 - val_loss: 0.6824 - val_binary_accuracy: 0.5786\n",
            "Epoch 45/1000\n",
            "6974/6974 [==============================] - 1s 90us/sample - loss: 0.6804 - binary_accuracy: 0.5790 - val_loss: 0.6822 - val_binary_accuracy: 0.5791\n",
            "Epoch 46/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6802 - binary_accuracy: 0.5787 - val_loss: 0.6821 - val_binary_accuracy: 0.5780\n",
            "Epoch 47/1000\n",
            "6974/6974 [==============================] - 1s 75us/sample - loss: 0.6800 - binary_accuracy: 0.5810 - val_loss: 0.6819 - val_binary_accuracy: 0.5786\n",
            "Epoch 48/1000\n",
            "6974/6974 [==============================] - 1s 88us/sample - loss: 0.6798 - binary_accuracy: 0.5803 - val_loss: 0.6818 - val_binary_accuracy: 0.5786\n",
            "Epoch 49/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6797 - binary_accuracy: 0.5813 - val_loss: 0.6817 - val_binary_accuracy: 0.5791\n",
            "Epoch 50/1000\n",
            "6974/6974 [==============================] - 0s 51us/sample - loss: 0.6795 - binary_accuracy: 0.5824 - val_loss: 0.6815 - val_binary_accuracy: 0.5803\n",
            "Epoch 51/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6793 - binary_accuracy: 0.5817 - val_loss: 0.6814 - val_binary_accuracy: 0.5820\n",
            "Epoch 52/1000\n",
            "6974/6974 [==============================] - 0s 51us/sample - loss: 0.6791 - binary_accuracy: 0.5813 - val_loss: 0.6812 - val_binary_accuracy: 0.5826\n",
            "Epoch 53/1000\n",
            "6974/6974 [==============================] - 0s 48us/sample - loss: 0.6789 - binary_accuracy: 0.5829 - val_loss: 0.6811 - val_binary_accuracy: 0.5826\n",
            "Epoch 54/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6788 - binary_accuracy: 0.5833 - val_loss: 0.6810 - val_binary_accuracy: 0.5866\n",
            "Epoch 55/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6786 - binary_accuracy: 0.5840 - val_loss: 0.6808 - val_binary_accuracy: 0.5854\n",
            "Epoch 56/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6784 - binary_accuracy: 0.5835 - val_loss: 0.6807 - val_binary_accuracy: 0.5854\n",
            "Epoch 57/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6783 - binary_accuracy: 0.5833 - val_loss: 0.6806 - val_binary_accuracy: 0.5843\n",
            "Epoch 58/1000\n",
            "6974/6974 [==============================] - 0s 48us/sample - loss: 0.6781 - binary_accuracy: 0.5826 - val_loss: 0.6805 - val_binary_accuracy: 0.5837\n",
            "Epoch 59/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6779 - binary_accuracy: 0.5823 - val_loss: 0.6804 - val_binary_accuracy: 0.5837\n",
            "Epoch 60/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6778 - binary_accuracy: 0.5824 - val_loss: 0.6802 - val_binary_accuracy: 0.5849\n",
            "Epoch 61/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6776 - binary_accuracy: 0.5847 - val_loss: 0.6801 - val_binary_accuracy: 0.5837\n",
            "Epoch 62/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6775 - binary_accuracy: 0.5852 - val_loss: 0.6800 - val_binary_accuracy: 0.5860\n",
            "Epoch 63/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6773 - binary_accuracy: 0.5850 - val_loss: 0.6799 - val_binary_accuracy: 0.5872\n",
            "Epoch 64/1000\n",
            "6974/6974 [==============================] - 0s 48us/sample - loss: 0.6772 - binary_accuracy: 0.5852 - val_loss: 0.6798 - val_binary_accuracy: 0.5866\n",
            "Epoch 65/1000\n",
            "6974/6974 [==============================] - 0s 48us/sample - loss: 0.6770 - binary_accuracy: 0.5850 - val_loss: 0.6797 - val_binary_accuracy: 0.5883\n",
            "Epoch 66/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6768 - binary_accuracy: 0.5868 - val_loss: 0.6796 - val_binary_accuracy: 0.5877\n",
            "Epoch 67/1000\n",
            "6974/6974 [==============================] - 0s 48us/sample - loss: 0.6767 - binary_accuracy: 0.5866 - val_loss: 0.6795 - val_binary_accuracy: 0.5877\n",
            "Epoch 68/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6765 - binary_accuracy: 0.5863 - val_loss: 0.6793 - val_binary_accuracy: 0.5889\n",
            "Epoch 69/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6764 - binary_accuracy: 0.5869 - val_loss: 0.6792 - val_binary_accuracy: 0.5894\n",
            "Epoch 70/1000\n",
            "6974/6974 [==============================] - 0s 47us/sample - loss: 0.6762 - binary_accuracy: 0.5873 - val_loss: 0.6791 - val_binary_accuracy: 0.5883\n",
            "Epoch 71/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6761 - binary_accuracy: 0.5868 - val_loss: 0.6790 - val_binary_accuracy: 0.5883\n",
            "Epoch 72/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6759 - binary_accuracy: 0.5869 - val_loss: 0.6789 - val_binary_accuracy: 0.5883\n",
            "Epoch 73/1000\n",
            "6974/6974 [==============================] - 0s 48us/sample - loss: 0.6758 - binary_accuracy: 0.5882 - val_loss: 0.6788 - val_binary_accuracy: 0.5900\n",
            "Epoch 74/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6756 - binary_accuracy: 0.5880 - val_loss: 0.6787 - val_binary_accuracy: 0.5900\n",
            "Epoch 75/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6755 - binary_accuracy: 0.5875 - val_loss: 0.6786 - val_binary_accuracy: 0.5900\n",
            "Epoch 76/1000\n",
            "6974/6974 [==============================] - 0s 48us/sample - loss: 0.6753 - binary_accuracy: 0.5876 - val_loss: 0.6785 - val_binary_accuracy: 0.5912\n",
            "Epoch 77/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6752 - binary_accuracy: 0.5879 - val_loss: 0.6784 - val_binary_accuracy: 0.5912\n",
            "Epoch 78/1000\n",
            "6974/6974 [==============================] - 0s 51us/sample - loss: 0.6751 - binary_accuracy: 0.5876 - val_loss: 0.6783 - val_binary_accuracy: 0.5906\n",
            "Epoch 79/1000\n",
            "6974/6974 [==============================] - 0s 48us/sample - loss: 0.6749 - binary_accuracy: 0.5892 - val_loss: 0.6782 - val_binary_accuracy: 0.5900\n",
            "Epoch 80/1000\n",
            "6974/6974 [==============================] - 0s 48us/sample - loss: 0.6748 - binary_accuracy: 0.5876 - val_loss: 0.6781 - val_binary_accuracy: 0.5906\n",
            "Epoch 81/1000\n",
            "6974/6974 [==============================] - 0s 47us/sample - loss: 0.6747 - binary_accuracy: 0.5876 - val_loss: 0.6780 - val_binary_accuracy: 0.5894\n",
            "Epoch 82/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6745 - binary_accuracy: 0.5875 - val_loss: 0.6779 - val_binary_accuracy: 0.5894\n",
            "Epoch 83/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6744 - binary_accuracy: 0.5885 - val_loss: 0.6778 - val_binary_accuracy: 0.5877\n",
            "Epoch 84/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6743 - binary_accuracy: 0.5882 - val_loss: 0.6777 - val_binary_accuracy: 0.5860\n",
            "Epoch 85/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6741 - binary_accuracy: 0.5875 - val_loss: 0.6776 - val_binary_accuracy: 0.5860\n",
            "Epoch 86/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6740 - binary_accuracy: 0.5878 - val_loss: 0.6776 - val_binary_accuracy: 0.5866\n",
            "Epoch 87/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6739 - binary_accuracy: 0.5880 - val_loss: 0.6775 - val_binary_accuracy: 0.5860\n",
            "Epoch 88/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6737 - binary_accuracy: 0.5880 - val_loss: 0.6774 - val_binary_accuracy: 0.5866\n",
            "Epoch 89/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6736 - binary_accuracy: 0.5876 - val_loss: 0.6773 - val_binary_accuracy: 0.5866\n",
            "Epoch 90/1000\n",
            "6974/6974 [==============================] - 0s 51us/sample - loss: 0.6735 - binary_accuracy: 0.5880 - val_loss: 0.6772 - val_binary_accuracy: 0.5877\n",
            "Epoch 91/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6734 - binary_accuracy: 0.5886 - val_loss: 0.6771 - val_binary_accuracy: 0.5877\n",
            "Epoch 92/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6732 - binary_accuracy: 0.5880 - val_loss: 0.6770 - val_binary_accuracy: 0.5900\n",
            "Epoch 93/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6731 - binary_accuracy: 0.5890 - val_loss: 0.6769 - val_binary_accuracy: 0.5917\n",
            "Epoch 94/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6730 - binary_accuracy: 0.5890 - val_loss: 0.6768 - val_binary_accuracy: 0.5917\n",
            "Epoch 95/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6729 - binary_accuracy: 0.5898 - val_loss: 0.6768 - val_binary_accuracy: 0.5912\n",
            "Epoch 96/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6728 - binary_accuracy: 0.5896 - val_loss: 0.6767 - val_binary_accuracy: 0.5906\n",
            "Epoch 97/1000\n",
            "6974/6974 [==============================] - 0s 51us/sample - loss: 0.6727 - binary_accuracy: 0.5882 - val_loss: 0.6766 - val_binary_accuracy: 0.5906\n",
            "Epoch 98/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6725 - binary_accuracy: 0.5890 - val_loss: 0.6765 - val_binary_accuracy: 0.5889\n",
            "Epoch 99/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6724 - binary_accuracy: 0.5885 - val_loss: 0.6764 - val_binary_accuracy: 0.5894\n",
            "Epoch 100/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6723 - binary_accuracy: 0.5888 - val_loss: 0.6763 - val_binary_accuracy: 0.5883\n",
            "Epoch 101/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6722 - binary_accuracy: 0.5902 - val_loss: 0.6763 - val_binary_accuracy: 0.5894\n",
            "Epoch 102/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6721 - binary_accuracy: 0.5886 - val_loss: 0.6762 - val_binary_accuracy: 0.5900\n",
            "Epoch 103/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6720 - binary_accuracy: 0.5890 - val_loss: 0.6761 - val_binary_accuracy: 0.5900\n",
            "Epoch 104/1000\n",
            "6974/6974 [==============================] - 0s 48us/sample - loss: 0.6719 - binary_accuracy: 0.5895 - val_loss: 0.6760 - val_binary_accuracy: 0.5929\n",
            "Epoch 105/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6718 - binary_accuracy: 0.5896 - val_loss: 0.6759 - val_binary_accuracy: 0.5906\n",
            "Epoch 106/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6717 - binary_accuracy: 0.5899 - val_loss: 0.6758 - val_binary_accuracy: 0.5912\n",
            "Epoch 107/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6716 - binary_accuracy: 0.5902 - val_loss: 0.6758 - val_binary_accuracy: 0.5889\n",
            "Epoch 108/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6715 - binary_accuracy: 0.5896 - val_loss: 0.6757 - val_binary_accuracy: 0.5883\n",
            "Epoch 109/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6714 - binary_accuracy: 0.5906 - val_loss: 0.6756 - val_binary_accuracy: 0.5889\n",
            "Epoch 110/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6713 - binary_accuracy: 0.5906 - val_loss: 0.6756 - val_binary_accuracy: 0.5883\n",
            "Epoch 111/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6712 - binary_accuracy: 0.5898 - val_loss: 0.6755 - val_binary_accuracy: 0.5906\n",
            "Epoch 112/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6711 - binary_accuracy: 0.5896 - val_loss: 0.6754 - val_binary_accuracy: 0.5889\n",
            "Epoch 113/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6710 - binary_accuracy: 0.5888 - val_loss: 0.6754 - val_binary_accuracy: 0.5900\n",
            "Epoch 114/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6709 - binary_accuracy: 0.5899 - val_loss: 0.6753 - val_binary_accuracy: 0.5894\n",
            "Epoch 115/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6708 - binary_accuracy: 0.5905 - val_loss: 0.6752 - val_binary_accuracy: 0.5900\n",
            "Epoch 116/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6708 - binary_accuracy: 0.5903 - val_loss: 0.6752 - val_binary_accuracy: 0.5900\n",
            "Epoch 117/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6707 - binary_accuracy: 0.5890 - val_loss: 0.6751 - val_binary_accuracy: 0.5900\n",
            "Epoch 118/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6706 - binary_accuracy: 0.5906 - val_loss: 0.6750 - val_binary_accuracy: 0.5917\n",
            "Epoch 119/1000\n",
            "6974/6974 [==============================] - 0s 51us/sample - loss: 0.6705 - binary_accuracy: 0.5895 - val_loss: 0.6750 - val_binary_accuracy: 0.5929\n",
            "Epoch 120/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6704 - binary_accuracy: 0.5889 - val_loss: 0.6749 - val_binary_accuracy: 0.5912\n",
            "Epoch 121/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6703 - binary_accuracy: 0.5893 - val_loss: 0.6749 - val_binary_accuracy: 0.5912\n",
            "Epoch 122/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6703 - binary_accuracy: 0.5893 - val_loss: 0.6748 - val_binary_accuracy: 0.5923\n",
            "Epoch 123/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6702 - binary_accuracy: 0.5902 - val_loss: 0.6747 - val_binary_accuracy: 0.5935\n",
            "Epoch 124/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6701 - binary_accuracy: 0.5885 - val_loss: 0.6747 - val_binary_accuracy: 0.5935\n",
            "Epoch 125/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6700 - binary_accuracy: 0.5903 - val_loss: 0.6746 - val_binary_accuracy: 0.5940\n",
            "Epoch 126/1000\n",
            "6974/6974 [==============================] - 0s 51us/sample - loss: 0.6700 - binary_accuracy: 0.5898 - val_loss: 0.6746 - val_binary_accuracy: 0.5923\n",
            "Epoch 127/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6699 - binary_accuracy: 0.5902 - val_loss: 0.6745 - val_binary_accuracy: 0.5946\n",
            "Epoch 128/1000\n",
            "6974/6974 [==============================] - 0s 51us/sample - loss: 0.6698 - binary_accuracy: 0.5890 - val_loss: 0.6745 - val_binary_accuracy: 0.5940\n",
            "Epoch 129/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6697 - binary_accuracy: 0.5898 - val_loss: 0.6744 - val_binary_accuracy: 0.5969\n",
            "Epoch 130/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6697 - binary_accuracy: 0.5892 - val_loss: 0.6744 - val_binary_accuracy: 0.5969\n",
            "Epoch 131/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6696 - binary_accuracy: 0.5899 - val_loss: 0.6743 - val_binary_accuracy: 0.5963\n",
            "Epoch 132/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6695 - binary_accuracy: 0.5886 - val_loss: 0.6743 - val_binary_accuracy: 0.5958\n",
            "Epoch 133/1000\n",
            "6974/6974 [==============================] - 0s 51us/sample - loss: 0.6694 - binary_accuracy: 0.5895 - val_loss: 0.6742 - val_binary_accuracy: 0.5952\n",
            "Epoch 134/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6694 - binary_accuracy: 0.5892 - val_loss: 0.6742 - val_binary_accuracy: 0.5963\n",
            "Epoch 135/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6693 - binary_accuracy: 0.5903 - val_loss: 0.6742 - val_binary_accuracy: 0.5958\n",
            "Epoch 136/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6692 - binary_accuracy: 0.5896 - val_loss: 0.6741 - val_binary_accuracy: 0.5952\n",
            "Epoch 137/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6692 - binary_accuracy: 0.5902 - val_loss: 0.6741 - val_binary_accuracy: 0.5952\n",
            "Epoch 138/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6691 - binary_accuracy: 0.5899 - val_loss: 0.6740 - val_binary_accuracy: 0.5952\n",
            "Epoch 139/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6690 - binary_accuracy: 0.5900 - val_loss: 0.6740 - val_binary_accuracy: 0.5946\n",
            "Epoch 140/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6690 - binary_accuracy: 0.5892 - val_loss: 0.6739 - val_binary_accuracy: 0.5969\n",
            "Epoch 141/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6689 - binary_accuracy: 0.5899 - val_loss: 0.6739 - val_binary_accuracy: 0.5952\n",
            "Epoch 142/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6688 - binary_accuracy: 0.5899 - val_loss: 0.6739 - val_binary_accuracy: 0.5946\n",
            "Epoch 143/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6688 - binary_accuracy: 0.5900 - val_loss: 0.6738 - val_binary_accuracy: 0.5952\n",
            "Epoch 144/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6687 - binary_accuracy: 0.5893 - val_loss: 0.6738 - val_binary_accuracy: 0.5952\n",
            "Epoch 145/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6686 - binary_accuracy: 0.5902 - val_loss: 0.6738 - val_binary_accuracy: 0.5940\n",
            "Epoch 146/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6686 - binary_accuracy: 0.5898 - val_loss: 0.6737 - val_binary_accuracy: 0.5952\n",
            "Epoch 147/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6685 - binary_accuracy: 0.5900 - val_loss: 0.6737 - val_binary_accuracy: 0.5958\n",
            "Epoch 148/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6685 - binary_accuracy: 0.5905 - val_loss: 0.6737 - val_binary_accuracy: 0.5963\n",
            "Epoch 149/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6684 - binary_accuracy: 0.5893 - val_loss: 0.6736 - val_binary_accuracy: 0.5969\n",
            "Epoch 150/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6683 - binary_accuracy: 0.5896 - val_loss: 0.6736 - val_binary_accuracy: 0.5969\n",
            "Epoch 151/1000\n",
            "6974/6974 [==============================] - 0s 51us/sample - loss: 0.6683 - binary_accuracy: 0.5902 - val_loss: 0.6736 - val_binary_accuracy: 0.5975\n",
            "Epoch 152/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6683 - binary_accuracy: 0.5900 - val_loss: 0.6735 - val_binary_accuracy: 0.5969\n",
            "Epoch 153/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6682 - binary_accuracy: 0.5895 - val_loss: 0.6735 - val_binary_accuracy: 0.5981\n",
            "Epoch 154/1000\n",
            "6974/6974 [==============================] - 0s 51us/sample - loss: 0.6681 - binary_accuracy: 0.5888 - val_loss: 0.6734 - val_binary_accuracy: 0.5986\n",
            "Epoch 155/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6681 - binary_accuracy: 0.5898 - val_loss: 0.6734 - val_binary_accuracy: 0.5975\n",
            "Epoch 156/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6680 - binary_accuracy: 0.5902 - val_loss: 0.6734 - val_binary_accuracy: 0.5981\n",
            "Epoch 157/1000\n",
            "6974/6974 [==============================] - 0s 51us/sample - loss: 0.6680 - binary_accuracy: 0.5889 - val_loss: 0.6734 - val_binary_accuracy: 0.5986\n",
            "Epoch 158/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6679 - binary_accuracy: 0.5899 - val_loss: 0.6733 - val_binary_accuracy: 0.5963\n",
            "Epoch 159/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6679 - binary_accuracy: 0.5890 - val_loss: 0.6733 - val_binary_accuracy: 0.5992\n",
            "Epoch 160/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6678 - binary_accuracy: 0.5898 - val_loss: 0.6733 - val_binary_accuracy: 0.5975\n",
            "Epoch 161/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6678 - binary_accuracy: 0.5900 - val_loss: 0.6732 - val_binary_accuracy: 0.5986\n",
            "Epoch 162/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6677 - binary_accuracy: 0.5906 - val_loss: 0.6732 - val_binary_accuracy: 0.5998\n",
            "Epoch 163/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6677 - binary_accuracy: 0.5889 - val_loss: 0.6732 - val_binary_accuracy: 0.5992\n",
            "Epoch 164/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6676 - binary_accuracy: 0.5899 - val_loss: 0.6732 - val_binary_accuracy: 0.5992\n",
            "Epoch 165/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6676 - binary_accuracy: 0.5900 - val_loss: 0.6731 - val_binary_accuracy: 0.5986\n",
            "Epoch 166/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6675 - binary_accuracy: 0.5892 - val_loss: 0.6731 - val_binary_accuracy: 0.5986\n",
            "Epoch 167/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6675 - binary_accuracy: 0.5892 - val_loss: 0.6731 - val_binary_accuracy: 0.5992\n",
            "Epoch 168/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6674 - binary_accuracy: 0.5892 - val_loss: 0.6731 - val_binary_accuracy: 0.5986\n",
            "Epoch 169/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6674 - binary_accuracy: 0.5888 - val_loss: 0.6730 - val_binary_accuracy: 0.5981\n",
            "Epoch 170/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6673 - binary_accuracy: 0.5893 - val_loss: 0.6730 - val_binary_accuracy: 0.5992\n",
            "Epoch 171/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6673 - binary_accuracy: 0.5890 - val_loss: 0.6730 - val_binary_accuracy: 0.5981\n",
            "Epoch 172/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6673 - binary_accuracy: 0.5888 - val_loss: 0.6730 - val_binary_accuracy: 0.5986\n",
            "Epoch 173/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6672 - binary_accuracy: 0.5899 - val_loss: 0.6730 - val_binary_accuracy: 0.5975\n",
            "Epoch 174/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6672 - binary_accuracy: 0.5895 - val_loss: 0.6729 - val_binary_accuracy: 0.5986\n",
            "Epoch 175/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6671 - binary_accuracy: 0.5892 - val_loss: 0.6729 - val_binary_accuracy: 0.5986\n",
            "Epoch 176/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6671 - binary_accuracy: 0.5892 - val_loss: 0.6729 - val_binary_accuracy: 0.5981\n",
            "Epoch 177/1000\n",
            "6974/6974 [==============================] - 1s 137us/sample - loss: 0.6670 - binary_accuracy: 0.5895 - val_loss: 0.6729 - val_binary_accuracy: 0.5986\n",
            "Epoch 178/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6670 - binary_accuracy: 0.5899 - val_loss: 0.6728 - val_binary_accuracy: 0.5986\n",
            "Epoch 179/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6670 - binary_accuracy: 0.5899 - val_loss: 0.6728 - val_binary_accuracy: 0.5986\n",
            "Epoch 180/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6669 - binary_accuracy: 0.5899 - val_loss: 0.6728 - val_binary_accuracy: 0.5986\n",
            "Epoch 181/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6669 - binary_accuracy: 0.5900 - val_loss: 0.6728 - val_binary_accuracy: 0.5981\n",
            "Epoch 182/1000\n",
            "6974/6974 [==============================] - 0s 49us/sample - loss: 0.6668 - binary_accuracy: 0.5902 - val_loss: 0.6728 - val_binary_accuracy: 0.6003\n",
            "Epoch 183/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6668 - binary_accuracy: 0.5912 - val_loss: 0.6728 - val_binary_accuracy: 0.5992\n",
            "Epoch 184/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6667 - binary_accuracy: 0.5903 - val_loss: 0.6727 - val_binary_accuracy: 0.5986\n",
            "Epoch 185/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6667 - binary_accuracy: 0.5896 - val_loss: 0.6727 - val_binary_accuracy: 0.5998\n",
            "Epoch 186/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6667 - binary_accuracy: 0.5902 - val_loss: 0.6727 - val_binary_accuracy: 0.5998\n",
            "Epoch 187/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6667 - binary_accuracy: 0.5900 - val_loss: 0.6727 - val_binary_accuracy: 0.5981\n",
            "Epoch 188/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6666 - binary_accuracy: 0.5899 - val_loss: 0.6727 - val_binary_accuracy: 0.5992\n",
            "Epoch 189/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6666 - binary_accuracy: 0.5928 - val_loss: 0.6726 - val_binary_accuracy: 0.5998\n",
            "Epoch 190/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6665 - binary_accuracy: 0.5900 - val_loss: 0.6726 - val_binary_accuracy: 0.5992\n",
            "Epoch 191/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6665 - binary_accuracy: 0.5911 - val_loss: 0.6726 - val_binary_accuracy: 0.5969\n",
            "Epoch 192/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6665 - binary_accuracy: 0.5916 - val_loss: 0.6726 - val_binary_accuracy: 0.5981\n",
            "Epoch 193/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6664 - binary_accuracy: 0.5913 - val_loss: 0.6726 - val_binary_accuracy: 0.5986\n",
            "Epoch 194/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6664 - binary_accuracy: 0.5918 - val_loss: 0.6726 - val_binary_accuracy: 0.5992\n",
            "Epoch 195/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6663 - binary_accuracy: 0.5922 - val_loss: 0.6725 - val_binary_accuracy: 0.5986\n",
            "Epoch 196/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6663 - binary_accuracy: 0.5911 - val_loss: 0.6725 - val_binary_accuracy: 0.5998\n",
            "Epoch 197/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6663 - binary_accuracy: 0.5929 - val_loss: 0.6725 - val_binary_accuracy: 0.5992\n",
            "Epoch 198/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6663 - binary_accuracy: 0.5916 - val_loss: 0.6725 - val_binary_accuracy: 0.5998\n",
            "Epoch 199/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6662 - binary_accuracy: 0.5911 - val_loss: 0.6725 - val_binary_accuracy: 0.6003\n",
            "Epoch 200/1000\n",
            "6974/6974 [==============================] - 0s 51us/sample - loss: 0.6662 - binary_accuracy: 0.5928 - val_loss: 0.6725 - val_binary_accuracy: 0.6003\n",
            "Epoch 201/1000\n",
            "6974/6974 [==============================] - 0s 51us/sample - loss: 0.6661 - binary_accuracy: 0.5922 - val_loss: 0.6724 - val_binary_accuracy: 0.5998\n",
            "Epoch 202/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6661 - binary_accuracy: 0.5919 - val_loss: 0.6724 - val_binary_accuracy: 0.5998\n",
            "Epoch 203/1000\n",
            "6974/6974 [==============================] - 0s 50us/sample - loss: 0.6661 - binary_accuracy: 0.5929 - val_loss: 0.6724 - val_binary_accuracy: 0.5998\n",
            "Epoch 204/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6660 - binary_accuracy: 0.5918 - val_loss: 0.6724 - val_binary_accuracy: 0.5992\n",
            "Epoch 205/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6660 - binary_accuracy: 0.5912 - val_loss: 0.6724 - val_binary_accuracy: 0.5986\n",
            "Epoch 206/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6660 - binary_accuracy: 0.5913 - val_loss: 0.6724 - val_binary_accuracy: 0.5992\n",
            "Epoch 207/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6659 - binary_accuracy: 0.5913 - val_loss: 0.6723 - val_binary_accuracy: 0.6015\n",
            "Epoch 208/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6659 - binary_accuracy: 0.5925 - val_loss: 0.6723 - val_binary_accuracy: 0.5992\n",
            "Epoch 209/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6659 - binary_accuracy: 0.5926 - val_loss: 0.6723 - val_binary_accuracy: 0.5986\n",
            "Epoch 210/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6658 - binary_accuracy: 0.5923 - val_loss: 0.6723 - val_binary_accuracy: 0.5992\n",
            "Epoch 211/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6658 - binary_accuracy: 0.5936 - val_loss: 0.6723 - val_binary_accuracy: 0.5992\n",
            "Epoch 212/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6658 - binary_accuracy: 0.5921 - val_loss: 0.6722 - val_binary_accuracy: 0.5986\n",
            "Epoch 213/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6657 - binary_accuracy: 0.5939 - val_loss: 0.6722 - val_binary_accuracy: 0.5992\n",
            "Epoch 214/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6657 - binary_accuracy: 0.5922 - val_loss: 0.6722 - val_binary_accuracy: 0.5986\n",
            "Epoch 215/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6657 - binary_accuracy: 0.5935 - val_loss: 0.6722 - val_binary_accuracy: 0.5981\n",
            "Epoch 216/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6657 - binary_accuracy: 0.5922 - val_loss: 0.6722 - val_binary_accuracy: 0.5992\n",
            "Epoch 217/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6656 - binary_accuracy: 0.5921 - val_loss: 0.6722 - val_binary_accuracy: 0.5986\n",
            "Epoch 218/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6656 - binary_accuracy: 0.5926 - val_loss: 0.6721 - val_binary_accuracy: 0.5975\n",
            "Epoch 219/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6656 - binary_accuracy: 0.5938 - val_loss: 0.6721 - val_binary_accuracy: 0.5986\n",
            "Epoch 220/1000\n",
            "6974/6974 [==============================] - 0s 52us/sample - loss: 0.6655 - binary_accuracy: 0.5928 - val_loss: 0.6721 - val_binary_accuracy: 0.5981\n",
            "Epoch 221/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6655 - binary_accuracy: 0.5926 - val_loss: 0.6721 - val_binary_accuracy: 0.5969\n",
            "Epoch 222/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6655 - binary_accuracy: 0.5939 - val_loss: 0.6721 - val_binary_accuracy: 0.5975\n",
            "Epoch 223/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6654 - binary_accuracy: 0.5935 - val_loss: 0.6721 - val_binary_accuracy: 0.5975\n",
            "Epoch 224/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6654 - binary_accuracy: 0.5931 - val_loss: 0.6721 - val_binary_accuracy: 0.5986\n",
            "Epoch 225/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6654 - binary_accuracy: 0.5931 - val_loss: 0.6720 - val_binary_accuracy: 0.5969\n",
            "Epoch 226/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6654 - binary_accuracy: 0.5933 - val_loss: 0.6720 - val_binary_accuracy: 0.5969\n",
            "Epoch 227/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6653 - binary_accuracy: 0.5925 - val_loss: 0.6720 - val_binary_accuracy: 0.5969\n",
            "Epoch 228/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6653 - binary_accuracy: 0.5945 - val_loss: 0.6720 - val_binary_accuracy: 0.5981\n",
            "Epoch 229/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6653 - binary_accuracy: 0.5932 - val_loss: 0.6720 - val_binary_accuracy: 0.5975\n",
            "Epoch 230/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6652 - binary_accuracy: 0.5951 - val_loss: 0.6720 - val_binary_accuracy: 0.5975\n",
            "Epoch 231/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6652 - binary_accuracy: 0.5932 - val_loss: 0.6719 - val_binary_accuracy: 0.5975\n",
            "Epoch 232/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6652 - binary_accuracy: 0.5942 - val_loss: 0.6719 - val_binary_accuracy: 0.5969\n",
            "Epoch 233/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6652 - binary_accuracy: 0.5942 - val_loss: 0.6719 - val_binary_accuracy: 0.5963\n",
            "Epoch 234/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6651 - binary_accuracy: 0.5951 - val_loss: 0.6719 - val_binary_accuracy: 0.5963\n",
            "Epoch 235/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6651 - binary_accuracy: 0.5945 - val_loss: 0.6719 - val_binary_accuracy: 0.5969\n",
            "Epoch 236/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6651 - binary_accuracy: 0.5944 - val_loss: 0.6719 - val_binary_accuracy: 0.5958\n",
            "Epoch 237/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6650 - binary_accuracy: 0.5946 - val_loss: 0.6718 - val_binary_accuracy: 0.5963\n",
            "Epoch 238/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6650 - binary_accuracy: 0.5958 - val_loss: 0.6718 - val_binary_accuracy: 0.5975\n",
            "Epoch 239/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6650 - binary_accuracy: 0.5946 - val_loss: 0.6718 - val_binary_accuracy: 0.5958\n",
            "Epoch 240/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6650 - binary_accuracy: 0.5944 - val_loss: 0.6718 - val_binary_accuracy: 0.5963\n",
            "Epoch 241/1000\n",
            "6974/6974 [==============================] - 0s 54us/sample - loss: 0.6649 - binary_accuracy: 0.5952 - val_loss: 0.6718 - val_binary_accuracy: 0.5963\n",
            "Epoch 242/1000\n",
            "6974/6974 [==============================] - 1s 156us/sample - loss: 0.6649 - binary_accuracy: 0.5941 - val_loss: 0.6718 - val_binary_accuracy: 0.5969\n",
            "Epoch 243/1000\n",
            "6974/6974 [==============================] - 1s 84us/sample - loss: 0.6649 - binary_accuracy: 0.5958 - val_loss: 0.6718 - val_binary_accuracy: 0.5969\n",
            "Epoch 244/1000\n",
            "6974/6974 [==============================] - 1s 123us/sample - loss: 0.6649 - binary_accuracy: 0.5956 - val_loss: 0.6717 - val_binary_accuracy: 0.5969\n",
            "Epoch 245/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6649 - binary_accuracy: 0.5948 - val_loss: 0.6717 - val_binary_accuracy: 0.5975\n",
            "Epoch 246/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6648 - binary_accuracy: 0.5946 - val_loss: 0.6717 - val_binary_accuracy: 0.5969\n",
            "Epoch 247/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6648 - binary_accuracy: 0.5949 - val_loss: 0.6717 - val_binary_accuracy: 0.5975\n",
            "Epoch 248/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6648 - binary_accuracy: 0.5949 - val_loss: 0.6717 - val_binary_accuracy: 0.5975\n",
            "Epoch 249/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6647 - binary_accuracy: 0.5952 - val_loss: 0.6717 - val_binary_accuracy: 0.5969\n",
            "Epoch 250/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6647 - binary_accuracy: 0.5948 - val_loss: 0.6716 - val_binary_accuracy: 0.5963\n",
            "Epoch 251/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6647 - binary_accuracy: 0.5956 - val_loss: 0.6716 - val_binary_accuracy: 0.5963\n",
            "Epoch 252/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6647 - binary_accuracy: 0.5945 - val_loss: 0.6716 - val_binary_accuracy: 0.5958\n",
            "Epoch 253/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6646 - binary_accuracy: 0.5951 - val_loss: 0.6716 - val_binary_accuracy: 0.5975\n",
            "Epoch 254/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6646 - binary_accuracy: 0.5951 - val_loss: 0.6716 - val_binary_accuracy: 0.5975\n",
            "Epoch 255/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6646 - binary_accuracy: 0.5961 - val_loss: 0.6716 - val_binary_accuracy: 0.5952\n",
            "Epoch 256/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6646 - binary_accuracy: 0.5952 - val_loss: 0.6715 - val_binary_accuracy: 0.5952\n",
            "Epoch 257/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6645 - binary_accuracy: 0.5952 - val_loss: 0.6715 - val_binary_accuracy: 0.5958\n",
            "Epoch 258/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6645 - binary_accuracy: 0.5955 - val_loss: 0.6715 - val_binary_accuracy: 0.5975\n",
            "Epoch 259/1000\n",
            "6974/6974 [==============================] - 0s 59us/sample - loss: 0.6645 - binary_accuracy: 0.5954 - val_loss: 0.6715 - val_binary_accuracy: 0.5958\n",
            "Epoch 260/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6645 - binary_accuracy: 0.5955 - val_loss: 0.6715 - val_binary_accuracy: 0.5963\n",
            "Epoch 261/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6645 - binary_accuracy: 0.5964 - val_loss: 0.6715 - val_binary_accuracy: 0.5969\n",
            "Epoch 262/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6644 - binary_accuracy: 0.5964 - val_loss: 0.6715 - val_binary_accuracy: 0.5969\n",
            "Epoch 263/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6644 - binary_accuracy: 0.5956 - val_loss: 0.6715 - val_binary_accuracy: 0.5981\n",
            "Epoch 264/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6643 - binary_accuracy: 0.5962 - val_loss: 0.6715 - val_binary_accuracy: 0.5975\n",
            "Epoch 265/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6643 - binary_accuracy: 0.5952 - val_loss: 0.6714 - val_binary_accuracy: 0.5975\n",
            "Epoch 266/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6643 - binary_accuracy: 0.5952 - val_loss: 0.6714 - val_binary_accuracy: 0.5981\n",
            "Epoch 267/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6643 - binary_accuracy: 0.5959 - val_loss: 0.6714 - val_binary_accuracy: 0.5969\n",
            "Epoch 268/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6643 - binary_accuracy: 0.5959 - val_loss: 0.6714 - val_binary_accuracy: 0.5969\n",
            "Epoch 269/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6642 - binary_accuracy: 0.5966 - val_loss: 0.6714 - val_binary_accuracy: 0.5975\n",
            "Epoch 270/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6642 - binary_accuracy: 0.5964 - val_loss: 0.6714 - val_binary_accuracy: 0.5981\n",
            "Epoch 271/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6642 - binary_accuracy: 0.5966 - val_loss: 0.6714 - val_binary_accuracy: 0.5981\n",
            "Epoch 272/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6642 - binary_accuracy: 0.5959 - val_loss: 0.6713 - val_binary_accuracy: 0.5975\n",
            "Epoch 273/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6642 - binary_accuracy: 0.5964 - val_loss: 0.6713 - val_binary_accuracy: 0.5963\n",
            "Epoch 274/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6641 - binary_accuracy: 0.5961 - val_loss: 0.6713 - val_binary_accuracy: 0.5963\n",
            "Epoch 275/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6641 - binary_accuracy: 0.5951 - val_loss: 0.6713 - val_binary_accuracy: 0.5969\n",
            "Epoch 276/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6641 - binary_accuracy: 0.5956 - val_loss: 0.6713 - val_binary_accuracy: 0.5946\n",
            "Epoch 277/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6641 - binary_accuracy: 0.5966 - val_loss: 0.6713 - val_binary_accuracy: 0.5969\n",
            "Epoch 278/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6640 - binary_accuracy: 0.5959 - val_loss: 0.6713 - val_binary_accuracy: 0.5940\n",
            "Epoch 279/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6640 - binary_accuracy: 0.5968 - val_loss: 0.6713 - val_binary_accuracy: 0.5952\n",
            "Epoch 280/1000\n",
            "6974/6974 [==============================] - 1s 149us/sample - loss: 0.6640 - binary_accuracy: 0.5968 - val_loss: 0.6712 - val_binary_accuracy: 0.5969\n",
            "Epoch 281/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6640 - binary_accuracy: 0.5959 - val_loss: 0.6712 - val_binary_accuracy: 0.5952\n",
            "Epoch 282/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6640 - binary_accuracy: 0.5965 - val_loss: 0.6712 - val_binary_accuracy: 0.5969\n",
            "Epoch 283/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6639 - binary_accuracy: 0.5964 - val_loss: 0.6712 - val_binary_accuracy: 0.5969\n",
            "Epoch 284/1000\n",
            "6974/6974 [==============================] - 0s 59us/sample - loss: 0.6639 - binary_accuracy: 0.5971 - val_loss: 0.6712 - val_binary_accuracy: 0.5963\n",
            "Epoch 285/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6639 - binary_accuracy: 0.5969 - val_loss: 0.6712 - val_binary_accuracy: 0.5958\n",
            "Epoch 286/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6639 - binary_accuracy: 0.5968 - val_loss: 0.6712 - val_binary_accuracy: 0.5958\n",
            "Epoch 287/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6639 - binary_accuracy: 0.5966 - val_loss: 0.6712 - val_binary_accuracy: 0.5958\n",
            "Epoch 288/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6638 - binary_accuracy: 0.5975 - val_loss: 0.6711 - val_binary_accuracy: 0.5952\n",
            "Epoch 289/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6638 - binary_accuracy: 0.5964 - val_loss: 0.6711 - val_binary_accuracy: 0.5952\n",
            "Epoch 290/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6638 - binary_accuracy: 0.5974 - val_loss: 0.6711 - val_binary_accuracy: 0.5958\n",
            "Epoch 291/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6638 - binary_accuracy: 0.5969 - val_loss: 0.6711 - val_binary_accuracy: 0.5952\n",
            "Epoch 292/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6638 - binary_accuracy: 0.5974 - val_loss: 0.6711 - val_binary_accuracy: 0.5952\n",
            "Epoch 293/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6638 - binary_accuracy: 0.5974 - val_loss: 0.6711 - val_binary_accuracy: 0.5958\n",
            "Epoch 294/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6637 - binary_accuracy: 0.5966 - val_loss: 0.6711 - val_binary_accuracy: 0.5958\n",
            "Epoch 295/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6637 - binary_accuracy: 0.5978 - val_loss: 0.6710 - val_binary_accuracy: 0.5958\n",
            "Epoch 296/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6637 - binary_accuracy: 0.5985 - val_loss: 0.6710 - val_binary_accuracy: 0.5958\n",
            "Epoch 297/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6637 - binary_accuracy: 0.5982 - val_loss: 0.6710 - val_binary_accuracy: 0.5958\n",
            "Epoch 298/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6636 - binary_accuracy: 0.5972 - val_loss: 0.6710 - val_binary_accuracy: 0.5940\n",
            "Epoch 299/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6636 - binary_accuracy: 0.5971 - val_loss: 0.6710 - val_binary_accuracy: 0.5958\n",
            "Epoch 300/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6636 - binary_accuracy: 0.5984 - val_loss: 0.6710 - val_binary_accuracy: 0.5958\n",
            "Epoch 301/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6636 - binary_accuracy: 0.5978 - val_loss: 0.6710 - val_binary_accuracy: 0.5969\n",
            "Epoch 302/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6636 - binary_accuracy: 0.5979 - val_loss: 0.6710 - val_binary_accuracy: 0.5946\n",
            "Epoch 303/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6636 - binary_accuracy: 0.5981 - val_loss: 0.6710 - val_binary_accuracy: 0.5940\n",
            "Epoch 304/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6635 - binary_accuracy: 0.5976 - val_loss: 0.6709 - val_binary_accuracy: 0.5969\n",
            "Epoch 305/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6635 - binary_accuracy: 0.5978 - val_loss: 0.6709 - val_binary_accuracy: 0.5963\n",
            "Epoch 306/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6635 - binary_accuracy: 0.5982 - val_loss: 0.6709 - val_binary_accuracy: 0.5969\n",
            "Epoch 307/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6635 - binary_accuracy: 0.5981 - val_loss: 0.6709 - val_binary_accuracy: 0.5940\n",
            "Epoch 308/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6635 - binary_accuracy: 0.5974 - val_loss: 0.6709 - val_binary_accuracy: 0.5946\n",
            "Epoch 309/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6635 - binary_accuracy: 0.5979 - val_loss: 0.6709 - val_binary_accuracy: 0.5975\n",
            "Epoch 310/1000\n",
            "6974/6974 [==============================] - 0s 59us/sample - loss: 0.6634 - binary_accuracy: 0.5987 - val_loss: 0.6709 - val_binary_accuracy: 0.5952\n",
            "Epoch 311/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6634 - binary_accuracy: 0.5979 - val_loss: 0.6709 - val_binary_accuracy: 0.5946\n",
            "Epoch 312/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6634 - binary_accuracy: 0.5989 - val_loss: 0.6709 - val_binary_accuracy: 0.5946\n",
            "Epoch 313/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6634 - binary_accuracy: 0.5988 - val_loss: 0.6708 - val_binary_accuracy: 0.5952\n",
            "Epoch 314/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6633 - binary_accuracy: 0.5978 - val_loss: 0.6708 - val_binary_accuracy: 0.5935\n",
            "Epoch 315/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6633 - binary_accuracy: 0.5991 - val_loss: 0.6708 - val_binary_accuracy: 0.5946\n",
            "Epoch 316/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6633 - binary_accuracy: 0.5982 - val_loss: 0.6708 - val_binary_accuracy: 0.5952\n",
            "Epoch 317/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6633 - binary_accuracy: 0.5989 - val_loss: 0.6708 - val_binary_accuracy: 0.5935\n",
            "Epoch 318/1000\n",
            "6974/6974 [==============================] - 0s 66us/sample - loss: 0.6633 - binary_accuracy: 0.5961 - val_loss: 0.6708 - val_binary_accuracy: 0.5963\n",
            "Epoch 319/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6633 - binary_accuracy: 0.5995 - val_loss: 0.6708 - val_binary_accuracy: 0.5958\n",
            "Epoch 320/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6633 - binary_accuracy: 0.5984 - val_loss: 0.6708 - val_binary_accuracy: 0.5929\n",
            "Epoch 321/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6632 - binary_accuracy: 0.5988 - val_loss: 0.6708 - val_binary_accuracy: 0.5935\n",
            "Epoch 322/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6632 - binary_accuracy: 0.5982 - val_loss: 0.6707 - val_binary_accuracy: 0.5935\n",
            "Epoch 323/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6632 - binary_accuracy: 0.5995 - val_loss: 0.6707 - val_binary_accuracy: 0.5958\n",
            "Epoch 324/1000\n",
            "6974/6974 [==============================] - 0s 59us/sample - loss: 0.6632 - binary_accuracy: 0.5994 - val_loss: 0.6707 - val_binary_accuracy: 0.5958\n",
            "Epoch 325/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6632 - binary_accuracy: 0.5997 - val_loss: 0.6707 - val_binary_accuracy: 0.5963\n",
            "Epoch 326/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6632 - binary_accuracy: 0.5995 - val_loss: 0.6707 - val_binary_accuracy: 0.5963\n",
            "Epoch 327/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6631 - binary_accuracy: 0.6001 - val_loss: 0.6707 - val_binary_accuracy: 0.5975\n",
            "Epoch 328/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6631 - binary_accuracy: 0.5995 - val_loss: 0.6707 - val_binary_accuracy: 0.5969\n",
            "Epoch 329/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6631 - binary_accuracy: 0.5992 - val_loss: 0.6707 - val_binary_accuracy: 0.5952\n",
            "Epoch 330/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6631 - binary_accuracy: 0.5995 - val_loss: 0.6707 - val_binary_accuracy: 0.5958\n",
            "Epoch 331/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6631 - binary_accuracy: 0.5995 - val_loss: 0.6707 - val_binary_accuracy: 0.5952\n",
            "Epoch 332/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6631 - binary_accuracy: 0.5997 - val_loss: 0.6707 - val_binary_accuracy: 0.5946\n",
            "Epoch 333/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6630 - binary_accuracy: 0.5997 - val_loss: 0.6707 - val_binary_accuracy: 0.5963\n",
            "Epoch 334/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6630 - binary_accuracy: 0.5997 - val_loss: 0.6707 - val_binary_accuracy: 0.5963\n",
            "Epoch 335/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6630 - binary_accuracy: 0.5991 - val_loss: 0.6706 - val_binary_accuracy: 0.5952\n",
            "Epoch 336/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6630 - binary_accuracy: 0.6001 - val_loss: 0.6706 - val_binary_accuracy: 0.5958\n",
            "Epoch 337/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6630 - binary_accuracy: 0.5995 - val_loss: 0.6706 - val_binary_accuracy: 0.5952\n",
            "Epoch 338/1000\n",
            "6974/6974 [==============================] - 0s 59us/sample - loss: 0.6630 - binary_accuracy: 0.6004 - val_loss: 0.6706 - val_binary_accuracy: 0.5963\n",
            "Epoch 339/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6630 - binary_accuracy: 0.5999 - val_loss: 0.6706 - val_binary_accuracy: 0.5963\n",
            "Epoch 340/1000\n",
            "6974/6974 [==============================] - 0s 55us/sample - loss: 0.6629 - binary_accuracy: 0.6005 - val_loss: 0.6706 - val_binary_accuracy: 0.5952\n",
            "Epoch 341/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6629 - binary_accuracy: 0.6011 - val_loss: 0.6706 - val_binary_accuracy: 0.5963\n",
            "Epoch 342/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6629 - binary_accuracy: 0.6001 - val_loss: 0.6706 - val_binary_accuracy: 0.5975\n",
            "Epoch 343/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6629 - binary_accuracy: 0.5995 - val_loss: 0.6706 - val_binary_accuracy: 0.5963\n",
            "Epoch 344/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6629 - binary_accuracy: 0.5998 - val_loss: 0.6706 - val_binary_accuracy: 0.5963\n",
            "Epoch 345/1000\n",
            "6974/6974 [==============================] - 0s 59us/sample - loss: 0.6629 - binary_accuracy: 0.6005 - val_loss: 0.6706 - val_binary_accuracy: 0.5969\n",
            "Epoch 346/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6628 - binary_accuracy: 0.5999 - val_loss: 0.6705 - val_binary_accuracy: 0.5975\n",
            "Epoch 347/1000\n",
            "6974/6974 [==============================] - 0s 53us/sample - loss: 0.6628 - binary_accuracy: 0.6001 - val_loss: 0.6705 - val_binary_accuracy: 0.5969\n",
            "Epoch 348/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6628 - binary_accuracy: 0.5997 - val_loss: 0.6705 - val_binary_accuracy: 0.5975\n",
            "Epoch 349/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6628 - binary_accuracy: 0.5999 - val_loss: 0.6705 - val_binary_accuracy: 0.5963\n",
            "Epoch 350/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6628 - binary_accuracy: 0.5984 - val_loss: 0.6705 - val_binary_accuracy: 0.5975\n",
            "Epoch 351/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6628 - binary_accuracy: 0.5992 - val_loss: 0.6705 - val_binary_accuracy: 0.5975\n",
            "Epoch 352/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6627 - binary_accuracy: 0.6005 - val_loss: 0.6705 - val_binary_accuracy: 0.5969\n",
            "Epoch 353/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6627 - binary_accuracy: 0.5991 - val_loss: 0.6705 - val_binary_accuracy: 0.5969\n",
            "Epoch 354/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6627 - binary_accuracy: 0.5989 - val_loss: 0.6705 - val_binary_accuracy: 0.5963\n",
            "Epoch 355/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6627 - binary_accuracy: 0.5998 - val_loss: 0.6705 - val_binary_accuracy: 0.5963\n",
            "Epoch 356/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6627 - binary_accuracy: 0.5999 - val_loss: 0.6705 - val_binary_accuracy: 0.5975\n",
            "Epoch 357/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6627 - binary_accuracy: 0.5994 - val_loss: 0.6705 - val_binary_accuracy: 0.5975\n",
            "Epoch 358/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6627 - binary_accuracy: 0.6001 - val_loss: 0.6705 - val_binary_accuracy: 0.5969\n",
            "Epoch 359/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6627 - binary_accuracy: 0.5995 - val_loss: 0.6705 - val_binary_accuracy: 0.5975\n",
            "Epoch 360/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6626 - binary_accuracy: 0.5997 - val_loss: 0.6705 - val_binary_accuracy: 0.5981\n",
            "Epoch 361/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6626 - binary_accuracy: 0.5998 - val_loss: 0.6705 - val_binary_accuracy: 0.5981\n",
            "Epoch 362/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6626 - binary_accuracy: 0.6008 - val_loss: 0.6705 - val_binary_accuracy: 0.5981\n",
            "Epoch 363/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6626 - binary_accuracy: 0.6005 - val_loss: 0.6704 - val_binary_accuracy: 0.5981\n",
            "Epoch 364/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6626 - binary_accuracy: 0.6005 - val_loss: 0.6704 - val_binary_accuracy: 0.5975\n",
            "Epoch 365/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6625 - binary_accuracy: 0.6001 - val_loss: 0.6704 - val_binary_accuracy: 0.5981\n",
            "Epoch 366/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6625 - binary_accuracy: 0.6001 - val_loss: 0.6704 - val_binary_accuracy: 0.5986\n",
            "Epoch 367/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6625 - binary_accuracy: 0.6001 - val_loss: 0.6704 - val_binary_accuracy: 0.5981\n",
            "Epoch 368/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6625 - binary_accuracy: 0.6002 - val_loss: 0.6704 - val_binary_accuracy: 0.5975\n",
            "Epoch 369/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6625 - binary_accuracy: 0.5997 - val_loss: 0.6704 - val_binary_accuracy: 0.5975\n",
            "Epoch 370/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6625 - binary_accuracy: 0.6001 - val_loss: 0.6704 - val_binary_accuracy: 0.5969\n",
            "Epoch 371/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6625 - binary_accuracy: 0.6001 - val_loss: 0.6704 - val_binary_accuracy: 0.5975\n",
            "Epoch 372/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6625 - binary_accuracy: 0.5998 - val_loss: 0.6704 - val_binary_accuracy: 0.5986\n",
            "Epoch 373/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6625 - binary_accuracy: 0.6008 - val_loss: 0.6704 - val_binary_accuracy: 0.5969\n",
            "Epoch 374/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6624 - binary_accuracy: 0.6001 - val_loss: 0.6704 - val_binary_accuracy: 0.5981\n",
            "Epoch 375/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6624 - binary_accuracy: 0.6001 - val_loss: 0.6704 - val_binary_accuracy: 0.5998\n",
            "Epoch 376/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6624 - binary_accuracy: 0.6005 - val_loss: 0.6704 - val_binary_accuracy: 0.5992\n",
            "Epoch 377/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6624 - binary_accuracy: 0.6005 - val_loss: 0.6703 - val_binary_accuracy: 0.6003\n",
            "Epoch 378/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6624 - binary_accuracy: 0.6007 - val_loss: 0.6703 - val_binary_accuracy: 0.5981\n",
            "Epoch 379/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6624 - binary_accuracy: 0.6012 - val_loss: 0.6703 - val_binary_accuracy: 0.5992\n",
            "Epoch 380/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6624 - binary_accuracy: 0.6004 - val_loss: 0.6704 - val_binary_accuracy: 0.6003\n",
            "Epoch 381/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6624 - binary_accuracy: 0.6012 - val_loss: 0.6703 - val_binary_accuracy: 0.5986\n",
            "Epoch 382/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6624 - binary_accuracy: 0.5998 - val_loss: 0.6703 - val_binary_accuracy: 0.5992\n",
            "Epoch 383/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6623 - binary_accuracy: 0.6002 - val_loss: 0.6703 - val_binary_accuracy: 0.5986\n",
            "Epoch 384/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6623 - binary_accuracy: 0.6009 - val_loss: 0.6703 - val_binary_accuracy: 0.6003\n",
            "Epoch 385/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6623 - binary_accuracy: 0.6011 - val_loss: 0.6703 - val_binary_accuracy: 0.5992\n",
            "Epoch 386/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6623 - binary_accuracy: 0.6017 - val_loss: 0.6703 - val_binary_accuracy: 0.5992\n",
            "Epoch 387/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6623 - binary_accuracy: 0.6008 - val_loss: 0.6703 - val_binary_accuracy: 0.5992\n",
            "Epoch 388/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6622 - binary_accuracy: 0.6008 - val_loss: 0.6703 - val_binary_accuracy: 0.5998\n",
            "Epoch 389/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6622 - binary_accuracy: 0.6007 - val_loss: 0.6703 - val_binary_accuracy: 0.5992\n",
            "Epoch 390/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6623 - binary_accuracy: 0.6017 - val_loss: 0.6703 - val_binary_accuracy: 0.5992\n",
            "Epoch 391/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6622 - binary_accuracy: 0.6017 - val_loss: 0.6703 - val_binary_accuracy: 0.5992\n",
            "Epoch 392/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6622 - binary_accuracy: 0.6011 - val_loss: 0.6703 - val_binary_accuracy: 0.6015\n",
            "Epoch 393/1000\n",
            "6974/6974 [==============================] - 1s 88us/sample - loss: 0.6622 - binary_accuracy: 0.6011 - val_loss: 0.6703 - val_binary_accuracy: 0.5986\n",
            "Epoch 394/1000\n",
            "6974/6974 [==============================] - 1s 107us/sample - loss: 0.6622 - binary_accuracy: 0.6018 - val_loss: 0.6703 - val_binary_accuracy: 0.6026\n",
            "Epoch 395/1000\n",
            "6974/6974 [==============================] - 1s 120us/sample - loss: 0.6622 - binary_accuracy: 0.6011 - val_loss: 0.6703 - val_binary_accuracy: 0.5998\n",
            "Epoch 396/1000\n",
            "6974/6974 [==============================] - 1s 105us/sample - loss: 0.6622 - binary_accuracy: 0.6014 - val_loss: 0.6703 - val_binary_accuracy: 0.5986\n",
            "Epoch 397/1000\n",
            "6974/6974 [==============================] - 1s 99us/sample - loss: 0.6621 - binary_accuracy: 0.5997 - val_loss: 0.6703 - val_binary_accuracy: 0.6015\n",
            "Epoch 398/1000\n",
            "6974/6974 [==============================] - 1s 94us/sample - loss: 0.6621 - binary_accuracy: 0.6018 - val_loss: 0.6703 - val_binary_accuracy: 0.6021\n",
            "Epoch 399/1000\n",
            "6974/6974 [==============================] - 1s 105us/sample - loss: 0.6621 - binary_accuracy: 0.6020 - val_loss: 0.6702 - val_binary_accuracy: 0.5992\n",
            "Epoch 400/1000\n",
            "6974/6974 [==============================] - 1s 112us/sample - loss: 0.6621 - binary_accuracy: 0.6008 - val_loss: 0.6702 - val_binary_accuracy: 0.5992\n",
            "Epoch 401/1000\n",
            "6974/6974 [==============================] - 1s 106us/sample - loss: 0.6621 - binary_accuracy: 0.6020 - val_loss: 0.6702 - val_binary_accuracy: 0.6015\n",
            "Epoch 402/1000\n",
            "6974/6974 [==============================] - 1s 104us/sample - loss: 0.6621 - binary_accuracy: 0.6017 - val_loss: 0.6702 - val_binary_accuracy: 0.6026\n",
            "Epoch 403/1000\n",
            "6974/6974 [==============================] - 1s 88us/sample - loss: 0.6621 - binary_accuracy: 0.6022 - val_loss: 0.6702 - val_binary_accuracy: 0.5992\n",
            "Epoch 404/1000\n",
            "6974/6974 [==============================] - 1s 142us/sample - loss: 0.6620 - binary_accuracy: 0.6015 - val_loss: 0.6702 - val_binary_accuracy: 0.6015\n",
            "Epoch 405/1000\n",
            "6974/6974 [==============================] - 1s 86us/sample - loss: 0.6620 - binary_accuracy: 0.6017 - val_loss: 0.6702 - val_binary_accuracy: 0.6009\n",
            "Epoch 406/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6620 - binary_accuracy: 0.6021 - val_loss: 0.6702 - val_binary_accuracy: 0.6021\n",
            "Epoch 407/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6620 - binary_accuracy: 0.6018 - val_loss: 0.6702 - val_binary_accuracy: 0.6009\n",
            "Epoch 408/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6620 - binary_accuracy: 0.6020 - val_loss: 0.6702 - val_binary_accuracy: 0.6003\n",
            "Epoch 409/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6620 - binary_accuracy: 0.6021 - val_loss: 0.6702 - val_binary_accuracy: 0.6009\n",
            "Epoch 410/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6620 - binary_accuracy: 0.6024 - val_loss: 0.6702 - val_binary_accuracy: 0.6038\n",
            "Epoch 411/1000\n",
            "6974/6974 [==============================] - 0s 59us/sample - loss: 0.6620 - binary_accuracy: 0.6021 - val_loss: 0.6702 - val_binary_accuracy: 0.6026\n",
            "Epoch 412/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6620 - binary_accuracy: 0.6025 - val_loss: 0.6702 - val_binary_accuracy: 0.6021\n",
            "Epoch 413/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6619 - binary_accuracy: 0.6014 - val_loss: 0.6702 - val_binary_accuracy: 0.6015\n",
            "Epoch 414/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6619 - binary_accuracy: 0.6030 - val_loss: 0.6702 - val_binary_accuracy: 0.6032\n",
            "Epoch 415/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6619 - binary_accuracy: 0.6020 - val_loss: 0.6702 - val_binary_accuracy: 0.6021\n",
            "Epoch 416/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6619 - binary_accuracy: 0.6020 - val_loss: 0.6701 - val_binary_accuracy: 0.6026\n",
            "Epoch 417/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6619 - binary_accuracy: 0.6034 - val_loss: 0.6701 - val_binary_accuracy: 0.6021\n",
            "Epoch 418/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6619 - binary_accuracy: 0.6028 - val_loss: 0.6701 - val_binary_accuracy: 0.6021\n",
            "Epoch 419/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6619 - binary_accuracy: 0.6035 - val_loss: 0.6701 - val_binary_accuracy: 0.6032\n",
            "Epoch 420/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6618 - binary_accuracy: 0.6028 - val_loss: 0.6701 - val_binary_accuracy: 0.6038\n",
            "Epoch 421/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6619 - binary_accuracy: 0.6025 - val_loss: 0.6701 - val_binary_accuracy: 0.6032\n",
            "Epoch 422/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6619 - binary_accuracy: 0.6027 - val_loss: 0.6701 - val_binary_accuracy: 0.6026\n",
            "Epoch 423/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6618 - binary_accuracy: 0.6024 - val_loss: 0.6701 - val_binary_accuracy: 0.6032\n",
            "Epoch 424/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6618 - binary_accuracy: 0.6030 - val_loss: 0.6701 - val_binary_accuracy: 0.6032\n",
            "Epoch 425/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6618 - binary_accuracy: 0.6014 - val_loss: 0.6701 - val_binary_accuracy: 0.6032\n",
            "Epoch 426/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6618 - binary_accuracy: 0.6025 - val_loss: 0.6701 - val_binary_accuracy: 0.6032\n",
            "Epoch 427/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6618 - binary_accuracy: 0.6027 - val_loss: 0.6701 - val_binary_accuracy: 0.6026\n",
            "Epoch 428/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6617 - binary_accuracy: 0.6020 - val_loss: 0.6700 - val_binary_accuracy: 0.6032\n",
            "Epoch 429/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6617 - binary_accuracy: 0.6030 - val_loss: 0.6700 - val_binary_accuracy: 0.6038\n",
            "Epoch 430/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6617 - binary_accuracy: 0.6035 - val_loss: 0.6700 - val_binary_accuracy: 0.6032\n",
            "Epoch 431/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6617 - binary_accuracy: 0.6030 - val_loss: 0.6700 - val_binary_accuracy: 0.6038\n",
            "Epoch 432/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6617 - binary_accuracy: 0.6032 - val_loss: 0.6700 - val_binary_accuracy: 0.6032\n",
            "Epoch 433/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6617 - binary_accuracy: 0.6032 - val_loss: 0.6700 - val_binary_accuracy: 0.6032\n",
            "Epoch 434/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6617 - binary_accuracy: 0.6025 - val_loss: 0.6700 - val_binary_accuracy: 0.6032\n",
            "Epoch 435/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6617 - binary_accuracy: 0.6032 - val_loss: 0.6700 - val_binary_accuracy: 0.6026\n",
            "Epoch 436/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6617 - binary_accuracy: 0.6024 - val_loss: 0.6700 - val_binary_accuracy: 0.6038\n",
            "Epoch 437/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6616 - binary_accuracy: 0.6025 - val_loss: 0.6700 - val_binary_accuracy: 0.6032\n",
            "Epoch 438/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6617 - binary_accuracy: 0.6018 - val_loss: 0.6700 - val_binary_accuracy: 0.6015\n",
            "Epoch 439/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6616 - binary_accuracy: 0.6025 - val_loss: 0.6700 - val_binary_accuracy: 0.6026\n",
            "Epoch 440/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6616 - binary_accuracy: 0.6025 - val_loss: 0.6700 - val_binary_accuracy: 0.6038\n",
            "Epoch 441/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6616 - binary_accuracy: 0.6030 - val_loss: 0.6700 - val_binary_accuracy: 0.6044\n",
            "Epoch 442/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6616 - binary_accuracy: 0.6027 - val_loss: 0.6700 - val_binary_accuracy: 0.6032\n",
            "Epoch 443/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6616 - binary_accuracy: 0.6025 - val_loss: 0.6700 - val_binary_accuracy: 0.6038\n",
            "Epoch 444/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6616 - binary_accuracy: 0.6031 - val_loss: 0.6699 - val_binary_accuracy: 0.6032\n",
            "Epoch 445/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6616 - binary_accuracy: 0.6024 - val_loss: 0.6699 - val_binary_accuracy: 0.6038\n",
            "Epoch 446/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6616 - binary_accuracy: 0.6031 - val_loss: 0.6699 - val_binary_accuracy: 0.6038\n",
            "Epoch 447/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6615 - binary_accuracy: 0.6025 - val_loss: 0.6699 - val_binary_accuracy: 0.6032\n",
            "Epoch 448/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6615 - binary_accuracy: 0.6040 - val_loss: 0.6699 - val_binary_accuracy: 0.6032\n",
            "Epoch 449/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6615 - binary_accuracy: 0.6031 - val_loss: 0.6699 - val_binary_accuracy: 0.6049\n",
            "Epoch 450/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6615 - binary_accuracy: 0.6031 - val_loss: 0.6699 - val_binary_accuracy: 0.6038\n",
            "Epoch 451/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6615 - binary_accuracy: 0.6025 - val_loss: 0.6699 - val_binary_accuracy: 0.6038\n",
            "Epoch 452/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6615 - binary_accuracy: 0.6027 - val_loss: 0.6699 - val_binary_accuracy: 0.6055\n",
            "Epoch 453/1000\n",
            "6974/6974 [==============================] - 0s 59us/sample - loss: 0.6615 - binary_accuracy: 0.6031 - val_loss: 0.6699 - val_binary_accuracy: 0.6055\n",
            "Epoch 454/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6615 - binary_accuracy: 0.6025 - val_loss: 0.6699 - val_binary_accuracy: 0.6044\n",
            "Epoch 455/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6614 - binary_accuracy: 0.6030 - val_loss: 0.6699 - val_binary_accuracy: 0.6044\n",
            "Epoch 456/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6614 - binary_accuracy: 0.6040 - val_loss: 0.6699 - val_binary_accuracy: 0.6044\n",
            "Epoch 457/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6614 - binary_accuracy: 0.6031 - val_loss: 0.6699 - val_binary_accuracy: 0.6067\n",
            "Epoch 458/1000\n",
            "6974/6974 [==============================] - 0s 59us/sample - loss: 0.6614 - binary_accuracy: 0.6035 - val_loss: 0.6699 - val_binary_accuracy: 0.6067\n",
            "Epoch 459/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6614 - binary_accuracy: 0.6035 - val_loss: 0.6699 - val_binary_accuracy: 0.6061\n",
            "Epoch 460/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6614 - binary_accuracy: 0.6034 - val_loss: 0.6699 - val_binary_accuracy: 0.6055\n",
            "Epoch 461/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6614 - binary_accuracy: 0.6037 - val_loss: 0.6699 - val_binary_accuracy: 0.6067\n",
            "Epoch 462/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6614 - binary_accuracy: 0.6028 - val_loss: 0.6699 - val_binary_accuracy: 0.6055\n",
            "Epoch 463/1000\n",
            "6974/6974 [==============================] - 0s 59us/sample - loss: 0.6614 - binary_accuracy: 0.6032 - val_loss: 0.6699 - val_binary_accuracy: 0.6055\n",
            "Epoch 464/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6614 - binary_accuracy: 0.6034 - val_loss: 0.6698 - val_binary_accuracy: 0.6067\n",
            "Epoch 465/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6613 - binary_accuracy: 0.6031 - val_loss: 0.6698 - val_binary_accuracy: 0.6072\n",
            "Epoch 466/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6613 - binary_accuracy: 0.6035 - val_loss: 0.6698 - val_binary_accuracy: 0.6072\n",
            "Epoch 467/1000\n",
            "6974/6974 [==============================] - 0s 59us/sample - loss: 0.6613 - binary_accuracy: 0.6040 - val_loss: 0.6698 - val_binary_accuracy: 0.6072\n",
            "Epoch 468/1000\n",
            "6974/6974 [==============================] - 0s 59us/sample - loss: 0.6613 - binary_accuracy: 0.6028 - val_loss: 0.6698 - val_binary_accuracy: 0.6055\n",
            "Epoch 469/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6613 - binary_accuracy: 0.6030 - val_loss: 0.6698 - val_binary_accuracy: 0.6072\n",
            "Epoch 470/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6613 - binary_accuracy: 0.6032 - val_loss: 0.6698 - val_binary_accuracy: 0.6067\n",
            "Epoch 471/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6613 - binary_accuracy: 0.6025 - val_loss: 0.6698 - val_binary_accuracy: 0.6072\n",
            "Epoch 472/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6613 - binary_accuracy: 0.6038 - val_loss: 0.6698 - val_binary_accuracy: 0.6072\n",
            "Epoch 473/1000\n",
            "6974/6974 [==============================] - 0s 59us/sample - loss: 0.6613 - binary_accuracy: 0.6042 - val_loss: 0.6698 - val_binary_accuracy: 0.6055\n",
            "Epoch 474/1000\n",
            "6974/6974 [==============================] - 0s 59us/sample - loss: 0.6612 - binary_accuracy: 0.6032 - val_loss: 0.6698 - val_binary_accuracy: 0.6055\n",
            "Epoch 475/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6612 - binary_accuracy: 0.6040 - val_loss: 0.6698 - val_binary_accuracy: 0.6067\n",
            "Epoch 476/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6612 - binary_accuracy: 0.6037 - val_loss: 0.6698 - val_binary_accuracy: 0.6067\n",
            "Epoch 477/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6612 - binary_accuracy: 0.6032 - val_loss: 0.6698 - val_binary_accuracy: 0.6055\n",
            "Epoch 478/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6612 - binary_accuracy: 0.6030 - val_loss: 0.6698 - val_binary_accuracy: 0.6078\n",
            "Epoch 479/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6612 - binary_accuracy: 0.6030 - val_loss: 0.6698 - val_binary_accuracy: 0.6067\n",
            "Epoch 480/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6612 - binary_accuracy: 0.6035 - val_loss: 0.6698 - val_binary_accuracy: 0.6072\n",
            "Epoch 481/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6612 - binary_accuracy: 0.6037 - val_loss: 0.6698 - val_binary_accuracy: 0.6072\n",
            "Epoch 482/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6612 - binary_accuracy: 0.6040 - val_loss: 0.6698 - val_binary_accuracy: 0.6072\n",
            "Epoch 483/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6611 - binary_accuracy: 0.6042 - val_loss: 0.6698 - val_binary_accuracy: 0.6072\n",
            "Epoch 484/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6611 - binary_accuracy: 0.6045 - val_loss: 0.6698 - val_binary_accuracy: 0.6072\n",
            "Epoch 485/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6611 - binary_accuracy: 0.6047 - val_loss: 0.6697 - val_binary_accuracy: 0.6061\n",
            "Epoch 486/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6611 - binary_accuracy: 0.6034 - val_loss: 0.6697 - val_binary_accuracy: 0.6078\n",
            "Epoch 487/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6611 - binary_accuracy: 0.6035 - val_loss: 0.6697 - val_binary_accuracy: 0.6078\n",
            "Epoch 488/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6611 - binary_accuracy: 0.6035 - val_loss: 0.6697 - val_binary_accuracy: 0.6078\n",
            "Epoch 489/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6611 - binary_accuracy: 0.6040 - val_loss: 0.6697 - val_binary_accuracy: 0.6084\n",
            "Epoch 490/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6611 - binary_accuracy: 0.6038 - val_loss: 0.6697 - val_binary_accuracy: 0.6072\n",
            "Epoch 491/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6611 - binary_accuracy: 0.6038 - val_loss: 0.6697 - val_binary_accuracy: 0.6072\n",
            "Epoch 492/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6611 - binary_accuracy: 0.6038 - val_loss: 0.6697 - val_binary_accuracy: 0.6072\n",
            "Epoch 493/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6610 - binary_accuracy: 0.6048 - val_loss: 0.6697 - val_binary_accuracy: 0.6078\n",
            "Epoch 494/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6610 - binary_accuracy: 0.6041 - val_loss: 0.6697 - val_binary_accuracy: 0.6084\n",
            "Epoch 495/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6610 - binary_accuracy: 0.6034 - val_loss: 0.6697 - val_binary_accuracy: 0.6089\n",
            "Epoch 496/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6610 - binary_accuracy: 0.6040 - val_loss: 0.6697 - val_binary_accuracy: 0.6089\n",
            "Epoch 497/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6610 - binary_accuracy: 0.6038 - val_loss: 0.6697 - val_binary_accuracy: 0.6078\n",
            "Epoch 498/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6610 - binary_accuracy: 0.6030 - val_loss: 0.6697 - val_binary_accuracy: 0.6089\n",
            "Epoch 499/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6610 - binary_accuracy: 0.6050 - val_loss: 0.6697 - val_binary_accuracy: 0.6089\n",
            "Epoch 500/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6610 - binary_accuracy: 0.6041 - val_loss: 0.6697 - val_binary_accuracy: 0.6089\n",
            "Epoch 501/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6610 - binary_accuracy: 0.6040 - val_loss: 0.6697 - val_binary_accuracy: 0.6084\n",
            "Epoch 502/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6610 - binary_accuracy: 0.6032 - val_loss: 0.6697 - val_binary_accuracy: 0.6095\n",
            "Epoch 503/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6609 - binary_accuracy: 0.6041 - val_loss: 0.6697 - val_binary_accuracy: 0.6095\n",
            "Epoch 504/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6610 - binary_accuracy: 0.6037 - val_loss: 0.6697 - val_binary_accuracy: 0.6101\n",
            "Epoch 505/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6609 - binary_accuracy: 0.6038 - val_loss: 0.6697 - val_binary_accuracy: 0.6084\n",
            "Epoch 506/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6609 - binary_accuracy: 0.6031 - val_loss: 0.6697 - val_binary_accuracy: 0.6101\n",
            "Epoch 507/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6609 - binary_accuracy: 0.6048 - val_loss: 0.6697 - val_binary_accuracy: 0.6089\n",
            "Epoch 508/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6609 - binary_accuracy: 0.6040 - val_loss: 0.6697 - val_binary_accuracy: 0.6078\n",
            "Epoch 509/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6609 - binary_accuracy: 0.6050 - val_loss: 0.6697 - val_binary_accuracy: 0.6095\n",
            "Epoch 510/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6609 - binary_accuracy: 0.6035 - val_loss: 0.6696 - val_binary_accuracy: 0.6107\n",
            "Epoch 511/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6609 - binary_accuracy: 0.6042 - val_loss: 0.6697 - val_binary_accuracy: 0.6107\n",
            "Epoch 512/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6609 - binary_accuracy: 0.6045 - val_loss: 0.6696 - val_binary_accuracy: 0.6095\n",
            "Epoch 513/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6608 - binary_accuracy: 0.6048 - val_loss: 0.6697 - val_binary_accuracy: 0.6078\n",
            "Epoch 514/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6608 - binary_accuracy: 0.6040 - val_loss: 0.6696 - val_binary_accuracy: 0.6112\n",
            "Epoch 515/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6608 - binary_accuracy: 0.6050 - val_loss: 0.6696 - val_binary_accuracy: 0.6101\n",
            "Epoch 516/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6608 - binary_accuracy: 0.6047 - val_loss: 0.6696 - val_binary_accuracy: 0.6095\n",
            "Epoch 517/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6608 - binary_accuracy: 0.6040 - val_loss: 0.6696 - val_binary_accuracy: 0.6095\n",
            "Epoch 518/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6608 - binary_accuracy: 0.6048 - val_loss: 0.6696 - val_binary_accuracy: 0.6095\n",
            "Epoch 519/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6608 - binary_accuracy: 0.6040 - val_loss: 0.6696 - val_binary_accuracy: 0.6095\n",
            "Epoch 520/1000\n",
            "6974/6974 [==============================] - 0s 56us/sample - loss: 0.6607 - binary_accuracy: 0.6045 - val_loss: 0.6696 - val_binary_accuracy: 0.6095\n",
            "Epoch 521/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6607 - binary_accuracy: 0.6047 - val_loss: 0.6696 - val_binary_accuracy: 0.6095\n",
            "Epoch 522/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6607 - binary_accuracy: 0.6045 - val_loss: 0.6696 - val_binary_accuracy: 0.6089\n",
            "Epoch 523/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6607 - binary_accuracy: 0.6048 - val_loss: 0.6696 - val_binary_accuracy: 0.6089\n",
            "Epoch 524/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6607 - binary_accuracy: 0.6040 - val_loss: 0.6696 - val_binary_accuracy: 0.6089\n",
            "Epoch 525/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6607 - binary_accuracy: 0.6044 - val_loss: 0.6696 - val_binary_accuracy: 0.6095\n",
            "Epoch 526/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6607 - binary_accuracy: 0.6041 - val_loss: 0.6696 - val_binary_accuracy: 0.6084\n",
            "Epoch 527/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6607 - binary_accuracy: 0.6052 - val_loss: 0.6696 - val_binary_accuracy: 0.6089\n",
            "Epoch 528/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6607 - binary_accuracy: 0.6051 - val_loss: 0.6696 - val_binary_accuracy: 0.6089\n",
            "Epoch 529/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6607 - binary_accuracy: 0.6045 - val_loss: 0.6696 - val_binary_accuracy: 0.6089\n",
            "Epoch 530/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6607 - binary_accuracy: 0.6051 - val_loss: 0.6696 - val_binary_accuracy: 0.6084\n",
            "Epoch 531/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6607 - binary_accuracy: 0.6040 - val_loss: 0.6696 - val_binary_accuracy: 0.6084\n",
            "Epoch 532/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6607 - binary_accuracy: 0.6035 - val_loss: 0.6696 - val_binary_accuracy: 0.6095\n",
            "Epoch 533/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6606 - binary_accuracy: 0.6041 - val_loss: 0.6696 - val_binary_accuracy: 0.6084\n",
            "Epoch 534/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6606 - binary_accuracy: 0.6057 - val_loss: 0.6696 - val_binary_accuracy: 0.6089\n",
            "Epoch 535/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6606 - binary_accuracy: 0.6042 - val_loss: 0.6696 - val_binary_accuracy: 0.6095\n",
            "Epoch 536/1000\n",
            "6974/6974 [==============================] - 0s 57us/sample - loss: 0.6606 - binary_accuracy: 0.6048 - val_loss: 0.6696 - val_binary_accuracy: 0.6089\n",
            "Epoch 537/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6606 - binary_accuracy: 0.6042 - val_loss: 0.6695 - val_binary_accuracy: 0.6089\n",
            "Epoch 538/1000\n",
            "6974/6974 [==============================] - 0s 59us/sample - loss: 0.6606 - binary_accuracy: 0.6063 - val_loss: 0.6695 - val_binary_accuracy: 0.6089\n",
            "Epoch 539/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6606 - binary_accuracy: 0.6051 - val_loss: 0.6695 - val_binary_accuracy: 0.6095\n",
            "Epoch 540/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6606 - binary_accuracy: 0.6057 - val_loss: 0.6696 - val_binary_accuracy: 0.6101\n",
            "Epoch 541/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6605 - binary_accuracy: 0.6054 - val_loss: 0.6695 - val_binary_accuracy: 0.6101\n",
            "Epoch 542/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6605 - binary_accuracy: 0.6052 - val_loss: 0.6695 - val_binary_accuracy: 0.6084\n",
            "Epoch 543/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6605 - binary_accuracy: 0.6042 - val_loss: 0.6696 - val_binary_accuracy: 0.6101\n",
            "Epoch 544/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6605 - binary_accuracy: 0.6051 - val_loss: 0.6695 - val_binary_accuracy: 0.6101\n",
            "Epoch 545/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6605 - binary_accuracy: 0.6047 - val_loss: 0.6695 - val_binary_accuracy: 0.6101\n",
            "Epoch 546/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6605 - binary_accuracy: 0.6045 - val_loss: 0.6695 - val_binary_accuracy: 0.6101\n",
            "Epoch 547/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6605 - binary_accuracy: 0.6047 - val_loss: 0.6695 - val_binary_accuracy: 0.6107\n",
            "Epoch 548/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6605 - binary_accuracy: 0.6054 - val_loss: 0.6695 - val_binary_accuracy: 0.6095\n",
            "Epoch 549/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6605 - binary_accuracy: 0.6052 - val_loss: 0.6695 - val_binary_accuracy: 0.6095\n",
            "Epoch 550/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6605 - binary_accuracy: 0.6051 - val_loss: 0.6695 - val_binary_accuracy: 0.6101\n",
            "Epoch 551/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6604 - binary_accuracy: 0.6045 - val_loss: 0.6695 - val_binary_accuracy: 0.6107\n",
            "Epoch 552/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6604 - binary_accuracy: 0.6044 - val_loss: 0.6695 - val_binary_accuracy: 0.6095\n",
            "Epoch 553/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6604 - binary_accuracy: 0.6048 - val_loss: 0.6695 - val_binary_accuracy: 0.6101\n",
            "Epoch 554/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6604 - binary_accuracy: 0.6042 - val_loss: 0.6695 - val_binary_accuracy: 0.6107\n",
            "Epoch 555/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6604 - binary_accuracy: 0.6045 - val_loss: 0.6695 - val_binary_accuracy: 0.6101\n",
            "Epoch 556/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6604 - binary_accuracy: 0.6051 - val_loss: 0.6695 - val_binary_accuracy: 0.6095\n",
            "Epoch 557/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6604 - binary_accuracy: 0.6052 - val_loss: 0.6695 - val_binary_accuracy: 0.6101\n",
            "Epoch 558/1000\n",
            "6974/6974 [==============================] - 0s 58us/sample - loss: 0.6604 - binary_accuracy: 0.6060 - val_loss: 0.6695 - val_binary_accuracy: 0.6107\n",
            "Epoch 559/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6604 - binary_accuracy: 0.6041 - val_loss: 0.6695 - val_binary_accuracy: 0.6107\n",
            "Epoch 560/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6604 - binary_accuracy: 0.6044 - val_loss: 0.6695 - val_binary_accuracy: 0.6118\n",
            "Epoch 561/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6604 - binary_accuracy: 0.6057 - val_loss: 0.6695 - val_binary_accuracy: 0.6107\n",
            "Epoch 562/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6604 - binary_accuracy: 0.6031 - val_loss: 0.6695 - val_binary_accuracy: 0.6107\n",
            "Epoch 563/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6603 - binary_accuracy: 0.6038 - val_loss: 0.6695 - val_binary_accuracy: 0.6101\n",
            "Epoch 564/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6603 - binary_accuracy: 0.6052 - val_loss: 0.6695 - val_binary_accuracy: 0.6089\n",
            "Epoch 565/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6603 - binary_accuracy: 0.6065 - val_loss: 0.6695 - val_binary_accuracy: 0.6112\n",
            "Epoch 566/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6603 - binary_accuracy: 0.6035 - val_loss: 0.6695 - val_binary_accuracy: 0.6101\n",
            "Epoch 567/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6603 - binary_accuracy: 0.6058 - val_loss: 0.6695 - val_binary_accuracy: 0.6107\n",
            "Epoch 568/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6603 - binary_accuracy: 0.6028 - val_loss: 0.6695 - val_binary_accuracy: 0.6112\n",
            "Epoch 569/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6603 - binary_accuracy: 0.6052 - val_loss: 0.6695 - val_binary_accuracy: 0.6101\n",
            "Epoch 570/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6603 - binary_accuracy: 0.6052 - val_loss: 0.6695 - val_binary_accuracy: 0.6107\n",
            "Epoch 571/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6602 - binary_accuracy: 0.6050 - val_loss: 0.6695 - val_binary_accuracy: 0.6118\n",
            "Epoch 572/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6602 - binary_accuracy: 0.6044 - val_loss: 0.6695 - val_binary_accuracy: 0.6107\n",
            "Epoch 573/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6602 - binary_accuracy: 0.6034 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "Epoch 574/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6602 - binary_accuracy: 0.6054 - val_loss: 0.6694 - val_binary_accuracy: 0.6089\n",
            "Epoch 575/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6602 - binary_accuracy: 0.6057 - val_loss: 0.6694 - val_binary_accuracy: 0.6101\n",
            "Epoch 576/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6602 - binary_accuracy: 0.6035 - val_loss: 0.6694 - val_binary_accuracy: 0.6101\n",
            "Epoch 577/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6602 - binary_accuracy: 0.6048 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "Epoch 578/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6602 - binary_accuracy: 0.6058 - val_loss: 0.6694 - val_binary_accuracy: 0.6112\n",
            "Epoch 579/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6602 - binary_accuracy: 0.6064 - val_loss: 0.6694 - val_binary_accuracy: 0.6101\n",
            "Epoch 580/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6602 - binary_accuracy: 0.6034 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "Epoch 581/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6602 - binary_accuracy: 0.6048 - val_loss: 0.6695 - val_binary_accuracy: 0.6089\n",
            "Epoch 582/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6602 - binary_accuracy: 0.6048 - val_loss: 0.6694 - val_binary_accuracy: 0.6107\n",
            "Epoch 583/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6602 - binary_accuracy: 0.6044 - val_loss: 0.6694 - val_binary_accuracy: 0.6101\n",
            "Epoch 584/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6601 - binary_accuracy: 0.6054 - val_loss: 0.6694 - val_binary_accuracy: 0.6101\n",
            "Epoch 585/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6601 - binary_accuracy: 0.6032 - val_loss: 0.6694 - val_binary_accuracy: 0.6107\n",
            "Epoch 586/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6601 - binary_accuracy: 0.6042 - val_loss: 0.6694 - val_binary_accuracy: 0.6107\n",
            "Epoch 587/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6601 - binary_accuracy: 0.6044 - val_loss: 0.6694 - val_binary_accuracy: 0.6089\n",
            "Epoch 588/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6601 - binary_accuracy: 0.6054 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "Epoch 589/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6601 - binary_accuracy: 0.6050 - val_loss: 0.6694 - val_binary_accuracy: 0.6089\n",
            "Epoch 590/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6601 - binary_accuracy: 0.6040 - val_loss: 0.6694 - val_binary_accuracy: 0.6107\n",
            "Epoch 591/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6601 - binary_accuracy: 0.6045 - val_loss: 0.6694 - val_binary_accuracy: 0.6101\n",
            "Epoch 592/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6601 - binary_accuracy: 0.6038 - val_loss: 0.6694 - val_binary_accuracy: 0.6107\n",
            "Epoch 593/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6601 - binary_accuracy: 0.6054 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "Epoch 594/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6601 - binary_accuracy: 0.6057 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "Epoch 595/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6600 - binary_accuracy: 0.6044 - val_loss: 0.6694 - val_binary_accuracy: 0.6107\n",
            "Epoch 596/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6600 - binary_accuracy: 0.6052 - val_loss: 0.6694 - val_binary_accuracy: 0.6089\n",
            "Epoch 597/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6600 - binary_accuracy: 0.6052 - val_loss: 0.6694 - val_binary_accuracy: 0.6089\n",
            "Epoch 598/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6600 - binary_accuracy: 0.6035 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "Epoch 599/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6600 - binary_accuracy: 0.6045 - val_loss: 0.6694 - val_binary_accuracy: 0.6101\n",
            "Epoch 600/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6600 - binary_accuracy: 0.6048 - val_loss: 0.6694 - val_binary_accuracy: 0.6101\n",
            "Epoch 601/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6600 - binary_accuracy: 0.6047 - val_loss: 0.6694 - val_binary_accuracy: 0.6101\n",
            "Epoch 602/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6600 - binary_accuracy: 0.6045 - val_loss: 0.6694 - val_binary_accuracy: 0.6084\n",
            "Epoch 603/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6599 - binary_accuracy: 0.6050 - val_loss: 0.6694 - val_binary_accuracy: 0.6089\n",
            "Epoch 604/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6600 - binary_accuracy: 0.6054 - val_loss: 0.6694 - val_binary_accuracy: 0.6101\n",
            "Epoch 605/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6599 - binary_accuracy: 0.6052 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "Epoch 606/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6599 - binary_accuracy: 0.6047 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "Epoch 607/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6599 - binary_accuracy: 0.6047 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "Epoch 608/1000\n",
            "6974/6974 [==============================] - 0s 59us/sample - loss: 0.6599 - binary_accuracy: 0.6035 - val_loss: 0.6694 - val_binary_accuracy: 0.6089\n",
            "Epoch 609/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6599 - binary_accuracy: 0.6051 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "Epoch 610/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6599 - binary_accuracy: 0.6048 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "Epoch 611/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6599 - binary_accuracy: 0.6060 - val_loss: 0.6694 - val_binary_accuracy: 0.6089\n",
            "Epoch 612/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6599 - binary_accuracy: 0.6041 - val_loss: 0.6694 - val_binary_accuracy: 0.6089\n",
            "Epoch 613/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6599 - binary_accuracy: 0.6058 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "Epoch 614/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6598 - binary_accuracy: 0.6051 - val_loss: 0.6694 - val_binary_accuracy: 0.6084\n",
            "Epoch 615/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6599 - binary_accuracy: 0.6044 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "Epoch 616/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6599 - binary_accuracy: 0.6045 - val_loss: 0.6694 - val_binary_accuracy: 0.6089\n",
            "Epoch 617/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6598 - binary_accuracy: 0.6041 - val_loss: 0.6694 - val_binary_accuracy: 0.6089\n",
            "Epoch 618/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6598 - binary_accuracy: 0.6041 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "Epoch 619/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6598 - binary_accuracy: 0.6054 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "Epoch 620/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6598 - binary_accuracy: 0.6051 - val_loss: 0.6694 - val_binary_accuracy: 0.6101\n",
            "Epoch 621/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6598 - binary_accuracy: 0.6048 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "Epoch 622/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6598 - binary_accuracy: 0.6047 - val_loss: 0.6694 - val_binary_accuracy: 0.6089\n",
            "Epoch 623/1000\n",
            "6974/6974 [==============================] - 0s 66us/sample - loss: 0.6598 - binary_accuracy: 0.6052 - val_loss: 0.6694 - val_binary_accuracy: 0.6089\n",
            "Epoch 624/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6598 - binary_accuracy: 0.6047 - val_loss: 0.6694 - val_binary_accuracy: 0.6101\n",
            "Epoch 625/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6598 - binary_accuracy: 0.6044 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "Epoch 626/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6597 - binary_accuracy: 0.6055 - val_loss: 0.6694 - val_binary_accuracy: 0.6089\n",
            "Epoch 627/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6598 - binary_accuracy: 0.6038 - val_loss: 0.6694 - val_binary_accuracy: 0.6061\n",
            "Epoch 628/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6597 - binary_accuracy: 0.6045 - val_loss: 0.6694 - val_binary_accuracy: 0.6084\n",
            "Epoch 629/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6597 - binary_accuracy: 0.6047 - val_loss: 0.6694 - val_binary_accuracy: 0.6095\n",
            "(6974, 20)\n",
            "(1744, 20)\n",
            "Train on 6974 samples, validate on 1744 samples\n",
            "Epoch 1/1000\n",
            "6974/6974 [==============================] - 1s 83us/sample - loss: 0.6904 - binary_accuracy: 0.5194 - val_loss: 0.6900 - val_binary_accuracy: 0.5269\n",
            "Epoch 2/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6903 - binary_accuracy: 0.5231 - val_loss: 0.6898 - val_binary_accuracy: 0.5281\n",
            "Epoch 3/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6902 - binary_accuracy: 0.5247 - val_loss: 0.6897 - val_binary_accuracy: 0.5292\n",
            "Epoch 4/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6901 - binary_accuracy: 0.5261 - val_loss: 0.6896 - val_binary_accuracy: 0.5310\n",
            "Epoch 5/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6900 - binary_accuracy: 0.5294 - val_loss: 0.6894 - val_binary_accuracy: 0.5327\n",
            "Epoch 6/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6898 - binary_accuracy: 0.5298 - val_loss: 0.6893 - val_binary_accuracy: 0.5356\n",
            "Epoch 7/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6897 - binary_accuracy: 0.5336 - val_loss: 0.6891 - val_binary_accuracy: 0.5361\n",
            "Epoch 8/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6896 - binary_accuracy: 0.5341 - val_loss: 0.6890 - val_binary_accuracy: 0.5378\n",
            "Epoch 9/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6895 - binary_accuracy: 0.5370 - val_loss: 0.6889 - val_binary_accuracy: 0.5419\n",
            "Epoch 10/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6893 - binary_accuracy: 0.5389 - val_loss: 0.6887 - val_binary_accuracy: 0.5447\n",
            "Epoch 11/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6892 - binary_accuracy: 0.5410 - val_loss: 0.6886 - val_binary_accuracy: 0.5487\n",
            "Epoch 12/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6891 - binary_accuracy: 0.5432 - val_loss: 0.6884 - val_binary_accuracy: 0.5510\n",
            "Epoch 13/1000\n",
            "6974/6974 [==============================] - 1s 165us/sample - loss: 0.6890 - binary_accuracy: 0.5440 - val_loss: 0.6883 - val_binary_accuracy: 0.5533\n",
            "Epoch 14/1000\n",
            "6974/6974 [==============================] - 1s 85us/sample - loss: 0.6888 - binary_accuracy: 0.5453 - val_loss: 0.6881 - val_binary_accuracy: 0.5539\n",
            "Epoch 15/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6887 - binary_accuracy: 0.5467 - val_loss: 0.6880 - val_binary_accuracy: 0.5568\n",
            "Epoch 16/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6886 - binary_accuracy: 0.5469 - val_loss: 0.6879 - val_binary_accuracy: 0.5562\n",
            "Epoch 17/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6885 - binary_accuracy: 0.5495 - val_loss: 0.6877 - val_binary_accuracy: 0.5568\n",
            "Epoch 18/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6883 - binary_accuracy: 0.5503 - val_loss: 0.6876 - val_binary_accuracy: 0.5591\n",
            "Epoch 19/1000\n",
            "6974/6974 [==============================] - 0s 60us/sample - loss: 0.6882 - binary_accuracy: 0.5505 - val_loss: 0.6874 - val_binary_accuracy: 0.5614\n",
            "Epoch 20/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6881 - binary_accuracy: 0.5521 - val_loss: 0.6873 - val_binary_accuracy: 0.5642\n",
            "Epoch 21/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6879 - binary_accuracy: 0.5536 - val_loss: 0.6871 - val_binary_accuracy: 0.5642\n",
            "Epoch 22/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6878 - binary_accuracy: 0.5558 - val_loss: 0.6870 - val_binary_accuracy: 0.5648\n",
            "Epoch 23/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6877 - binary_accuracy: 0.5566 - val_loss: 0.6869 - val_binary_accuracy: 0.5614\n",
            "Epoch 24/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6876 - binary_accuracy: 0.5576 - val_loss: 0.6867 - val_binary_accuracy: 0.5614\n",
            "Epoch 25/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6874 - binary_accuracy: 0.5584 - val_loss: 0.6866 - val_binary_accuracy: 0.5614\n",
            "Epoch 26/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6873 - binary_accuracy: 0.5601 - val_loss: 0.6864 - val_binary_accuracy: 0.5614\n",
            "Epoch 27/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6872 - binary_accuracy: 0.5602 - val_loss: 0.6863 - val_binary_accuracy: 0.5614\n",
            "Epoch 28/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6870 - binary_accuracy: 0.5621 - val_loss: 0.6861 - val_binary_accuracy: 0.5631\n",
            "Epoch 29/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6869 - binary_accuracy: 0.5625 - val_loss: 0.6860 - val_binary_accuracy: 0.5625\n",
            "Epoch 30/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6868 - binary_accuracy: 0.5627 - val_loss: 0.6858 - val_binary_accuracy: 0.5636\n",
            "Epoch 31/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6866 - binary_accuracy: 0.5622 - val_loss: 0.6856 - val_binary_accuracy: 0.5625\n",
            "Epoch 32/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6865 - binary_accuracy: 0.5641 - val_loss: 0.6855 - val_binary_accuracy: 0.5625\n",
            "Epoch 33/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6863 - binary_accuracy: 0.5674 - val_loss: 0.6853 - val_binary_accuracy: 0.5642\n",
            "Epoch 34/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6861 - binary_accuracy: 0.5671 - val_loss: 0.6852 - val_binary_accuracy: 0.5688\n",
            "Epoch 35/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6860 - binary_accuracy: 0.5677 - val_loss: 0.6850 - val_binary_accuracy: 0.5717\n",
            "Epoch 36/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6858 - binary_accuracy: 0.5700 - val_loss: 0.6849 - val_binary_accuracy: 0.5711\n",
            "Epoch 37/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6857 - binary_accuracy: 0.5697 - val_loss: 0.6847 - val_binary_accuracy: 0.5705\n",
            "Epoch 38/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6855 - binary_accuracy: 0.5697 - val_loss: 0.6845 - val_binary_accuracy: 0.5722\n",
            "Epoch 39/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6853 - binary_accuracy: 0.5718 - val_loss: 0.6843 - val_binary_accuracy: 0.5722\n",
            "Epoch 40/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6852 - binary_accuracy: 0.5714 - val_loss: 0.6842 - val_binary_accuracy: 0.5734\n",
            "Epoch 41/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6850 - binary_accuracy: 0.5733 - val_loss: 0.6840 - val_binary_accuracy: 0.5740\n",
            "Epoch 42/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6848 - binary_accuracy: 0.5734 - val_loss: 0.6838 - val_binary_accuracy: 0.5797\n",
            "Epoch 43/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6847 - binary_accuracy: 0.5741 - val_loss: 0.6837 - val_binary_accuracy: 0.5820\n",
            "Epoch 44/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6845 - binary_accuracy: 0.5748 - val_loss: 0.6835 - val_binary_accuracy: 0.5820\n",
            "Epoch 45/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6844 - binary_accuracy: 0.5746 - val_loss: 0.6833 - val_binary_accuracy: 0.5826\n",
            "Epoch 46/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6842 - binary_accuracy: 0.5753 - val_loss: 0.6831 - val_binary_accuracy: 0.5843\n",
            "Epoch 47/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6841 - binary_accuracy: 0.5760 - val_loss: 0.6830 - val_binary_accuracy: 0.5866\n",
            "Epoch 48/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6839 - binary_accuracy: 0.5766 - val_loss: 0.6828 - val_binary_accuracy: 0.5866\n",
            "Epoch 49/1000\n",
            "6974/6974 [==============================] - 0s 66us/sample - loss: 0.6837 - binary_accuracy: 0.5764 - val_loss: 0.6826 - val_binary_accuracy: 0.5872\n",
            "Epoch 50/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6836 - binary_accuracy: 0.5757 - val_loss: 0.6824 - val_binary_accuracy: 0.5860\n",
            "Epoch 51/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6834 - binary_accuracy: 0.5777 - val_loss: 0.6822 - val_binary_accuracy: 0.5866\n",
            "Epoch 52/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6832 - binary_accuracy: 0.5786 - val_loss: 0.6820 - val_binary_accuracy: 0.5889\n",
            "Epoch 53/1000\n",
            "6974/6974 [==============================] - 0s 66us/sample - loss: 0.6831 - binary_accuracy: 0.5776 - val_loss: 0.6819 - val_binary_accuracy: 0.5894\n",
            "Epoch 54/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6829 - binary_accuracy: 0.5787 - val_loss: 0.6817 - val_binary_accuracy: 0.5912\n",
            "Epoch 55/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6827 - binary_accuracy: 0.5777 - val_loss: 0.6815 - val_binary_accuracy: 0.5906\n",
            "Epoch 56/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6825 - binary_accuracy: 0.5787 - val_loss: 0.6813 - val_binary_accuracy: 0.5912\n",
            "Epoch 57/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6824 - binary_accuracy: 0.5784 - val_loss: 0.6811 - val_binary_accuracy: 0.5912\n",
            "Epoch 58/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6822 - binary_accuracy: 0.5787 - val_loss: 0.6810 - val_binary_accuracy: 0.5923\n",
            "Epoch 59/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6820 - binary_accuracy: 0.5812 - val_loss: 0.6808 - val_binary_accuracy: 0.5923\n",
            "Epoch 60/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6819 - binary_accuracy: 0.5820 - val_loss: 0.6806 - val_binary_accuracy: 0.5917\n",
            "Epoch 61/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6817 - binary_accuracy: 0.5822 - val_loss: 0.6804 - val_binary_accuracy: 0.5929\n",
            "Epoch 62/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6815 - binary_accuracy: 0.5827 - val_loss: 0.6802 - val_binary_accuracy: 0.5923\n",
            "Epoch 63/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6814 - binary_accuracy: 0.5816 - val_loss: 0.6800 - val_binary_accuracy: 0.5912\n",
            "Epoch 64/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6812 - binary_accuracy: 0.5840 - val_loss: 0.6799 - val_binary_accuracy: 0.5894\n",
            "Epoch 65/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6810 - binary_accuracy: 0.5852 - val_loss: 0.6797 - val_binary_accuracy: 0.5894\n",
            "Epoch 66/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6809 - binary_accuracy: 0.5856 - val_loss: 0.6795 - val_binary_accuracy: 0.5894\n",
            "Epoch 67/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6807 - binary_accuracy: 0.5859 - val_loss: 0.6793 - val_binary_accuracy: 0.5900\n",
            "Epoch 68/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6806 - binary_accuracy: 0.5866 - val_loss: 0.6791 - val_binary_accuracy: 0.5900\n",
            "Epoch 69/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6804 - binary_accuracy: 0.5869 - val_loss: 0.6790 - val_binary_accuracy: 0.5906\n",
            "Epoch 70/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6802 - binary_accuracy: 0.5870 - val_loss: 0.6788 - val_binary_accuracy: 0.5900\n",
            "Epoch 71/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6801 - binary_accuracy: 0.5868 - val_loss: 0.6786 - val_binary_accuracy: 0.5900\n",
            "Epoch 72/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6799 - binary_accuracy: 0.5868 - val_loss: 0.6785 - val_binary_accuracy: 0.5889\n",
            "Epoch 73/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6798 - binary_accuracy: 0.5865 - val_loss: 0.6783 - val_binary_accuracy: 0.5906\n",
            "Epoch 74/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6796 - binary_accuracy: 0.5852 - val_loss: 0.6781 - val_binary_accuracy: 0.5900\n",
            "Epoch 75/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6795 - binary_accuracy: 0.5872 - val_loss: 0.6779 - val_binary_accuracy: 0.5900\n",
            "Epoch 76/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6793 - binary_accuracy: 0.5870 - val_loss: 0.6778 - val_binary_accuracy: 0.5906\n",
            "Epoch 77/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6792 - binary_accuracy: 0.5876 - val_loss: 0.6776 - val_binary_accuracy: 0.5912\n",
            "Epoch 78/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6790 - binary_accuracy: 0.5875 - val_loss: 0.6774 - val_binary_accuracy: 0.5917\n",
            "Epoch 79/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6789 - binary_accuracy: 0.5869 - val_loss: 0.6772 - val_binary_accuracy: 0.5935\n",
            "Epoch 80/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6787 - binary_accuracy: 0.5886 - val_loss: 0.6771 - val_binary_accuracy: 0.5935\n",
            "Epoch 81/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6786 - binary_accuracy: 0.5889 - val_loss: 0.6769 - val_binary_accuracy: 0.5940\n",
            "Epoch 82/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6784 - binary_accuracy: 0.5873 - val_loss: 0.6767 - val_binary_accuracy: 0.5940\n",
            "Epoch 83/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6783 - binary_accuracy: 0.5892 - val_loss: 0.6765 - val_binary_accuracy: 0.5935\n",
            "Epoch 84/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6781 - binary_accuracy: 0.5888 - val_loss: 0.6764 - val_binary_accuracy: 0.5935\n",
            "Epoch 85/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6780 - binary_accuracy: 0.5888 - val_loss: 0.6762 - val_binary_accuracy: 0.5952\n",
            "Epoch 86/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6779 - binary_accuracy: 0.5879 - val_loss: 0.6760 - val_binary_accuracy: 0.5946\n",
            "Epoch 87/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6777 - binary_accuracy: 0.5893 - val_loss: 0.6759 - val_binary_accuracy: 0.5958\n",
            "Epoch 88/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6776 - binary_accuracy: 0.5892 - val_loss: 0.6757 - val_binary_accuracy: 0.5952\n",
            "Epoch 89/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6774 - binary_accuracy: 0.5899 - val_loss: 0.6755 - val_binary_accuracy: 0.5935\n",
            "Epoch 90/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6773 - binary_accuracy: 0.5880 - val_loss: 0.6753 - val_binary_accuracy: 0.5946\n",
            "Epoch 91/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6772 - binary_accuracy: 0.5883 - val_loss: 0.6752 - val_binary_accuracy: 0.5940\n",
            "Epoch 92/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6770 - binary_accuracy: 0.5886 - val_loss: 0.6750 - val_binary_accuracy: 0.5935\n",
            "Epoch 93/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6769 - binary_accuracy: 0.5896 - val_loss: 0.6749 - val_binary_accuracy: 0.5929\n",
            "Epoch 94/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6767 - binary_accuracy: 0.5899 - val_loss: 0.6747 - val_binary_accuracy: 0.5935\n",
            "Epoch 95/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6766 - binary_accuracy: 0.5896 - val_loss: 0.6745 - val_binary_accuracy: 0.5958\n",
            "Epoch 96/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6765 - binary_accuracy: 0.5893 - val_loss: 0.6744 - val_binary_accuracy: 0.5940\n",
            "Epoch 97/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6763 - binary_accuracy: 0.5900 - val_loss: 0.6742 - val_binary_accuracy: 0.5952\n",
            "Epoch 98/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6762 - binary_accuracy: 0.5915 - val_loss: 0.6741 - val_binary_accuracy: 0.5958\n",
            "Epoch 99/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6761 - binary_accuracy: 0.5905 - val_loss: 0.6739 - val_binary_accuracy: 0.5963\n",
            "Epoch 100/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6759 - binary_accuracy: 0.5912 - val_loss: 0.6737 - val_binary_accuracy: 0.5975\n",
            "Epoch 101/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6758 - binary_accuracy: 0.5906 - val_loss: 0.6736 - val_binary_accuracy: 0.5963\n",
            "Epoch 102/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6757 - binary_accuracy: 0.5915 - val_loss: 0.6734 - val_binary_accuracy: 0.5952\n",
            "Epoch 103/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6756 - binary_accuracy: 0.5918 - val_loss: 0.6733 - val_binary_accuracy: 0.5946\n",
            "Epoch 104/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6754 - binary_accuracy: 0.5922 - val_loss: 0.6732 - val_binary_accuracy: 0.5958\n",
            "Epoch 105/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6753 - binary_accuracy: 0.5918 - val_loss: 0.6730 - val_binary_accuracy: 0.5952\n",
            "Epoch 106/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6752 - binary_accuracy: 0.5925 - val_loss: 0.6729 - val_binary_accuracy: 0.5969\n",
            "Epoch 107/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6751 - binary_accuracy: 0.5918 - val_loss: 0.6727 - val_binary_accuracy: 0.5963\n",
            "Epoch 108/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6749 - binary_accuracy: 0.5918 - val_loss: 0.6726 - val_binary_accuracy: 0.5963\n",
            "Epoch 109/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6748 - binary_accuracy: 0.5923 - val_loss: 0.6724 - val_binary_accuracy: 0.5969\n",
            "Epoch 110/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6747 - binary_accuracy: 0.5923 - val_loss: 0.6723 - val_binary_accuracy: 0.5975\n",
            "Epoch 111/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6746 - binary_accuracy: 0.5928 - val_loss: 0.6722 - val_binary_accuracy: 0.5975\n",
            "Epoch 112/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6745 - binary_accuracy: 0.5928 - val_loss: 0.6720 - val_binary_accuracy: 0.5975\n",
            "Epoch 113/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6744 - binary_accuracy: 0.5936 - val_loss: 0.6719 - val_binary_accuracy: 0.5986\n",
            "Epoch 114/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6743 - binary_accuracy: 0.5933 - val_loss: 0.6718 - val_binary_accuracy: 0.5986\n",
            "Epoch 115/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6741 - binary_accuracy: 0.5945 - val_loss: 0.6716 - val_binary_accuracy: 0.5975\n",
            "Epoch 116/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6740 - binary_accuracy: 0.5935 - val_loss: 0.6715 - val_binary_accuracy: 0.5963\n",
            "Epoch 117/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6739 - binary_accuracy: 0.5941 - val_loss: 0.6714 - val_binary_accuracy: 0.5969\n",
            "Epoch 118/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6738 - binary_accuracy: 0.5929 - val_loss: 0.6712 - val_binary_accuracy: 0.5969\n",
            "Epoch 119/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6737 - binary_accuracy: 0.5929 - val_loss: 0.6711 - val_binary_accuracy: 0.5975\n",
            "Epoch 120/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6736 - binary_accuracy: 0.5946 - val_loss: 0.6710 - val_binary_accuracy: 0.5975\n",
            "Epoch 121/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6735 - binary_accuracy: 0.5938 - val_loss: 0.6709 - val_binary_accuracy: 0.5981\n",
            "Epoch 122/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6734 - binary_accuracy: 0.5942 - val_loss: 0.6707 - val_binary_accuracy: 0.5969\n",
            "Epoch 123/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6733 - binary_accuracy: 0.5938 - val_loss: 0.6706 - val_binary_accuracy: 0.5963\n",
            "Epoch 124/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6732 - binary_accuracy: 0.5939 - val_loss: 0.6705 - val_binary_accuracy: 0.5963\n",
            "Epoch 125/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6731 - binary_accuracy: 0.5948 - val_loss: 0.6704 - val_binary_accuracy: 0.5969\n",
            "Epoch 126/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6730 - binary_accuracy: 0.5946 - val_loss: 0.6703 - val_binary_accuracy: 0.5969\n",
            "Epoch 127/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6729 - binary_accuracy: 0.5938 - val_loss: 0.6701 - val_binary_accuracy: 0.5958\n",
            "Epoch 128/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6728 - binary_accuracy: 0.5954 - val_loss: 0.6701 - val_binary_accuracy: 0.5969\n",
            "Epoch 129/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6727 - binary_accuracy: 0.5955 - val_loss: 0.6699 - val_binary_accuracy: 0.5963\n",
            "Epoch 130/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6726 - binary_accuracy: 0.5958 - val_loss: 0.6698 - val_binary_accuracy: 0.5963\n",
            "Epoch 131/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6726 - binary_accuracy: 0.5958 - val_loss: 0.6697 - val_binary_accuracy: 0.5969\n",
            "Epoch 132/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6725 - binary_accuracy: 0.5962 - val_loss: 0.6696 - val_binary_accuracy: 0.5958\n",
            "Epoch 133/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6724 - binary_accuracy: 0.5964 - val_loss: 0.6695 - val_binary_accuracy: 0.5963\n",
            "Epoch 134/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6723 - binary_accuracy: 0.5964 - val_loss: 0.6694 - val_binary_accuracy: 0.5952\n",
            "Epoch 135/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6722 - binary_accuracy: 0.5959 - val_loss: 0.6693 - val_binary_accuracy: 0.5958\n",
            "Epoch 136/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6721 - binary_accuracy: 0.5968 - val_loss: 0.6692 - val_binary_accuracy: 0.5969\n",
            "Epoch 137/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6720 - binary_accuracy: 0.5961 - val_loss: 0.6691 - val_binary_accuracy: 0.5958\n",
            "Epoch 138/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6719 - binary_accuracy: 0.5949 - val_loss: 0.6689 - val_binary_accuracy: 0.5952\n",
            "Epoch 139/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6719 - binary_accuracy: 0.5962 - val_loss: 0.6688 - val_binary_accuracy: 0.5975\n",
            "Epoch 140/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6718 - binary_accuracy: 0.5968 - val_loss: 0.6687 - val_binary_accuracy: 0.5975\n",
            "Epoch 141/1000\n",
            "6974/6974 [==============================] - 0s 66us/sample - loss: 0.6717 - binary_accuracy: 0.5971 - val_loss: 0.6686 - val_binary_accuracy: 0.5958\n",
            "Epoch 142/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6716 - binary_accuracy: 0.5954 - val_loss: 0.6685 - val_binary_accuracy: 0.5963\n",
            "Epoch 143/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6715 - binary_accuracy: 0.5966 - val_loss: 0.6684 - val_binary_accuracy: 0.5952\n",
            "Epoch 144/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6715 - binary_accuracy: 0.5976 - val_loss: 0.6683 - val_binary_accuracy: 0.5958\n",
            "Epoch 145/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6714 - binary_accuracy: 0.5949 - val_loss: 0.6682 - val_binary_accuracy: 0.5958\n",
            "Epoch 146/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6713 - binary_accuracy: 0.5968 - val_loss: 0.6682 - val_binary_accuracy: 0.5952\n",
            "Epoch 147/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6712 - binary_accuracy: 0.5969 - val_loss: 0.6681 - val_binary_accuracy: 0.5958\n",
            "Epoch 148/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6712 - binary_accuracy: 0.5948 - val_loss: 0.6680 - val_binary_accuracy: 0.5952\n",
            "Epoch 149/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6711 - binary_accuracy: 0.5969 - val_loss: 0.6679 - val_binary_accuracy: 0.5975\n",
            "Epoch 150/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6710 - binary_accuracy: 0.5959 - val_loss: 0.6678 - val_binary_accuracy: 0.5969\n",
            "Epoch 151/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6709 - binary_accuracy: 0.5958 - val_loss: 0.6677 - val_binary_accuracy: 0.5975\n",
            "Epoch 152/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6709 - binary_accuracy: 0.5954 - val_loss: 0.6676 - val_binary_accuracy: 0.5969\n",
            "Epoch 153/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6708 - binary_accuracy: 0.5936 - val_loss: 0.6675 - val_binary_accuracy: 0.5963\n",
            "Epoch 154/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6707 - binary_accuracy: 0.5959 - val_loss: 0.6674 - val_binary_accuracy: 0.5969\n",
            "Epoch 155/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6707 - binary_accuracy: 0.5978 - val_loss: 0.6674 - val_binary_accuracy: 0.5969\n",
            "Epoch 156/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6706 - binary_accuracy: 0.5942 - val_loss: 0.6673 - val_binary_accuracy: 0.5969\n",
            "Epoch 157/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6705 - binary_accuracy: 0.5966 - val_loss: 0.6672 - val_binary_accuracy: 0.5969\n",
            "Epoch 158/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6704 - binary_accuracy: 0.5952 - val_loss: 0.6671 - val_binary_accuracy: 0.5969\n",
            "Epoch 159/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6704 - binary_accuracy: 0.5952 - val_loss: 0.6670 - val_binary_accuracy: 0.5952\n",
            "Epoch 160/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6703 - binary_accuracy: 0.5958 - val_loss: 0.6669 - val_binary_accuracy: 0.5952\n",
            "Epoch 161/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6703 - binary_accuracy: 0.5939 - val_loss: 0.6669 - val_binary_accuracy: 0.5958\n",
            "Epoch 162/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6702 - binary_accuracy: 0.5952 - val_loss: 0.6668 - val_binary_accuracy: 0.5952\n",
            "Epoch 163/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6701 - binary_accuracy: 0.5951 - val_loss: 0.6667 - val_binary_accuracy: 0.5952\n",
            "Epoch 164/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6701 - binary_accuracy: 0.5956 - val_loss: 0.6666 - val_binary_accuracy: 0.5958\n",
            "Epoch 165/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6700 - binary_accuracy: 0.5962 - val_loss: 0.6666 - val_binary_accuracy: 0.5963\n",
            "Epoch 166/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6699 - binary_accuracy: 0.5954 - val_loss: 0.6665 - val_binary_accuracy: 0.5952\n",
            "Epoch 167/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6699 - binary_accuracy: 0.5951 - val_loss: 0.6664 - val_binary_accuracy: 0.5952\n",
            "Epoch 168/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6698 - binary_accuracy: 0.5964 - val_loss: 0.6663 - val_binary_accuracy: 0.5963\n",
            "Epoch 169/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6697 - binary_accuracy: 0.5958 - val_loss: 0.6662 - val_binary_accuracy: 0.5952\n",
            "Epoch 170/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6697 - binary_accuracy: 0.5952 - val_loss: 0.6662 - val_binary_accuracy: 0.5958\n",
            "Epoch 171/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6696 - binary_accuracy: 0.5964 - val_loss: 0.6661 - val_binary_accuracy: 0.5946\n",
            "Epoch 172/1000\n",
            "6974/6974 [==============================] - 1s 75us/sample - loss: 0.6696 - binary_accuracy: 0.5965 - val_loss: 0.6660 - val_binary_accuracy: 0.5952\n",
            "Epoch 173/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6695 - binary_accuracy: 0.5949 - val_loss: 0.6659 - val_binary_accuracy: 0.5963\n",
            "Epoch 174/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6695 - binary_accuracy: 0.5966 - val_loss: 0.6659 - val_binary_accuracy: 0.5963\n",
            "Epoch 175/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6694 - binary_accuracy: 0.5952 - val_loss: 0.6658 - val_binary_accuracy: 0.5952\n",
            "Epoch 176/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6694 - binary_accuracy: 0.5946 - val_loss: 0.6657 - val_binary_accuracy: 0.5952\n",
            "Epoch 177/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6693 - binary_accuracy: 0.5961 - val_loss: 0.6657 - val_binary_accuracy: 0.5952\n",
            "Epoch 178/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6692 - binary_accuracy: 0.5955 - val_loss: 0.6656 - val_binary_accuracy: 0.5952\n",
            "Epoch 179/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6692 - binary_accuracy: 0.5955 - val_loss: 0.6655 - val_binary_accuracy: 0.5946\n",
            "Epoch 180/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6691 - binary_accuracy: 0.5972 - val_loss: 0.6655 - val_binary_accuracy: 0.5958\n",
            "Epoch 181/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6691 - binary_accuracy: 0.5964 - val_loss: 0.6654 - val_binary_accuracy: 0.5952\n",
            "Epoch 182/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6690 - binary_accuracy: 0.5959 - val_loss: 0.6654 - val_binary_accuracy: 0.5940\n",
            "Epoch 183/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6690 - binary_accuracy: 0.5956 - val_loss: 0.6653 - val_binary_accuracy: 0.5958\n",
            "Epoch 184/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6689 - binary_accuracy: 0.5955 - val_loss: 0.6652 - val_binary_accuracy: 0.5952\n",
            "Epoch 185/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6689 - binary_accuracy: 0.5946 - val_loss: 0.6652 - val_binary_accuracy: 0.5946\n",
            "Epoch 186/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6688 - binary_accuracy: 0.5964 - val_loss: 0.6651 - val_binary_accuracy: 0.5958\n",
            "Epoch 187/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6688 - binary_accuracy: 0.5956 - val_loss: 0.6651 - val_binary_accuracy: 0.5963\n",
            "Epoch 188/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6687 - binary_accuracy: 0.5952 - val_loss: 0.6650 - val_binary_accuracy: 0.5963\n",
            "Epoch 189/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6687 - binary_accuracy: 0.5969 - val_loss: 0.6649 - val_binary_accuracy: 0.5963\n",
            "Epoch 190/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6686 - binary_accuracy: 0.5948 - val_loss: 0.6649 - val_binary_accuracy: 0.5963\n",
            "Epoch 191/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6686 - binary_accuracy: 0.5958 - val_loss: 0.6648 - val_binary_accuracy: 0.5975\n",
            "Epoch 192/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6686 - binary_accuracy: 0.5966 - val_loss: 0.6647 - val_binary_accuracy: 0.5975\n",
            "Epoch 193/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6685 - binary_accuracy: 0.5956 - val_loss: 0.6647 - val_binary_accuracy: 0.5975\n",
            "Epoch 194/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6684 - binary_accuracy: 0.5964 - val_loss: 0.6646 - val_binary_accuracy: 0.5963\n",
            "Epoch 195/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6684 - binary_accuracy: 0.5958 - val_loss: 0.6646 - val_binary_accuracy: 0.5963\n",
            "Epoch 196/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6684 - binary_accuracy: 0.5949 - val_loss: 0.6645 - val_binary_accuracy: 0.5963\n",
            "Epoch 197/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6683 - binary_accuracy: 0.5952 - val_loss: 0.6645 - val_binary_accuracy: 0.5963\n",
            "Epoch 198/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6683 - binary_accuracy: 0.5962 - val_loss: 0.6644 - val_binary_accuracy: 0.5952\n",
            "Epoch 199/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6683 - binary_accuracy: 0.5959 - val_loss: 0.6643 - val_binary_accuracy: 0.5958\n",
            "Epoch 200/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6682 - binary_accuracy: 0.5955 - val_loss: 0.6643 - val_binary_accuracy: 0.5958\n",
            "Epoch 201/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6682 - binary_accuracy: 0.5958 - val_loss: 0.6642 - val_binary_accuracy: 0.5963\n",
            "Epoch 202/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6681 - binary_accuracy: 0.5965 - val_loss: 0.6642 - val_binary_accuracy: 0.5969\n",
            "Epoch 203/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6681 - binary_accuracy: 0.5968 - val_loss: 0.6641 - val_binary_accuracy: 0.5981\n",
            "Epoch 204/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6680 - binary_accuracy: 0.5962 - val_loss: 0.6641 - val_binary_accuracy: 0.5981\n",
            "Epoch 205/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6680 - binary_accuracy: 0.5968 - val_loss: 0.6640 - val_binary_accuracy: 0.5969\n",
            "Epoch 206/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6680 - binary_accuracy: 0.5949 - val_loss: 0.6640 - val_binary_accuracy: 0.5969\n",
            "Epoch 207/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6679 - binary_accuracy: 0.5962 - val_loss: 0.6639 - val_binary_accuracy: 0.5969\n",
            "Epoch 208/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6679 - binary_accuracy: 0.5964 - val_loss: 0.6639 - val_binary_accuracy: 0.5963\n",
            "Epoch 209/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6678 - binary_accuracy: 0.5974 - val_loss: 0.6638 - val_binary_accuracy: 0.5975\n",
            "Epoch 210/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6678 - binary_accuracy: 0.5951 - val_loss: 0.6638 - val_binary_accuracy: 0.5981\n",
            "Epoch 211/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6678 - binary_accuracy: 0.5962 - val_loss: 0.6637 - val_binary_accuracy: 0.5986\n",
            "Epoch 212/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6677 - binary_accuracy: 0.5956 - val_loss: 0.6637 - val_binary_accuracy: 0.5981\n",
            "Epoch 213/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6677 - binary_accuracy: 0.5964 - val_loss: 0.6637 - val_binary_accuracy: 0.5992\n",
            "Epoch 214/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6677 - binary_accuracy: 0.5965 - val_loss: 0.6636 - val_binary_accuracy: 0.5986\n",
            "Epoch 215/1000\n",
            "6974/6974 [==============================] - 0s 66us/sample - loss: 0.6676 - binary_accuracy: 0.5962 - val_loss: 0.6636 - val_binary_accuracy: 0.5986\n",
            "Epoch 216/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6676 - binary_accuracy: 0.5966 - val_loss: 0.6635 - val_binary_accuracy: 0.5975\n",
            "Epoch 217/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6675 - binary_accuracy: 0.5968 - val_loss: 0.6635 - val_binary_accuracy: 0.5986\n",
            "Epoch 218/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6675 - binary_accuracy: 0.5964 - val_loss: 0.6635 - val_binary_accuracy: 0.5992\n",
            "Epoch 219/1000\n",
            "6974/6974 [==============================] - 1s 75us/sample - loss: 0.6675 - binary_accuracy: 0.5959 - val_loss: 0.6634 - val_binary_accuracy: 0.5986\n",
            "Epoch 220/1000\n",
            "6974/6974 [==============================] - 0s 66us/sample - loss: 0.6675 - binary_accuracy: 0.5974 - val_loss: 0.6634 - val_binary_accuracy: 0.5981\n",
            "Epoch 221/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6674 - binary_accuracy: 0.5976 - val_loss: 0.6633 - val_binary_accuracy: 0.5998\n",
            "Epoch 222/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6674 - binary_accuracy: 0.5962 - val_loss: 0.6633 - val_binary_accuracy: 0.5986\n",
            "Epoch 223/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6674 - binary_accuracy: 0.5965 - val_loss: 0.6633 - val_binary_accuracy: 0.5986\n",
            "Epoch 224/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6673 - binary_accuracy: 0.5958 - val_loss: 0.6632 - val_binary_accuracy: 0.5986\n",
            "Epoch 225/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6673 - binary_accuracy: 0.5965 - val_loss: 0.6632 - val_binary_accuracy: 0.5981\n",
            "Epoch 226/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6673 - binary_accuracy: 0.5968 - val_loss: 0.6631 - val_binary_accuracy: 0.5986\n",
            "Epoch 227/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6672 - binary_accuracy: 0.5965 - val_loss: 0.6631 - val_binary_accuracy: 0.5986\n",
            "Epoch 228/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6672 - binary_accuracy: 0.5972 - val_loss: 0.6631 - val_binary_accuracy: 0.5986\n",
            "Epoch 229/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6672 - binary_accuracy: 0.5982 - val_loss: 0.6630 - val_binary_accuracy: 0.5981\n",
            "Epoch 230/1000\n",
            "6974/6974 [==============================] - 0s 66us/sample - loss: 0.6672 - binary_accuracy: 0.5966 - val_loss: 0.6630 - val_binary_accuracy: 0.5986\n",
            "Epoch 231/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6671 - binary_accuracy: 0.5972 - val_loss: 0.6630 - val_binary_accuracy: 0.5992\n",
            "Epoch 232/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6671 - binary_accuracy: 0.5966 - val_loss: 0.6629 - val_binary_accuracy: 0.5992\n",
            "Epoch 233/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6671 - binary_accuracy: 0.5972 - val_loss: 0.6629 - val_binary_accuracy: 0.5992\n",
            "Epoch 234/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6671 - binary_accuracy: 0.5964 - val_loss: 0.6629 - val_binary_accuracy: 0.5986\n",
            "Epoch 235/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6670 - binary_accuracy: 0.5979 - val_loss: 0.6628 - val_binary_accuracy: 0.5998\n",
            "Epoch 236/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6670 - binary_accuracy: 0.5984 - val_loss: 0.6628 - val_binary_accuracy: 0.5992\n",
            "Epoch 237/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6670 - binary_accuracy: 0.5981 - val_loss: 0.6627 - val_binary_accuracy: 0.5992\n",
            "Epoch 238/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6670 - binary_accuracy: 0.5974 - val_loss: 0.6627 - val_binary_accuracy: 0.5998\n",
            "Epoch 239/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6669 - binary_accuracy: 0.5982 - val_loss: 0.6627 - val_binary_accuracy: 0.5998\n",
            "Epoch 240/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6669 - binary_accuracy: 0.5985 - val_loss: 0.6626 - val_binary_accuracy: 0.6003\n",
            "Epoch 241/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6669 - binary_accuracy: 0.5989 - val_loss: 0.6626 - val_binary_accuracy: 0.5975\n",
            "Epoch 242/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6668 - binary_accuracy: 0.5974 - val_loss: 0.6626 - val_binary_accuracy: 0.5992\n",
            "Epoch 243/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6668 - binary_accuracy: 0.5985 - val_loss: 0.6625 - val_binary_accuracy: 0.5998\n",
            "Epoch 244/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6668 - binary_accuracy: 0.5982 - val_loss: 0.6625 - val_binary_accuracy: 0.5992\n",
            "Epoch 245/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6668 - binary_accuracy: 0.5997 - val_loss: 0.6625 - val_binary_accuracy: 0.5981\n",
            "Epoch 246/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6667 - binary_accuracy: 0.5984 - val_loss: 0.6625 - val_binary_accuracy: 0.5963\n",
            "Epoch 247/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6667 - binary_accuracy: 0.5978 - val_loss: 0.6624 - val_binary_accuracy: 0.5981\n",
            "Epoch 248/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6667 - binary_accuracy: 0.5991 - val_loss: 0.6624 - val_binary_accuracy: 0.5986\n",
            "Epoch 249/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6667 - binary_accuracy: 0.5981 - val_loss: 0.6624 - val_binary_accuracy: 0.5963\n",
            "Epoch 250/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6666 - binary_accuracy: 0.5978 - val_loss: 0.6624 - val_binary_accuracy: 0.5981\n",
            "Epoch 251/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6666 - binary_accuracy: 0.5981 - val_loss: 0.6623 - val_binary_accuracy: 0.5975\n",
            "Epoch 252/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6666 - binary_accuracy: 0.5989 - val_loss: 0.6623 - val_binary_accuracy: 0.5975\n",
            "Epoch 253/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6666 - binary_accuracy: 0.5994 - val_loss: 0.6623 - val_binary_accuracy: 0.5975\n",
            "Epoch 254/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6665 - binary_accuracy: 0.5984 - val_loss: 0.6623 - val_binary_accuracy: 0.5969\n",
            "Epoch 255/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6665 - binary_accuracy: 0.5979 - val_loss: 0.6622 - val_binary_accuracy: 0.5975\n",
            "Epoch 256/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6665 - binary_accuracy: 0.5978 - val_loss: 0.6622 - val_binary_accuracy: 0.5969\n",
            "Epoch 257/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6665 - binary_accuracy: 0.5989 - val_loss: 0.6622 - val_binary_accuracy: 0.5969\n",
            "Epoch 258/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6665 - binary_accuracy: 0.5982 - val_loss: 0.6622 - val_binary_accuracy: 0.5981\n",
            "Epoch 259/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6664 - binary_accuracy: 0.5985 - val_loss: 0.6622 - val_binary_accuracy: 0.5969\n",
            "Epoch 260/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6664 - binary_accuracy: 0.5984 - val_loss: 0.6621 - val_binary_accuracy: 0.5975\n",
            "Epoch 261/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6664 - binary_accuracy: 0.5982 - val_loss: 0.6621 - val_binary_accuracy: 0.5981\n",
            "Epoch 262/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6664 - binary_accuracy: 0.5981 - val_loss: 0.6621 - val_binary_accuracy: 0.5986\n",
            "Epoch 263/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6664 - binary_accuracy: 0.5974 - val_loss: 0.6621 - val_binary_accuracy: 0.5963\n",
            "Epoch 264/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6663 - binary_accuracy: 0.5994 - val_loss: 0.6620 - val_binary_accuracy: 0.5986\n",
            "Epoch 265/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6663 - binary_accuracy: 0.5975 - val_loss: 0.6620 - val_binary_accuracy: 0.5975\n",
            "Epoch 266/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6663 - binary_accuracy: 0.5979 - val_loss: 0.6620 - val_binary_accuracy: 0.5969\n",
            "Epoch 267/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6663 - binary_accuracy: 0.5976 - val_loss: 0.6620 - val_binary_accuracy: 0.5963\n",
            "Epoch 268/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6662 - binary_accuracy: 0.5981 - val_loss: 0.6620 - val_binary_accuracy: 0.5963\n",
            "Epoch 269/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6662 - binary_accuracy: 0.5999 - val_loss: 0.6619 - val_binary_accuracy: 0.5963\n",
            "Epoch 270/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6662 - binary_accuracy: 0.5982 - val_loss: 0.6619 - val_binary_accuracy: 0.5969\n",
            "Epoch 271/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6662 - binary_accuracy: 0.5979 - val_loss: 0.6619 - val_binary_accuracy: 0.5981\n",
            "Epoch 272/1000\n",
            "6974/6974 [==============================] - 0s 66us/sample - loss: 0.6662 - binary_accuracy: 0.5979 - val_loss: 0.6619 - val_binary_accuracy: 0.5969\n",
            "Epoch 273/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6661 - binary_accuracy: 0.5979 - val_loss: 0.6618 - val_binary_accuracy: 0.5981\n",
            "Epoch 274/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6661 - binary_accuracy: 0.5979 - val_loss: 0.6618 - val_binary_accuracy: 0.5969\n",
            "Epoch 275/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6661 - binary_accuracy: 0.5987 - val_loss: 0.6618 - val_binary_accuracy: 0.5975\n",
            "Epoch 276/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6661 - binary_accuracy: 0.5991 - val_loss: 0.6618 - val_binary_accuracy: 0.5986\n",
            "Epoch 277/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6661 - binary_accuracy: 0.5987 - val_loss: 0.6618 - val_binary_accuracy: 0.5986\n",
            "Epoch 278/1000\n",
            "6974/6974 [==============================] - 0s 62us/sample - loss: 0.6661 - binary_accuracy: 0.5981 - val_loss: 0.6617 - val_binary_accuracy: 0.5992\n",
            "Epoch 279/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6660 - binary_accuracy: 0.5978 - val_loss: 0.6617 - val_binary_accuracy: 0.5981\n",
            "Epoch 280/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6660 - binary_accuracy: 0.5987 - val_loss: 0.6617 - val_binary_accuracy: 0.5992\n",
            "Epoch 281/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6660 - binary_accuracy: 0.5978 - val_loss: 0.6617 - val_binary_accuracy: 0.5969\n",
            "Epoch 282/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6660 - binary_accuracy: 0.5992 - val_loss: 0.6617 - val_binary_accuracy: 0.5986\n",
            "Epoch 283/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6660 - binary_accuracy: 0.5978 - val_loss: 0.6616 - val_binary_accuracy: 0.5986\n",
            "Epoch 284/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6659 - binary_accuracy: 0.5978 - val_loss: 0.6616 - val_binary_accuracy: 0.5986\n",
            "Epoch 285/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6659 - binary_accuracy: 0.5981 - val_loss: 0.6616 - val_binary_accuracy: 0.5998\n",
            "Epoch 286/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6659 - binary_accuracy: 0.5968 - val_loss: 0.6616 - val_binary_accuracy: 0.5986\n",
            "Epoch 287/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6659 - binary_accuracy: 0.5982 - val_loss: 0.6616 - val_binary_accuracy: 0.5992\n",
            "Epoch 288/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6659 - binary_accuracy: 0.5974 - val_loss: 0.6616 - val_binary_accuracy: 0.5992\n",
            "Epoch 289/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6659 - binary_accuracy: 0.5975 - val_loss: 0.6615 - val_binary_accuracy: 0.5981\n",
            "Epoch 290/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6659 - binary_accuracy: 0.5978 - val_loss: 0.6615 - val_binary_accuracy: 0.5981\n",
            "Epoch 291/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6658 - binary_accuracy: 0.5968 - val_loss: 0.6615 - val_binary_accuracy: 0.5998\n",
            "Epoch 292/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6658 - binary_accuracy: 0.5987 - val_loss: 0.6615 - val_binary_accuracy: 0.5981\n",
            "Epoch 293/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6658 - binary_accuracy: 0.5981 - val_loss: 0.6615 - val_binary_accuracy: 0.5992\n",
            "Epoch 294/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6658 - binary_accuracy: 0.5981 - val_loss: 0.6614 - val_binary_accuracy: 0.5992\n",
            "Epoch 295/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6658 - binary_accuracy: 0.5978 - val_loss: 0.6614 - val_binary_accuracy: 0.5986\n",
            "Epoch 296/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6657 - binary_accuracy: 0.5975 - val_loss: 0.6614 - val_binary_accuracy: 0.5981\n",
            "Epoch 297/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6657 - binary_accuracy: 0.5975 - val_loss: 0.6614 - val_binary_accuracy: 0.5981\n",
            "Epoch 298/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6657 - binary_accuracy: 0.5989 - val_loss: 0.6614 - val_binary_accuracy: 0.5986\n",
            "Epoch 299/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6657 - binary_accuracy: 0.5978 - val_loss: 0.6614 - val_binary_accuracy: 0.5986\n",
            "Epoch 300/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6657 - binary_accuracy: 0.5975 - val_loss: 0.6614 - val_binary_accuracy: 0.5992\n",
            "Epoch 301/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6657 - binary_accuracy: 0.5984 - val_loss: 0.6614 - val_binary_accuracy: 0.5975\n",
            "Epoch 302/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6656 - binary_accuracy: 0.5978 - val_loss: 0.6613 - val_binary_accuracy: 0.5981\n",
            "Epoch 303/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6657 - binary_accuracy: 0.5975 - val_loss: 0.6613 - val_binary_accuracy: 0.5986\n",
            "Epoch 304/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6656 - binary_accuracy: 0.5975 - val_loss: 0.6613 - val_binary_accuracy: 0.5981\n",
            "Epoch 305/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6656 - binary_accuracy: 0.5991 - val_loss: 0.6613 - val_binary_accuracy: 0.5981\n",
            "Epoch 306/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6656 - binary_accuracy: 0.5981 - val_loss: 0.6613 - val_binary_accuracy: 0.5981\n",
            "Epoch 307/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6656 - binary_accuracy: 0.5981 - val_loss: 0.6613 - val_binary_accuracy: 0.5981\n",
            "Epoch 308/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6656 - binary_accuracy: 0.5982 - val_loss: 0.6613 - val_binary_accuracy: 0.5981\n",
            "Epoch 309/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6656 - binary_accuracy: 0.5985 - val_loss: 0.6612 - val_binary_accuracy: 0.5981\n",
            "Epoch 310/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6656 - binary_accuracy: 0.5981 - val_loss: 0.6612 - val_binary_accuracy: 0.5975\n",
            "Epoch 311/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6655 - binary_accuracy: 0.5984 - val_loss: 0.6612 - val_binary_accuracy: 0.5975\n",
            "Epoch 312/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6655 - binary_accuracy: 0.5981 - val_loss: 0.6612 - val_binary_accuracy: 0.5975\n",
            "Epoch 313/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6655 - binary_accuracy: 0.5979 - val_loss: 0.6612 - val_binary_accuracy: 0.5975\n",
            "Epoch 314/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6655 - binary_accuracy: 0.5988 - val_loss: 0.6612 - val_binary_accuracy: 0.5975\n",
            "Epoch 315/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6655 - binary_accuracy: 0.5978 - val_loss: 0.6611 - val_binary_accuracy: 0.5975\n",
            "Epoch 316/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6655 - binary_accuracy: 0.5989 - val_loss: 0.6611 - val_binary_accuracy: 0.5975\n",
            "Epoch 317/1000\n",
            "6974/6974 [==============================] - 0s 66us/sample - loss: 0.6654 - binary_accuracy: 0.5979 - val_loss: 0.6611 - val_binary_accuracy: 0.5975\n",
            "Epoch 318/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6655 - binary_accuracy: 0.5978 - val_loss: 0.6611 - val_binary_accuracy: 0.5975\n",
            "Epoch 319/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6654 - binary_accuracy: 0.5981 - val_loss: 0.6611 - val_binary_accuracy: 0.5975\n",
            "Epoch 320/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6654 - binary_accuracy: 0.5984 - val_loss: 0.6611 - val_binary_accuracy: 0.5969\n",
            "Epoch 321/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6654 - binary_accuracy: 0.5988 - val_loss: 0.6611 - val_binary_accuracy: 0.5969\n",
            "Epoch 322/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6654 - binary_accuracy: 0.5985 - val_loss: 0.6611 - val_binary_accuracy: 0.5969\n",
            "Epoch 323/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6654 - binary_accuracy: 0.5982 - val_loss: 0.6611 - val_binary_accuracy: 0.5958\n",
            "Epoch 324/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6653 - binary_accuracy: 0.5994 - val_loss: 0.6610 - val_binary_accuracy: 0.5963\n",
            "Epoch 325/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6653 - binary_accuracy: 0.5984 - val_loss: 0.6610 - val_binary_accuracy: 0.5986\n",
            "Epoch 326/1000\n",
            "6974/6974 [==============================] - 1s 75us/sample - loss: 0.6653 - binary_accuracy: 0.5984 - val_loss: 0.6610 - val_binary_accuracy: 0.5952\n",
            "Epoch 327/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6653 - binary_accuracy: 0.5987 - val_loss: 0.6610 - val_binary_accuracy: 0.5986\n",
            "Epoch 328/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6653 - binary_accuracy: 0.5979 - val_loss: 0.6610 - val_binary_accuracy: 0.5969\n",
            "Epoch 329/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6653 - binary_accuracy: 0.5988 - val_loss: 0.6610 - val_binary_accuracy: 0.5952\n",
            "Epoch 330/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6653 - binary_accuracy: 0.5987 - val_loss: 0.6610 - val_binary_accuracy: 0.5975\n",
            "Epoch 331/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6653 - binary_accuracy: 0.5987 - val_loss: 0.6610 - val_binary_accuracy: 0.5958\n",
            "Epoch 332/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6653 - binary_accuracy: 0.5982 - val_loss: 0.6609 - val_binary_accuracy: 0.5958\n",
            "Epoch 333/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6652 - binary_accuracy: 0.5989 - val_loss: 0.6609 - val_binary_accuracy: 0.5969\n",
            "Epoch 334/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6652 - binary_accuracy: 0.5995 - val_loss: 0.6609 - val_binary_accuracy: 0.5963\n",
            "Epoch 335/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6652 - binary_accuracy: 0.5988 - val_loss: 0.6609 - val_binary_accuracy: 0.5981\n",
            "Epoch 336/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6652 - binary_accuracy: 0.5995 - val_loss: 0.6609 - val_binary_accuracy: 0.5975\n",
            "Epoch 337/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6652 - binary_accuracy: 0.5985 - val_loss: 0.6609 - val_binary_accuracy: 0.5969\n",
            "Epoch 338/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6652 - binary_accuracy: 0.5985 - val_loss: 0.6609 - val_binary_accuracy: 0.5969\n",
            "Epoch 339/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6652 - binary_accuracy: 0.5985 - val_loss: 0.6609 - val_binary_accuracy: 0.5975\n",
            "Epoch 340/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6652 - binary_accuracy: 0.5987 - val_loss: 0.6609 - val_binary_accuracy: 0.5969\n",
            "Epoch 341/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6651 - binary_accuracy: 0.5989 - val_loss: 0.6609 - val_binary_accuracy: 0.5986\n",
            "Epoch 342/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6651 - binary_accuracy: 0.5994 - val_loss: 0.6609 - val_binary_accuracy: 0.5981\n",
            "Epoch 343/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6651 - binary_accuracy: 0.5988 - val_loss: 0.6608 - val_binary_accuracy: 0.5969\n",
            "Epoch 344/1000\n",
            "6974/6974 [==============================] - 1s 75us/sample - loss: 0.6651 - binary_accuracy: 0.5991 - val_loss: 0.6608 - val_binary_accuracy: 0.5975\n",
            "Epoch 345/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6651 - binary_accuracy: 0.5991 - val_loss: 0.6608 - val_binary_accuracy: 0.5969\n",
            "Epoch 346/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6651 - binary_accuracy: 0.5988 - val_loss: 0.6608 - val_binary_accuracy: 0.5975\n",
            "Epoch 347/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6651 - binary_accuracy: 0.5989 - val_loss: 0.6608 - val_binary_accuracy: 0.5981\n",
            "Epoch 348/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6651 - binary_accuracy: 0.5985 - val_loss: 0.6608 - val_binary_accuracy: 0.5981\n",
            "Epoch 349/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6651 - binary_accuracy: 0.5988 - val_loss: 0.6608 - val_binary_accuracy: 0.5986\n",
            "Epoch 350/1000\n",
            "6974/6974 [==============================] - 0s 61us/sample - loss: 0.6650 - binary_accuracy: 0.5989 - val_loss: 0.6608 - val_binary_accuracy: 0.5986\n",
            "Epoch 351/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6650 - binary_accuracy: 0.5985 - val_loss: 0.6608 - val_binary_accuracy: 0.5986\n",
            "Epoch 352/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6651 - binary_accuracy: 0.5982 - val_loss: 0.6608 - val_binary_accuracy: 0.5981\n",
            "Epoch 353/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6650 - binary_accuracy: 0.5991 - val_loss: 0.6608 - val_binary_accuracy: 0.5981\n",
            "Epoch 354/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6650 - binary_accuracy: 0.5999 - val_loss: 0.6608 - val_binary_accuracy: 0.5986\n",
            "Epoch 355/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6650 - binary_accuracy: 0.5994 - val_loss: 0.6607 - val_binary_accuracy: 0.5986\n",
            "Epoch 356/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6650 - binary_accuracy: 0.5991 - val_loss: 0.6607 - val_binary_accuracy: 0.5986\n",
            "Epoch 357/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6650 - binary_accuracy: 0.6004 - val_loss: 0.6607 - val_binary_accuracy: 0.5992\n",
            "Epoch 358/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6650 - binary_accuracy: 0.5992 - val_loss: 0.6607 - val_binary_accuracy: 0.5981\n",
            "Epoch 359/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6650 - binary_accuracy: 0.5989 - val_loss: 0.6607 - val_binary_accuracy: 0.5992\n",
            "Epoch 360/1000\n",
            "6974/6974 [==============================] - 0s 66us/sample - loss: 0.6650 - binary_accuracy: 0.5979 - val_loss: 0.6607 - val_binary_accuracy: 0.5981\n",
            "Epoch 361/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6649 - binary_accuracy: 0.5998 - val_loss: 0.6607 - val_binary_accuracy: 0.5981\n",
            "Epoch 362/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6650 - binary_accuracy: 0.5984 - val_loss: 0.6607 - val_binary_accuracy: 0.5992\n",
            "Epoch 363/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6649 - binary_accuracy: 0.5984 - val_loss: 0.6607 - val_binary_accuracy: 0.5975\n",
            "Epoch 364/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6649 - binary_accuracy: 0.5997 - val_loss: 0.6607 - val_binary_accuracy: 0.5986\n",
            "Epoch 365/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6649 - binary_accuracy: 0.6002 - val_loss: 0.6607 - val_binary_accuracy: 0.5986\n",
            "Epoch 366/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6649 - binary_accuracy: 0.5988 - val_loss: 0.6607 - val_binary_accuracy: 0.5992\n",
            "Epoch 367/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6649 - binary_accuracy: 0.5995 - val_loss: 0.6607 - val_binary_accuracy: 0.5981\n",
            "Epoch 368/1000\n",
            "6974/6974 [==============================] - 1s 82us/sample - loss: 0.6649 - binary_accuracy: 0.5979 - val_loss: 0.6606 - val_binary_accuracy: 0.5981\n",
            "Epoch 369/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6649 - binary_accuracy: 0.5988 - val_loss: 0.6607 - val_binary_accuracy: 0.5992\n",
            "Epoch 370/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6649 - binary_accuracy: 0.5988 - val_loss: 0.6606 - val_binary_accuracy: 0.5981\n",
            "Epoch 371/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6648 - binary_accuracy: 0.5992 - val_loss: 0.6606 - val_binary_accuracy: 0.5986\n",
            "Epoch 372/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6648 - binary_accuracy: 0.5984 - val_loss: 0.6606 - val_binary_accuracy: 0.5986\n",
            "Epoch 373/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6648 - binary_accuracy: 0.5991 - val_loss: 0.6606 - val_binary_accuracy: 0.5986\n",
            "Epoch 374/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6648 - binary_accuracy: 0.5989 - val_loss: 0.6606 - val_binary_accuracy: 0.5992\n",
            "Epoch 375/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6648 - binary_accuracy: 0.5981 - val_loss: 0.6606 - val_binary_accuracy: 0.5986\n",
            "Epoch 376/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6648 - binary_accuracy: 0.5974 - val_loss: 0.6606 - val_binary_accuracy: 0.5986\n",
            "Epoch 377/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6648 - binary_accuracy: 0.5981 - val_loss: 0.6606 - val_binary_accuracy: 0.5992\n",
            "Epoch 378/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6648 - binary_accuracy: 0.5982 - val_loss: 0.6606 - val_binary_accuracy: 0.5992\n",
            "Epoch 379/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6648 - binary_accuracy: 0.5976 - val_loss: 0.6606 - val_binary_accuracy: 0.5998\n",
            "Epoch 380/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6648 - binary_accuracy: 0.5976 - val_loss: 0.6606 - val_binary_accuracy: 0.5992\n",
            "Epoch 381/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6648 - binary_accuracy: 0.5979 - val_loss: 0.6606 - val_binary_accuracy: 0.5981\n",
            "Epoch 382/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6647 - binary_accuracy: 0.5985 - val_loss: 0.6606 - val_binary_accuracy: 0.5992\n",
            "Epoch 383/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6647 - binary_accuracy: 0.5985 - val_loss: 0.6606 - val_binary_accuracy: 0.5992\n",
            "Epoch 384/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6647 - binary_accuracy: 0.5988 - val_loss: 0.6606 - val_binary_accuracy: 0.5986\n",
            "Epoch 385/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6647 - binary_accuracy: 0.5975 - val_loss: 0.6606 - val_binary_accuracy: 0.5992\n",
            "Epoch 386/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6647 - binary_accuracy: 0.5982 - val_loss: 0.6605 - val_binary_accuracy: 0.5992\n",
            "Epoch 387/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6647 - binary_accuracy: 0.5978 - val_loss: 0.6605 - val_binary_accuracy: 0.5992\n",
            "Epoch 388/1000\n",
            "6974/6974 [==============================] - 1s 84us/sample - loss: 0.6647 - binary_accuracy: 0.5989 - val_loss: 0.6605 - val_binary_accuracy: 0.5986\n",
            "Epoch 389/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6647 - binary_accuracy: 0.5991 - val_loss: 0.6605 - val_binary_accuracy: 0.5992\n",
            "Epoch 390/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6647 - binary_accuracy: 0.5982 - val_loss: 0.6605 - val_binary_accuracy: 0.5992\n",
            "Epoch 391/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6647 - binary_accuracy: 0.5968 - val_loss: 0.6605 - val_binary_accuracy: 0.5992\n",
            "Epoch 392/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6647 - binary_accuracy: 0.5992 - val_loss: 0.6605 - val_binary_accuracy: 0.5992\n",
            "Epoch 393/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6647 - binary_accuracy: 0.5984 - val_loss: 0.6605 - val_binary_accuracy: 0.5992\n",
            "Epoch 394/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6646 - binary_accuracy: 0.5979 - val_loss: 0.6605 - val_binary_accuracy: 0.5986\n",
            "Epoch 395/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6646 - binary_accuracy: 0.5979 - val_loss: 0.6605 - val_binary_accuracy: 0.5992\n",
            "Epoch 396/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6646 - binary_accuracy: 0.5988 - val_loss: 0.6605 - val_binary_accuracy: 0.5986\n",
            "Epoch 397/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6646 - binary_accuracy: 0.5981 - val_loss: 0.6605 - val_binary_accuracy: 0.5992\n",
            "Epoch 398/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6646 - binary_accuracy: 0.5987 - val_loss: 0.6605 - val_binary_accuracy: 0.5992\n",
            "Epoch 399/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6646 - binary_accuracy: 0.5982 - val_loss: 0.6605 - val_binary_accuracy: 0.5986\n",
            "Epoch 400/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6646 - binary_accuracy: 0.5992 - val_loss: 0.6605 - val_binary_accuracy: 0.5981\n",
            "Epoch 401/1000\n",
            "6974/6974 [==============================] - 1s 81us/sample - loss: 0.6646 - binary_accuracy: 0.5989 - val_loss: 0.6605 - val_binary_accuracy: 0.5986\n",
            "Epoch 402/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6646 - binary_accuracy: 0.5997 - val_loss: 0.6605 - val_binary_accuracy: 0.5992\n",
            "Epoch 403/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6645 - binary_accuracy: 0.5987 - val_loss: 0.6604 - val_binary_accuracy: 0.5986\n",
            "Epoch 404/1000\n",
            "6974/6974 [==============================] - 1s 93us/sample - loss: 0.6645 - binary_accuracy: 0.5985 - val_loss: 0.6604 - val_binary_accuracy: 0.5986\n",
            "Epoch 405/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6645 - binary_accuracy: 0.5988 - val_loss: 0.6604 - val_binary_accuracy: 0.6003\n",
            "Epoch 406/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6645 - binary_accuracy: 0.5989 - val_loss: 0.6604 - val_binary_accuracy: 0.5992\n",
            "Epoch 407/1000\n",
            "6974/6974 [==============================] - 0s 66us/sample - loss: 0.6645 - binary_accuracy: 0.5992 - val_loss: 0.6604 - val_binary_accuracy: 0.5992\n",
            "Epoch 408/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6645 - binary_accuracy: 0.5982 - val_loss: 0.6604 - val_binary_accuracy: 0.5998\n",
            "Epoch 409/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6645 - binary_accuracy: 0.5985 - val_loss: 0.6604 - val_binary_accuracy: 0.5998\n",
            "Epoch 410/1000\n",
            "6974/6974 [==============================] - 1s 84us/sample - loss: 0.6645 - binary_accuracy: 0.5988 - val_loss: 0.6604 - val_binary_accuracy: 0.5992\n",
            "Epoch 411/1000\n",
            "6974/6974 [==============================] - 1s 101us/sample - loss: 0.6645 - binary_accuracy: 0.5989 - val_loss: 0.6604 - val_binary_accuracy: 0.5998\n",
            "Epoch 412/1000\n",
            "6974/6974 [==============================] - 1s 80us/sample - loss: 0.6645 - binary_accuracy: 0.5992 - val_loss: 0.6604 - val_binary_accuracy: 0.6009\n",
            "Epoch 413/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6644 - binary_accuracy: 0.5987 - val_loss: 0.6604 - val_binary_accuracy: 0.5998\n",
            "Epoch 414/1000\n",
            "6974/6974 [==============================] - 1s 75us/sample - loss: 0.6645 - binary_accuracy: 0.5988 - val_loss: 0.6604 - val_binary_accuracy: 0.6003\n",
            "Epoch 415/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6645 - binary_accuracy: 0.5988 - val_loss: 0.6604 - val_binary_accuracy: 0.5992\n",
            "Epoch 416/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6644 - binary_accuracy: 0.5995 - val_loss: 0.6604 - val_binary_accuracy: 0.5998\n",
            "Epoch 417/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6644 - binary_accuracy: 0.5978 - val_loss: 0.6604 - val_binary_accuracy: 0.6009\n",
            "Epoch 418/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6644 - binary_accuracy: 0.5984 - val_loss: 0.6603 - val_binary_accuracy: 0.6003\n",
            "Epoch 419/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6644 - binary_accuracy: 0.5987 - val_loss: 0.6603 - val_binary_accuracy: 0.5998\n",
            "Epoch 420/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6644 - binary_accuracy: 0.5988 - val_loss: 0.6603 - val_binary_accuracy: 0.6009\n",
            "Epoch 421/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6644 - binary_accuracy: 0.5984 - val_loss: 0.6603 - val_binary_accuracy: 0.5998\n",
            "Epoch 422/1000\n",
            "6974/6974 [==============================] - 1s 75us/sample - loss: 0.6644 - binary_accuracy: 0.5989 - val_loss: 0.6603 - val_binary_accuracy: 0.6009\n",
            "Epoch 423/1000\n",
            "6974/6974 [==============================] - 1s 80us/sample - loss: 0.6644 - binary_accuracy: 0.5989 - val_loss: 0.6603 - val_binary_accuracy: 0.6009\n",
            "Epoch 424/1000\n",
            "6974/6974 [==============================] - 1s 95us/sample - loss: 0.6644 - binary_accuracy: 0.5995 - val_loss: 0.6603 - val_binary_accuracy: 0.6015\n",
            "Epoch 425/1000\n",
            "6974/6974 [==============================] - 1s 92us/sample - loss: 0.6644 - binary_accuracy: 0.5994 - val_loss: 0.6603 - val_binary_accuracy: 0.6003\n",
            "Epoch 426/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6643 - binary_accuracy: 0.5981 - val_loss: 0.6603 - val_binary_accuracy: 0.6009\n",
            "Epoch 427/1000\n",
            "6974/6974 [==============================] - 1s 87us/sample - loss: 0.6643 - binary_accuracy: 0.5989 - val_loss: 0.6603 - val_binary_accuracy: 0.5998\n",
            "Epoch 428/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6643 - binary_accuracy: 0.5992 - val_loss: 0.6603 - val_binary_accuracy: 0.6009\n",
            "Epoch 429/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6643 - binary_accuracy: 0.6002 - val_loss: 0.6603 - val_binary_accuracy: 0.6009\n",
            "Epoch 430/1000\n",
            "6974/6974 [==============================] - 1s 83us/sample - loss: 0.6643 - binary_accuracy: 0.5987 - val_loss: 0.6603 - val_binary_accuracy: 0.6015\n",
            "Epoch 431/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6643 - binary_accuracy: 0.5998 - val_loss: 0.6603 - val_binary_accuracy: 0.6003\n",
            "Epoch 432/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6643 - binary_accuracy: 0.6001 - val_loss: 0.6603 - val_binary_accuracy: 0.6015\n",
            "Epoch 433/1000\n",
            "6974/6974 [==============================] - 1s 87us/sample - loss: 0.6643 - binary_accuracy: 0.5992 - val_loss: 0.6603 - val_binary_accuracy: 0.6009\n",
            "Epoch 434/1000\n",
            "6974/6974 [==============================] - 1s 88us/sample - loss: 0.6643 - binary_accuracy: 0.5988 - val_loss: 0.6603 - val_binary_accuracy: 0.6009\n",
            "Epoch 435/1000\n",
            "6974/6974 [==============================] - 1s 83us/sample - loss: 0.6643 - binary_accuracy: 0.5997 - val_loss: 0.6603 - val_binary_accuracy: 0.6015\n",
            "Epoch 436/1000\n",
            "6974/6974 [==============================] - 1s 83us/sample - loss: 0.6643 - binary_accuracy: 0.5998 - val_loss: 0.6603 - val_binary_accuracy: 0.6009\n",
            "Epoch 437/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6643 - binary_accuracy: 0.5999 - val_loss: 0.6603 - val_binary_accuracy: 0.6015\n",
            "Epoch 438/1000\n",
            "6974/6974 [==============================] - 1s 85us/sample - loss: 0.6643 - binary_accuracy: 0.6002 - val_loss: 0.6603 - val_binary_accuracy: 0.6015\n",
            "Epoch 439/1000\n",
            "6974/6974 [==============================] - 1s 87us/sample - loss: 0.6642 - binary_accuracy: 0.6001 - val_loss: 0.6602 - val_binary_accuracy: 0.6015\n",
            "Epoch 440/1000\n",
            "6974/6974 [==============================] - 1s 94us/sample - loss: 0.6642 - binary_accuracy: 0.5995 - val_loss: 0.6602 - val_binary_accuracy: 0.5998\n",
            "Epoch 441/1000\n",
            "6974/6974 [==============================] - 1s 80us/sample - loss: 0.6642 - binary_accuracy: 0.5998 - val_loss: 0.6602 - val_binary_accuracy: 0.5998\n",
            "Epoch 442/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6642 - binary_accuracy: 0.5998 - val_loss: 0.6602 - val_binary_accuracy: 0.6003\n",
            "Epoch 443/1000\n",
            "6974/6974 [==============================] - 1s 86us/sample - loss: 0.6642 - binary_accuracy: 0.5992 - val_loss: 0.6602 - val_binary_accuracy: 0.5992\n",
            "Epoch 444/1000\n",
            "6974/6974 [==============================] - 1s 75us/sample - loss: 0.6642 - binary_accuracy: 0.6001 - val_loss: 0.6602 - val_binary_accuracy: 0.5986\n",
            "Epoch 445/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6642 - binary_accuracy: 0.6002 - val_loss: 0.6602 - val_binary_accuracy: 0.5992\n",
            "Epoch 446/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6642 - binary_accuracy: 0.6001 - val_loss: 0.6602 - val_binary_accuracy: 0.5986\n",
            "Epoch 447/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6642 - binary_accuracy: 0.6002 - val_loss: 0.6602 - val_binary_accuracy: 0.6003\n",
            "Epoch 448/1000\n",
            "6974/6974 [==============================] - 1s 75us/sample - loss: 0.6642 - binary_accuracy: 0.6008 - val_loss: 0.6602 - val_binary_accuracy: 0.5992\n",
            "Epoch 449/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6642 - binary_accuracy: 0.6004 - val_loss: 0.6602 - val_binary_accuracy: 0.6009\n",
            "Epoch 450/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6642 - binary_accuracy: 0.6001 - val_loss: 0.6602 - val_binary_accuracy: 0.5986\n",
            "Epoch 451/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6642 - binary_accuracy: 0.5992 - val_loss: 0.6602 - val_binary_accuracy: 0.5998\n",
            "Epoch 452/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6641 - binary_accuracy: 0.5995 - val_loss: 0.6602 - val_binary_accuracy: 0.6003\n",
            "Epoch 453/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6641 - binary_accuracy: 0.6007 - val_loss: 0.6602 - val_binary_accuracy: 0.5986\n",
            "Epoch 454/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6641 - binary_accuracy: 0.6011 - val_loss: 0.6602 - val_binary_accuracy: 0.5986\n",
            "Epoch 455/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6641 - binary_accuracy: 0.6001 - val_loss: 0.6602 - val_binary_accuracy: 0.5998\n",
            "Epoch 456/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6641 - binary_accuracy: 0.6001 - val_loss: 0.6602 - val_binary_accuracy: 0.5998\n",
            "Epoch 457/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6641 - binary_accuracy: 0.5999 - val_loss: 0.6602 - val_binary_accuracy: 0.5986\n",
            "Epoch 458/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6641 - binary_accuracy: 0.6005 - val_loss: 0.6602 - val_binary_accuracy: 0.5986\n",
            "Epoch 459/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6641 - binary_accuracy: 0.6012 - val_loss: 0.6602 - val_binary_accuracy: 0.5992\n",
            "Epoch 460/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6641 - binary_accuracy: 0.5999 - val_loss: 0.6602 - val_binary_accuracy: 0.5998\n",
            "Epoch 461/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6641 - binary_accuracy: 0.5999 - val_loss: 0.6602 - val_binary_accuracy: 0.5986\n",
            "Epoch 462/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6641 - binary_accuracy: 0.6002 - val_loss: 0.6602 - val_binary_accuracy: 0.6003\n",
            "Epoch 463/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6640 - binary_accuracy: 0.5998 - val_loss: 0.6602 - val_binary_accuracy: 0.5981\n",
            "Epoch 464/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6640 - binary_accuracy: 0.5998 - val_loss: 0.6602 - val_binary_accuracy: 0.5981\n",
            "Epoch 465/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6640 - binary_accuracy: 0.5999 - val_loss: 0.6601 - val_binary_accuracy: 0.5986\n",
            "Epoch 466/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6640 - binary_accuracy: 0.5995 - val_loss: 0.6601 - val_binary_accuracy: 0.5986\n",
            "Epoch 467/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6640 - binary_accuracy: 0.6008 - val_loss: 0.6602 - val_binary_accuracy: 0.5998\n",
            "Epoch 468/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6640 - binary_accuracy: 0.6001 - val_loss: 0.6601 - val_binary_accuracy: 0.5981\n",
            "Epoch 469/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6640 - binary_accuracy: 0.6009 - val_loss: 0.6601 - val_binary_accuracy: 0.5981\n",
            "Epoch 470/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6640 - binary_accuracy: 0.6009 - val_loss: 0.6601 - val_binary_accuracy: 0.5986\n",
            "Epoch 471/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6640 - binary_accuracy: 0.6009 - val_loss: 0.6601 - val_binary_accuracy: 0.5986\n",
            "Epoch 472/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6640 - binary_accuracy: 0.6005 - val_loss: 0.6601 - val_binary_accuracy: 0.5998\n",
            "Epoch 473/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6640 - binary_accuracy: 0.5998 - val_loss: 0.6601 - val_binary_accuracy: 0.5986\n",
            "Epoch 474/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6640 - binary_accuracy: 0.6012 - val_loss: 0.6601 - val_binary_accuracy: 0.5986\n",
            "Epoch 475/1000\n",
            "6974/6974 [==============================] - 1s 80us/sample - loss: 0.6640 - binary_accuracy: 0.6005 - val_loss: 0.6601 - val_binary_accuracy: 0.5981\n",
            "Epoch 476/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6640 - binary_accuracy: 0.6001 - val_loss: 0.6601 - val_binary_accuracy: 0.5986\n",
            "Epoch 477/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6639 - binary_accuracy: 0.5997 - val_loss: 0.6601 - val_binary_accuracy: 0.6003\n",
            "Epoch 478/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6639 - binary_accuracy: 0.6002 - val_loss: 0.6601 - val_binary_accuracy: 0.5986\n",
            "Epoch 479/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6639 - binary_accuracy: 0.6005 - val_loss: 0.6601 - val_binary_accuracy: 0.5992\n",
            "Epoch 480/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6640 - binary_accuracy: 0.6009 - val_loss: 0.6601 - val_binary_accuracy: 0.5986\n",
            "Epoch 481/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6639 - binary_accuracy: 0.6004 - val_loss: 0.6601 - val_binary_accuracy: 0.5998\n",
            "Epoch 482/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6639 - binary_accuracy: 0.6004 - val_loss: 0.6601 - val_binary_accuracy: 0.5981\n",
            "Epoch 483/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6639 - binary_accuracy: 0.6001 - val_loss: 0.6601 - val_binary_accuracy: 0.5975\n",
            "Epoch 484/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6639 - binary_accuracy: 0.5999 - val_loss: 0.6601 - val_binary_accuracy: 0.5998\n",
            "Epoch 485/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6639 - binary_accuracy: 0.6007 - val_loss: 0.6601 - val_binary_accuracy: 0.6003\n",
            "Epoch 486/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6639 - binary_accuracy: 0.6012 - val_loss: 0.6601 - val_binary_accuracy: 0.5986\n",
            "Epoch 487/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6639 - binary_accuracy: 0.6011 - val_loss: 0.6601 - val_binary_accuracy: 0.5986\n",
            "Epoch 488/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6639 - binary_accuracy: 0.6009 - val_loss: 0.6601 - val_binary_accuracy: 0.5975\n",
            "Epoch 489/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6638 - binary_accuracy: 0.5998 - val_loss: 0.6601 - val_binary_accuracy: 0.5986\n",
            "Epoch 490/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6638 - binary_accuracy: 0.5998 - val_loss: 0.6601 - val_binary_accuracy: 0.5975\n",
            "Epoch 491/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6638 - binary_accuracy: 0.6004 - val_loss: 0.6601 - val_binary_accuracy: 0.5992\n",
            "Epoch 492/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6638 - binary_accuracy: 0.6007 - val_loss: 0.6601 - val_binary_accuracy: 0.5986\n",
            "Epoch 493/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6638 - binary_accuracy: 0.5997 - val_loss: 0.6601 - val_binary_accuracy: 0.5992\n",
            "Epoch 494/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6638 - binary_accuracy: 0.6002 - val_loss: 0.6601 - val_binary_accuracy: 0.5975\n",
            "Epoch 495/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6638 - binary_accuracy: 0.6008 - val_loss: 0.6601 - val_binary_accuracy: 0.5975\n",
            "Epoch 496/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6638 - binary_accuracy: 0.5995 - val_loss: 0.6601 - val_binary_accuracy: 0.5981\n",
            "Epoch 497/1000\n",
            "6974/6974 [==============================] - 1s 136us/sample - loss: 0.6638 - binary_accuracy: 0.6011 - val_loss: 0.6601 - val_binary_accuracy: 0.5986\n",
            "Epoch 498/1000\n",
            "6974/6974 [==============================] - 1s 117us/sample - loss: 0.6638 - binary_accuracy: 0.6005 - val_loss: 0.6601 - val_binary_accuracy: 0.5986\n",
            "Epoch 499/1000\n",
            "6974/6974 [==============================] - 1s 162us/sample - loss: 0.6638 - binary_accuracy: 0.6004 - val_loss: 0.6601 - val_binary_accuracy: 0.5975\n",
            "Epoch 500/1000\n",
            "6974/6974 [==============================] - 1s 145us/sample - loss: 0.6638 - binary_accuracy: 0.6005 - val_loss: 0.6601 - val_binary_accuracy: 0.5986\n",
            "Epoch 501/1000\n",
            "6974/6974 [==============================] - 1s 132us/sample - loss: 0.6638 - binary_accuracy: 0.6011 - val_loss: 0.6601 - val_binary_accuracy: 0.5986\n",
            "Epoch 502/1000\n",
            "6974/6974 [==============================] - 1s 130us/sample - loss: 0.6638 - binary_accuracy: 0.6011 - val_loss: 0.6601 - val_binary_accuracy: 0.5992\n",
            "Epoch 503/1000\n",
            "6974/6974 [==============================] - 1s 149us/sample - loss: 0.6638 - binary_accuracy: 0.5988 - val_loss: 0.6601 - val_binary_accuracy: 0.5981\n",
            "Epoch 504/1000\n",
            "6974/6974 [==============================] - 1s 173us/sample - loss: 0.6637 - binary_accuracy: 0.6004 - val_loss: 0.6601 - val_binary_accuracy: 0.5992\n",
            "Epoch 505/1000\n",
            "6974/6974 [==============================] - 1s 167us/sample - loss: 0.6637 - binary_accuracy: 0.6011 - val_loss: 0.6600 - val_binary_accuracy: 0.5992\n",
            "Epoch 506/1000\n",
            "6974/6974 [==============================] - 1s 168us/sample - loss: 0.6637 - binary_accuracy: 0.6009 - val_loss: 0.6600 - val_binary_accuracy: 0.5981\n",
            "Epoch 507/1000\n",
            "6974/6974 [==============================] - 1s 181us/sample - loss: 0.6637 - binary_accuracy: 0.6009 - val_loss: 0.6600 - val_binary_accuracy: 0.5986\n",
            "Epoch 508/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6637 - binary_accuracy: 0.6007 - val_loss: 0.6600 - val_binary_accuracy: 0.6003\n",
            "Epoch 509/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6637 - binary_accuracy: 0.6001 - val_loss: 0.6600 - val_binary_accuracy: 0.5998\n",
            "Epoch 510/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6637 - binary_accuracy: 0.6009 - val_loss: 0.6600 - val_binary_accuracy: 0.6009\n",
            "Epoch 511/1000\n",
            "6974/6974 [==============================] - 1s 80us/sample - loss: 0.6637 - binary_accuracy: 0.5999 - val_loss: 0.6600 - val_binary_accuracy: 0.5992\n",
            "Epoch 512/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6637 - binary_accuracy: 0.6012 - val_loss: 0.6600 - val_binary_accuracy: 0.5986\n",
            "Epoch 513/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6637 - binary_accuracy: 0.6007 - val_loss: 0.6600 - val_binary_accuracy: 0.5992\n",
            "Epoch 514/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6637 - binary_accuracy: 0.6014 - val_loss: 0.6600 - val_binary_accuracy: 0.5986\n",
            "Epoch 515/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6637 - binary_accuracy: 0.6007 - val_loss: 0.6600 - val_binary_accuracy: 0.5998\n",
            "Epoch 516/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6637 - binary_accuracy: 0.6001 - val_loss: 0.6600 - val_binary_accuracy: 0.6009\n",
            "Epoch 517/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6637 - binary_accuracy: 0.6005 - val_loss: 0.6600 - val_binary_accuracy: 0.5998\n",
            "Epoch 518/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6637 - binary_accuracy: 0.6011 - val_loss: 0.6600 - val_binary_accuracy: 0.5998\n",
            "Epoch 519/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6636 - binary_accuracy: 0.6004 - val_loss: 0.6600 - val_binary_accuracy: 0.5992\n",
            "Epoch 520/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6636 - binary_accuracy: 0.6001 - val_loss: 0.6600 - val_binary_accuracy: 0.5998\n",
            "Epoch 521/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6636 - binary_accuracy: 0.6005 - val_loss: 0.6600 - val_binary_accuracy: 0.6015\n",
            "Epoch 522/1000\n",
            "6974/6974 [==============================] - 1s 75us/sample - loss: 0.6636 - binary_accuracy: 0.5994 - val_loss: 0.6600 - val_binary_accuracy: 0.5992\n",
            "Epoch 523/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6636 - binary_accuracy: 0.6004 - val_loss: 0.6600 - val_binary_accuracy: 0.5992\n",
            "Epoch 524/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6636 - binary_accuracy: 0.6005 - val_loss: 0.6600 - val_binary_accuracy: 0.6003\n",
            "Epoch 525/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6636 - binary_accuracy: 0.6004 - val_loss: 0.6600 - val_binary_accuracy: 0.6015\n",
            "Epoch 526/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6636 - binary_accuracy: 0.6005 - val_loss: 0.6600 - val_binary_accuracy: 0.6003\n",
            "Epoch 527/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6636 - binary_accuracy: 0.6004 - val_loss: 0.6600 - val_binary_accuracy: 0.6003\n",
            "Epoch 528/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6636 - binary_accuracy: 0.5999 - val_loss: 0.6600 - val_binary_accuracy: 0.6009\n",
            "Epoch 529/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6636 - binary_accuracy: 0.5995 - val_loss: 0.6600 - val_binary_accuracy: 0.6021\n",
            "Epoch 530/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6636 - binary_accuracy: 0.6017 - val_loss: 0.6600 - val_binary_accuracy: 0.6003\n",
            "Epoch 531/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6636 - binary_accuracy: 0.6007 - val_loss: 0.6600 - val_binary_accuracy: 0.6026\n",
            "Epoch 532/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6636 - binary_accuracy: 0.6001 - val_loss: 0.6600 - val_binary_accuracy: 0.6021\n",
            "Epoch 533/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6636 - binary_accuracy: 0.6004 - val_loss: 0.6600 - val_binary_accuracy: 0.6026\n",
            "Epoch 534/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6636 - binary_accuracy: 0.6015 - val_loss: 0.6600 - val_binary_accuracy: 0.6021\n",
            "Epoch 535/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6635 - binary_accuracy: 0.6002 - val_loss: 0.6600 - val_binary_accuracy: 0.6026\n",
            "Epoch 536/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6636 - binary_accuracy: 0.6001 - val_loss: 0.6600 - val_binary_accuracy: 0.6038\n",
            "Epoch 537/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6635 - binary_accuracy: 0.6012 - val_loss: 0.6600 - val_binary_accuracy: 0.6021\n",
            "Epoch 538/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6635 - binary_accuracy: 0.6018 - val_loss: 0.6600 - val_binary_accuracy: 0.6015\n",
            "Epoch 539/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6636 - binary_accuracy: 0.6020 - val_loss: 0.6600 - val_binary_accuracy: 0.6038\n",
            "Epoch 540/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6635 - binary_accuracy: 0.5998 - val_loss: 0.6600 - val_binary_accuracy: 0.6038\n",
            "Epoch 541/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6635 - binary_accuracy: 0.6014 - val_loss: 0.6599 - val_binary_accuracy: 0.6026\n",
            "Epoch 542/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6635 - binary_accuracy: 0.6007 - val_loss: 0.6600 - val_binary_accuracy: 0.6032\n",
            "Epoch 543/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6635 - binary_accuracy: 0.6014 - val_loss: 0.6600 - val_binary_accuracy: 0.6015\n",
            "Epoch 544/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6635 - binary_accuracy: 0.6007 - val_loss: 0.6599 - val_binary_accuracy: 0.6044\n",
            "Epoch 545/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6635 - binary_accuracy: 0.6021 - val_loss: 0.6599 - val_binary_accuracy: 0.6032\n",
            "Epoch 546/1000\n",
            "6974/6974 [==============================] - 1s 84us/sample - loss: 0.6635 - binary_accuracy: 0.6018 - val_loss: 0.6599 - val_binary_accuracy: 0.6032\n",
            "Epoch 547/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6635 - binary_accuracy: 0.6009 - val_loss: 0.6599 - val_binary_accuracy: 0.6021\n",
            "Epoch 548/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6635 - binary_accuracy: 0.6011 - val_loss: 0.6599 - val_binary_accuracy: 0.6044\n",
            "Epoch 549/1000\n",
            "6974/6974 [==============================] - 1s 89us/sample - loss: 0.6635 - binary_accuracy: 0.5999 - val_loss: 0.6599 - val_binary_accuracy: 0.6032\n",
            "Epoch 550/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6635 - binary_accuracy: 0.6002 - val_loss: 0.6599 - val_binary_accuracy: 0.6038\n",
            "Epoch 551/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6635 - binary_accuracy: 0.6020 - val_loss: 0.6599 - val_binary_accuracy: 0.6032\n",
            "Epoch 552/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6634 - binary_accuracy: 0.6005 - val_loss: 0.6599 - val_binary_accuracy: 0.6026\n",
            "Epoch 553/1000\n",
            "6974/6974 [==============================] - 1s 91us/sample - loss: 0.6634 - binary_accuracy: 0.6011 - val_loss: 0.6599 - val_binary_accuracy: 0.6026\n",
            "Epoch 554/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6634 - binary_accuracy: 0.5997 - val_loss: 0.6599 - val_binary_accuracy: 0.6038\n",
            "Epoch 555/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6635 - binary_accuracy: 0.6008 - val_loss: 0.6599 - val_binary_accuracy: 0.6032\n",
            "Epoch 556/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6634 - binary_accuracy: 0.6004 - val_loss: 0.6599 - val_binary_accuracy: 0.6032\n",
            "Epoch 557/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6634 - binary_accuracy: 0.6007 - val_loss: 0.6599 - val_binary_accuracy: 0.6038\n",
            "Epoch 558/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6634 - binary_accuracy: 0.6018 - val_loss: 0.6599 - val_binary_accuracy: 0.6038\n",
            "Epoch 559/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6634 - binary_accuracy: 0.6020 - val_loss: 0.6599 - val_binary_accuracy: 0.6032\n",
            "Epoch 560/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6634 - binary_accuracy: 0.6012 - val_loss: 0.6599 - val_binary_accuracy: 0.6038\n",
            "Epoch 561/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6634 - binary_accuracy: 0.6025 - val_loss: 0.6599 - val_binary_accuracy: 0.6038\n",
            "Epoch 562/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6634 - binary_accuracy: 0.6012 - val_loss: 0.6599 - val_binary_accuracy: 0.6038\n",
            "Epoch 563/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6634 - binary_accuracy: 0.6014 - val_loss: 0.6599 - val_binary_accuracy: 0.6038\n",
            "Epoch 564/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6634 - binary_accuracy: 0.6027 - val_loss: 0.6599 - val_binary_accuracy: 0.6026\n",
            "Epoch 565/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6634 - binary_accuracy: 0.6004 - val_loss: 0.6599 - val_binary_accuracy: 0.6026\n",
            "Epoch 566/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6634 - binary_accuracy: 0.6008 - val_loss: 0.6599 - val_binary_accuracy: 0.6026\n",
            "Epoch 567/1000\n",
            "6974/6974 [==============================] - 1s 80us/sample - loss: 0.6634 - binary_accuracy: 0.6018 - val_loss: 0.6599 - val_binary_accuracy: 0.6038\n",
            "Epoch 568/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6634 - binary_accuracy: 0.6011 - val_loss: 0.6599 - val_binary_accuracy: 0.6032\n",
            "Epoch 569/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6634 - binary_accuracy: 0.6018 - val_loss: 0.6599 - val_binary_accuracy: 0.6032\n",
            "Epoch 570/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6634 - binary_accuracy: 0.6021 - val_loss: 0.6599 - val_binary_accuracy: 0.6032\n",
            "Epoch 571/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6633 - binary_accuracy: 0.6012 - val_loss: 0.6599 - val_binary_accuracy: 0.6032\n",
            "(6974, 20)\n",
            "(1744, 20)\n",
            "Train on 6974 samples, validate on 1744 samples\n",
            "Epoch 1/1000\n",
            "6974/6974 [==============================] - 1s 107us/sample - loss: 0.6922 - binary_accuracy: 0.5029 - val_loss: 0.6917 - val_binary_accuracy: 0.5029\n",
            "Epoch 2/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6917 - binary_accuracy: 0.5054 - val_loss: 0.6913 - val_binary_accuracy: 0.5034\n",
            "Epoch 3/1000\n",
            "6974/6974 [==============================] - 1s 84us/sample - loss: 0.6914 - binary_accuracy: 0.5063 - val_loss: 0.6910 - val_binary_accuracy: 0.5092\n",
            "Epoch 4/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6911 - binary_accuracy: 0.5092 - val_loss: 0.6906 - val_binary_accuracy: 0.5103\n",
            "Epoch 5/1000\n",
            "6974/6974 [==============================] - 1s 92us/sample - loss: 0.6909 - binary_accuracy: 0.5128 - val_loss: 0.6903 - val_binary_accuracy: 0.5161\n",
            "Epoch 6/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6906 - binary_accuracy: 0.5141 - val_loss: 0.6900 - val_binary_accuracy: 0.5172\n",
            "Epoch 7/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6904 - binary_accuracy: 0.5176 - val_loss: 0.6898 - val_binary_accuracy: 0.5269\n",
            "Epoch 8/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6902 - binary_accuracy: 0.5245 - val_loss: 0.6895 - val_binary_accuracy: 0.5361\n",
            "Epoch 9/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6900 - binary_accuracy: 0.5282 - val_loss: 0.6892 - val_binary_accuracy: 0.5413\n",
            "Epoch 10/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6897 - binary_accuracy: 0.5317 - val_loss: 0.6890 - val_binary_accuracy: 0.5407\n",
            "Epoch 11/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6895 - binary_accuracy: 0.5361 - val_loss: 0.6887 - val_binary_accuracy: 0.5442\n",
            "Epoch 12/1000\n",
            "6974/6974 [==============================] - 1s 80us/sample - loss: 0.6893 - binary_accuracy: 0.5369 - val_loss: 0.6884 - val_binary_accuracy: 0.5476\n",
            "Epoch 13/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6890 - binary_accuracy: 0.5419 - val_loss: 0.6880 - val_binary_accuracy: 0.5528\n",
            "Epoch 14/1000\n",
            "6974/6974 [==============================] - 1s 86us/sample - loss: 0.6887 - binary_accuracy: 0.5449 - val_loss: 0.6876 - val_binary_accuracy: 0.5568\n",
            "Epoch 15/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6883 - binary_accuracy: 0.5490 - val_loss: 0.6871 - val_binary_accuracy: 0.5648\n",
            "Epoch 16/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6880 - binary_accuracy: 0.5533 - val_loss: 0.6866 - val_binary_accuracy: 0.5734\n",
            "Epoch 17/1000\n",
            "6974/6974 [==============================] - 1s 84us/sample - loss: 0.6876 - binary_accuracy: 0.5572 - val_loss: 0.6861 - val_binary_accuracy: 0.5820\n",
            "Epoch 18/1000\n",
            "6974/6974 [==============================] - 1s 81us/sample - loss: 0.6872 - binary_accuracy: 0.5601 - val_loss: 0.6855 - val_binary_accuracy: 0.5837\n",
            "Epoch 19/1000\n",
            "6974/6974 [==============================] - 1s 80us/sample - loss: 0.6869 - binary_accuracy: 0.5641 - val_loss: 0.6850 - val_binary_accuracy: 0.5849\n",
            "Epoch 20/1000\n",
            "6974/6974 [==============================] - 1s 85us/sample - loss: 0.6865 - binary_accuracy: 0.5671 - val_loss: 0.6845 - val_binary_accuracy: 0.5872\n",
            "Epoch 21/1000\n",
            "6974/6974 [==============================] - 1s 92us/sample - loss: 0.6861 - binary_accuracy: 0.5713 - val_loss: 0.6840 - val_binary_accuracy: 0.5889\n",
            "Epoch 22/1000\n",
            "6974/6974 [==============================] - 1s 89us/sample - loss: 0.6857 - binary_accuracy: 0.5744 - val_loss: 0.6835 - val_binary_accuracy: 0.5952\n",
            "Epoch 23/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6853 - binary_accuracy: 0.5757 - val_loss: 0.6831 - val_binary_accuracy: 0.5946\n",
            "Epoch 24/1000\n",
            "6974/6974 [==============================] - 1s 83us/sample - loss: 0.6850 - binary_accuracy: 0.5744 - val_loss: 0.6827 - val_binary_accuracy: 0.5969\n",
            "Epoch 25/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6847 - binary_accuracy: 0.5736 - val_loss: 0.6822 - val_binary_accuracy: 0.5958\n",
            "Epoch 26/1000\n",
            "6974/6974 [==============================] - 1s 91us/sample - loss: 0.6844 - binary_accuracy: 0.5738 - val_loss: 0.6819 - val_binary_accuracy: 0.5952\n",
            "Epoch 27/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6841 - binary_accuracy: 0.5731 - val_loss: 0.6815 - val_binary_accuracy: 0.5935\n",
            "Epoch 28/1000\n",
            "6974/6974 [==============================] - 1s 89us/sample - loss: 0.6838 - binary_accuracy: 0.5751 - val_loss: 0.6811 - val_binary_accuracy: 0.5975\n",
            "Epoch 29/1000\n",
            "6974/6974 [==============================] - 1s 85us/sample - loss: 0.6835 - binary_accuracy: 0.5748 - val_loss: 0.6808 - val_binary_accuracy: 0.5981\n",
            "Epoch 30/1000\n",
            "6974/6974 [==============================] - 1s 80us/sample - loss: 0.6833 - binary_accuracy: 0.5759 - val_loss: 0.6804 - val_binary_accuracy: 0.5952\n",
            "Epoch 31/1000\n",
            "6974/6974 [==============================] - 1s 85us/sample - loss: 0.6830 - binary_accuracy: 0.5769 - val_loss: 0.6801 - val_binary_accuracy: 0.5969\n",
            "Epoch 32/1000\n",
            "6974/6974 [==============================] - 1s 80us/sample - loss: 0.6827 - binary_accuracy: 0.5773 - val_loss: 0.6798 - val_binary_accuracy: 0.5969\n",
            "Epoch 33/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6824 - binary_accuracy: 0.5781 - val_loss: 0.6795 - val_binary_accuracy: 0.5963\n",
            "Epoch 34/1000\n",
            "6974/6974 [==============================] - 1s 86us/sample - loss: 0.6822 - binary_accuracy: 0.5777 - val_loss: 0.6792 - val_binary_accuracy: 0.5969\n",
            "Epoch 35/1000\n",
            "6974/6974 [==============================] - 1s 88us/sample - loss: 0.6819 - binary_accuracy: 0.5793 - val_loss: 0.6789 - val_binary_accuracy: 0.5952\n",
            "Epoch 36/1000\n",
            "6974/6974 [==============================] - 1s 86us/sample - loss: 0.6817 - binary_accuracy: 0.5792 - val_loss: 0.6786 - val_binary_accuracy: 0.5981\n",
            "Epoch 37/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6814 - binary_accuracy: 0.5802 - val_loss: 0.6783 - val_binary_accuracy: 0.5981\n",
            "Epoch 38/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6812 - binary_accuracy: 0.5804 - val_loss: 0.6780 - val_binary_accuracy: 0.5958\n",
            "Epoch 39/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6809 - binary_accuracy: 0.5810 - val_loss: 0.6777 - val_binary_accuracy: 0.5969\n",
            "Epoch 40/1000\n",
            "6974/6974 [==============================] - 1s 83us/sample - loss: 0.6807 - binary_accuracy: 0.5819 - val_loss: 0.6774 - val_binary_accuracy: 0.5986\n",
            "Epoch 41/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6804 - binary_accuracy: 0.5816 - val_loss: 0.6771 - val_binary_accuracy: 0.5986\n",
            "Epoch 42/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6802 - binary_accuracy: 0.5820 - val_loss: 0.6768 - val_binary_accuracy: 0.5998\n",
            "Epoch 43/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6800 - binary_accuracy: 0.5812 - val_loss: 0.6764 - val_binary_accuracy: 0.5975\n",
            "Epoch 44/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6797 - binary_accuracy: 0.5827 - val_loss: 0.6761 - val_binary_accuracy: 0.5986\n",
            "Epoch 45/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6795 - binary_accuracy: 0.5814 - val_loss: 0.6758 - val_binary_accuracy: 0.5992\n",
            "Epoch 46/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6792 - binary_accuracy: 0.5804 - val_loss: 0.6755 - val_binary_accuracy: 0.5998\n",
            "Epoch 47/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6790 - binary_accuracy: 0.5827 - val_loss: 0.6751 - val_binary_accuracy: 0.6009\n",
            "Epoch 48/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6788 - binary_accuracy: 0.5822 - val_loss: 0.6748 - val_binary_accuracy: 0.6021\n",
            "Epoch 49/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6785 - binary_accuracy: 0.5826 - val_loss: 0.6746 - val_binary_accuracy: 0.6015\n",
            "Epoch 50/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6783 - binary_accuracy: 0.5829 - val_loss: 0.6743 - val_binary_accuracy: 0.6003\n",
            "Epoch 51/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6781 - binary_accuracy: 0.5833 - val_loss: 0.6740 - val_binary_accuracy: 0.6003\n",
            "Epoch 52/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6779 - binary_accuracy: 0.5843 - val_loss: 0.6737 - val_binary_accuracy: 0.6003\n",
            "Epoch 53/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6776 - binary_accuracy: 0.5839 - val_loss: 0.6734 - val_binary_accuracy: 0.6009\n",
            "Epoch 54/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6774 - binary_accuracy: 0.5842 - val_loss: 0.6731 - val_binary_accuracy: 0.6009\n",
            "Epoch 55/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6772 - binary_accuracy: 0.5853 - val_loss: 0.6728 - val_binary_accuracy: 0.6026\n",
            "Epoch 56/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6769 - binary_accuracy: 0.5845 - val_loss: 0.6726 - val_binary_accuracy: 0.6009\n",
            "Epoch 57/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6767 - binary_accuracy: 0.5860 - val_loss: 0.6723 - val_binary_accuracy: 0.6021\n",
            "Epoch 58/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6765 - binary_accuracy: 0.5866 - val_loss: 0.6721 - val_binary_accuracy: 0.6003\n",
            "Epoch 59/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6763 - binary_accuracy: 0.5857 - val_loss: 0.6719 - val_binary_accuracy: 0.6015\n",
            "Epoch 60/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6761 - binary_accuracy: 0.5859 - val_loss: 0.6717 - val_binary_accuracy: 0.6021\n",
            "Epoch 61/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6760 - binary_accuracy: 0.5865 - val_loss: 0.6715 - val_binary_accuracy: 0.6009\n",
            "Epoch 62/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6757 - binary_accuracy: 0.5872 - val_loss: 0.6713 - val_binary_accuracy: 0.6003\n",
            "Epoch 63/1000\n",
            "6974/6974 [==============================] - 1s 82us/sample - loss: 0.6756 - binary_accuracy: 0.5880 - val_loss: 0.6711 - val_binary_accuracy: 0.5992\n",
            "Epoch 64/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6754 - binary_accuracy: 0.5883 - val_loss: 0.6710 - val_binary_accuracy: 0.5998\n",
            "Epoch 65/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6752 - binary_accuracy: 0.5876 - val_loss: 0.6708 - val_binary_accuracy: 0.6015\n",
            "Epoch 66/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6751 - binary_accuracy: 0.5885 - val_loss: 0.6706 - val_binary_accuracy: 0.6015\n",
            "Epoch 67/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6749 - binary_accuracy: 0.5886 - val_loss: 0.6704 - val_binary_accuracy: 0.6015\n",
            "Epoch 68/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6747 - binary_accuracy: 0.5883 - val_loss: 0.6703 - val_binary_accuracy: 0.6021\n",
            "Epoch 69/1000\n",
            "6974/6974 [==============================] - 1s 80us/sample - loss: 0.6746 - binary_accuracy: 0.5882 - val_loss: 0.6701 - val_binary_accuracy: 0.6015\n",
            "Epoch 70/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6744 - binary_accuracy: 0.5893 - val_loss: 0.6699 - val_binary_accuracy: 0.6026\n",
            "Epoch 71/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6743 - binary_accuracy: 0.5895 - val_loss: 0.6698 - val_binary_accuracy: 0.6021\n",
            "Epoch 72/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6741 - binary_accuracy: 0.5892 - val_loss: 0.6696 - val_binary_accuracy: 0.6026\n",
            "Epoch 73/1000\n",
            "6974/6974 [==============================] - 1s 84us/sample - loss: 0.6740 - binary_accuracy: 0.5893 - val_loss: 0.6695 - val_binary_accuracy: 0.6021\n",
            "Epoch 74/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6739 - binary_accuracy: 0.5900 - val_loss: 0.6694 - val_binary_accuracy: 0.6021\n",
            "Epoch 75/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6737 - binary_accuracy: 0.5898 - val_loss: 0.6692 - val_binary_accuracy: 0.6021\n",
            "Epoch 76/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6736 - binary_accuracy: 0.5892 - val_loss: 0.6691 - val_binary_accuracy: 0.6032\n",
            "Epoch 77/1000\n",
            "6974/6974 [==============================] - 1s 81us/sample - loss: 0.6735 - binary_accuracy: 0.5900 - val_loss: 0.6690 - val_binary_accuracy: 0.6032\n",
            "Epoch 78/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6733 - binary_accuracy: 0.5900 - val_loss: 0.6689 - val_binary_accuracy: 0.6044\n",
            "Epoch 79/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6732 - binary_accuracy: 0.5896 - val_loss: 0.6687 - val_binary_accuracy: 0.6038\n",
            "Epoch 80/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6731 - binary_accuracy: 0.5906 - val_loss: 0.6686 - val_binary_accuracy: 0.6044\n",
            "Epoch 81/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6730 - binary_accuracy: 0.5895 - val_loss: 0.6685 - val_binary_accuracy: 0.6055\n",
            "Epoch 82/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6729 - binary_accuracy: 0.5895 - val_loss: 0.6684 - val_binary_accuracy: 0.6055\n",
            "Epoch 83/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6728 - binary_accuracy: 0.5902 - val_loss: 0.6683 - val_binary_accuracy: 0.6067\n",
            "Epoch 84/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6726 - binary_accuracy: 0.5895 - val_loss: 0.6682 - val_binary_accuracy: 0.6084\n",
            "Epoch 85/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6725 - binary_accuracy: 0.5896 - val_loss: 0.6681 - val_binary_accuracy: 0.6089\n",
            "Epoch 86/1000\n",
            "6974/6974 [==============================] - 1s 81us/sample - loss: 0.6724 - binary_accuracy: 0.5902 - val_loss: 0.6680 - val_binary_accuracy: 0.6084\n",
            "Epoch 87/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6723 - binary_accuracy: 0.5905 - val_loss: 0.6679 - val_binary_accuracy: 0.6101\n",
            "Epoch 88/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6722 - binary_accuracy: 0.5911 - val_loss: 0.6678 - val_binary_accuracy: 0.6095\n",
            "Epoch 89/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6722 - binary_accuracy: 0.5912 - val_loss: 0.6677 - val_binary_accuracy: 0.6095\n",
            "Epoch 90/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6721 - binary_accuracy: 0.5915 - val_loss: 0.6676 - val_binary_accuracy: 0.6095\n",
            "Epoch 91/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6720 - binary_accuracy: 0.5919 - val_loss: 0.6675 - val_binary_accuracy: 0.6107\n",
            "Epoch 92/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6719 - binary_accuracy: 0.5909 - val_loss: 0.6674 - val_binary_accuracy: 0.6084\n",
            "Epoch 93/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6718 - binary_accuracy: 0.5911 - val_loss: 0.6674 - val_binary_accuracy: 0.6095\n",
            "Epoch 94/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6717 - binary_accuracy: 0.5921 - val_loss: 0.6673 - val_binary_accuracy: 0.6095\n",
            "Epoch 95/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6716 - binary_accuracy: 0.5921 - val_loss: 0.6672 - val_binary_accuracy: 0.6089\n",
            "Epoch 96/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6715 - binary_accuracy: 0.5925 - val_loss: 0.6671 - val_binary_accuracy: 0.6084\n",
            "Epoch 97/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6714 - binary_accuracy: 0.5933 - val_loss: 0.6671 - val_binary_accuracy: 0.6107\n",
            "Epoch 98/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6713 - binary_accuracy: 0.5926 - val_loss: 0.6670 - val_binary_accuracy: 0.6095\n",
            "Epoch 99/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6713 - binary_accuracy: 0.5932 - val_loss: 0.6669 - val_binary_accuracy: 0.6095\n",
            "Epoch 100/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6712 - binary_accuracy: 0.5929 - val_loss: 0.6668 - val_binary_accuracy: 0.6101\n",
            "Epoch 101/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6711 - binary_accuracy: 0.5928 - val_loss: 0.6668 - val_binary_accuracy: 0.6101\n",
            "Epoch 102/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6710 - binary_accuracy: 0.5932 - val_loss: 0.6667 - val_binary_accuracy: 0.6101\n",
            "Epoch 103/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6709 - binary_accuracy: 0.5932 - val_loss: 0.6666 - val_binary_accuracy: 0.6107\n",
            "Epoch 104/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6709 - binary_accuracy: 0.5931 - val_loss: 0.6666 - val_binary_accuracy: 0.6107\n",
            "Epoch 105/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6708 - binary_accuracy: 0.5935 - val_loss: 0.6665 - val_binary_accuracy: 0.6095\n",
            "Epoch 106/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6707 - binary_accuracy: 0.5928 - val_loss: 0.6665 - val_binary_accuracy: 0.6095\n",
            "Epoch 107/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6706 - binary_accuracy: 0.5938 - val_loss: 0.6664 - val_binary_accuracy: 0.6095\n",
            "Epoch 108/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6706 - binary_accuracy: 0.5939 - val_loss: 0.6664 - val_binary_accuracy: 0.6112\n",
            "Epoch 109/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6705 - binary_accuracy: 0.5936 - val_loss: 0.6663 - val_binary_accuracy: 0.6095\n",
            "Epoch 110/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6704 - binary_accuracy: 0.5941 - val_loss: 0.6663 - val_binary_accuracy: 0.6084\n",
            "Epoch 111/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6704 - binary_accuracy: 0.5955 - val_loss: 0.6662 - val_binary_accuracy: 0.6089\n",
            "Epoch 112/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6703 - binary_accuracy: 0.5946 - val_loss: 0.6662 - val_binary_accuracy: 0.6095\n",
            "Epoch 113/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6702 - binary_accuracy: 0.5952 - val_loss: 0.6661 - val_binary_accuracy: 0.6095\n",
            "Epoch 114/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6702 - binary_accuracy: 0.5941 - val_loss: 0.6661 - val_binary_accuracy: 0.6089\n",
            "Epoch 115/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6701 - binary_accuracy: 0.5942 - val_loss: 0.6660 - val_binary_accuracy: 0.6101\n",
            "Epoch 116/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6700 - binary_accuracy: 0.5949 - val_loss: 0.6660 - val_binary_accuracy: 0.6095\n",
            "Epoch 117/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6700 - binary_accuracy: 0.5952 - val_loss: 0.6660 - val_binary_accuracy: 0.6095\n",
            "Epoch 118/1000\n",
            "6974/6974 [==============================] - 1s 82us/sample - loss: 0.6699 - binary_accuracy: 0.5949 - val_loss: 0.6659 - val_binary_accuracy: 0.6107\n",
            "Epoch 119/1000\n",
            "6974/6974 [==============================] - 1s 84us/sample - loss: 0.6698 - binary_accuracy: 0.5952 - val_loss: 0.6659 - val_binary_accuracy: 0.6101\n",
            "Epoch 120/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6698 - binary_accuracy: 0.5945 - val_loss: 0.6658 - val_binary_accuracy: 0.6107\n",
            "Epoch 121/1000\n",
            "6974/6974 [==============================] - 0s 66us/sample - loss: 0.6697 - binary_accuracy: 0.5949 - val_loss: 0.6658 - val_binary_accuracy: 0.6101\n",
            "Epoch 122/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6696 - binary_accuracy: 0.5961 - val_loss: 0.6658 - val_binary_accuracy: 0.6084\n",
            "Epoch 123/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6696 - binary_accuracy: 0.5949 - val_loss: 0.6657 - val_binary_accuracy: 0.6101\n",
            "Epoch 124/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6695 - binary_accuracy: 0.5949 - val_loss: 0.6657 - val_binary_accuracy: 0.6095\n",
            "Epoch 125/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6695 - binary_accuracy: 0.5952 - val_loss: 0.6657 - val_binary_accuracy: 0.6095\n",
            "Epoch 126/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6694 - binary_accuracy: 0.5956 - val_loss: 0.6656 - val_binary_accuracy: 0.6095\n",
            "Epoch 127/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6694 - binary_accuracy: 0.5956 - val_loss: 0.6656 - val_binary_accuracy: 0.6089\n",
            "Epoch 128/1000\n",
            "6974/6974 [==============================] - 1s 84us/sample - loss: 0.6693 - binary_accuracy: 0.5945 - val_loss: 0.6656 - val_binary_accuracy: 0.6089\n",
            "Epoch 129/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6693 - binary_accuracy: 0.5944 - val_loss: 0.6655 - val_binary_accuracy: 0.6095\n",
            "Epoch 130/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6692 - binary_accuracy: 0.5955 - val_loss: 0.6655 - val_binary_accuracy: 0.6095\n",
            "Epoch 131/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6691 - binary_accuracy: 0.5948 - val_loss: 0.6655 - val_binary_accuracy: 0.6095\n",
            "Epoch 132/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6691 - binary_accuracy: 0.5944 - val_loss: 0.6654 - val_binary_accuracy: 0.6089\n",
            "Epoch 133/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6691 - binary_accuracy: 0.5959 - val_loss: 0.6654 - val_binary_accuracy: 0.6084\n",
            "Epoch 134/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6690 - binary_accuracy: 0.5969 - val_loss: 0.6654 - val_binary_accuracy: 0.6095\n",
            "Epoch 135/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6690 - binary_accuracy: 0.5959 - val_loss: 0.6654 - val_binary_accuracy: 0.6095\n",
            "Epoch 136/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6689 - binary_accuracy: 0.5964 - val_loss: 0.6653 - val_binary_accuracy: 0.6101\n",
            "Epoch 137/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6689 - binary_accuracy: 0.5959 - val_loss: 0.6653 - val_binary_accuracy: 0.6101\n",
            "Epoch 138/1000\n",
            "6974/6974 [==============================] - 0s 66us/sample - loss: 0.6688 - binary_accuracy: 0.5964 - val_loss: 0.6653 - val_binary_accuracy: 0.6095\n",
            "Epoch 139/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6688 - binary_accuracy: 0.5962 - val_loss: 0.6653 - val_binary_accuracy: 0.6089\n",
            "Epoch 140/1000\n",
            "6974/6974 [==============================] - 0s 66us/sample - loss: 0.6687 - binary_accuracy: 0.5958 - val_loss: 0.6653 - val_binary_accuracy: 0.6089\n",
            "Epoch 141/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6687 - binary_accuracy: 0.5975 - val_loss: 0.6652 - val_binary_accuracy: 0.6101\n",
            "Epoch 142/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6686 - binary_accuracy: 0.5965 - val_loss: 0.6652 - val_binary_accuracy: 0.6089\n",
            "Epoch 143/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6686 - binary_accuracy: 0.5966 - val_loss: 0.6652 - val_binary_accuracy: 0.6095\n",
            "Epoch 144/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6685 - binary_accuracy: 0.5966 - val_loss: 0.6652 - val_binary_accuracy: 0.6084\n",
            "Epoch 145/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6685 - binary_accuracy: 0.5974 - val_loss: 0.6652 - val_binary_accuracy: 0.6095\n",
            "Epoch 146/1000\n",
            "6974/6974 [==============================] - 1s 75us/sample - loss: 0.6684 - binary_accuracy: 0.5971 - val_loss: 0.6652 - val_binary_accuracy: 0.6084\n",
            "Epoch 147/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6684 - binary_accuracy: 0.5951 - val_loss: 0.6652 - val_binary_accuracy: 0.6089\n",
            "Epoch 148/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6683 - binary_accuracy: 0.5966 - val_loss: 0.6651 - val_binary_accuracy: 0.6089\n",
            "Epoch 149/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6683 - binary_accuracy: 0.5979 - val_loss: 0.6651 - val_binary_accuracy: 0.6089\n",
            "Epoch 150/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6682 - binary_accuracy: 0.5966 - val_loss: 0.6651 - val_binary_accuracy: 0.6089\n",
            "Epoch 151/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6682 - binary_accuracy: 0.5966 - val_loss: 0.6651 - val_binary_accuracy: 0.6072\n",
            "Epoch 152/1000\n",
            "6974/6974 [==============================] - 1s 75us/sample - loss: 0.6681 - binary_accuracy: 0.5969 - val_loss: 0.6651 - val_binary_accuracy: 0.6095\n",
            "Epoch 153/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6681 - binary_accuracy: 0.5974 - val_loss: 0.6651 - val_binary_accuracy: 0.6084\n",
            "Epoch 154/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6680 - binary_accuracy: 0.5975 - val_loss: 0.6651 - val_binary_accuracy: 0.6095\n",
            "Epoch 155/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6680 - binary_accuracy: 0.5979 - val_loss: 0.6651 - val_binary_accuracy: 0.6089\n",
            "Epoch 156/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6680 - binary_accuracy: 0.5982 - val_loss: 0.6650 - val_binary_accuracy: 0.6095\n",
            "Epoch 157/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6679 - binary_accuracy: 0.5968 - val_loss: 0.6650 - val_binary_accuracy: 0.6089\n",
            "Epoch 158/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6679 - binary_accuracy: 0.5984 - val_loss: 0.6650 - val_binary_accuracy: 0.6072\n",
            "Epoch 159/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6678 - binary_accuracy: 0.5982 - val_loss: 0.6650 - val_binary_accuracy: 0.6072\n",
            "Epoch 160/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6678 - binary_accuracy: 0.5992 - val_loss: 0.6650 - val_binary_accuracy: 0.6078\n",
            "Epoch 161/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6678 - binary_accuracy: 0.5985 - val_loss: 0.6650 - val_binary_accuracy: 0.6101\n",
            "Epoch 162/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6677 - binary_accuracy: 0.5982 - val_loss: 0.6650 - val_binary_accuracy: 0.6084\n",
            "Epoch 163/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6677 - binary_accuracy: 0.5988 - val_loss: 0.6650 - val_binary_accuracy: 0.6078\n",
            "Epoch 164/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6677 - binary_accuracy: 0.5979 - val_loss: 0.6650 - val_binary_accuracy: 0.6084\n",
            "Epoch 165/1000\n",
            "6974/6974 [==============================] - 1s 76us/sample - loss: 0.6676 - binary_accuracy: 0.5989 - val_loss: 0.6650 - val_binary_accuracy: 0.6089\n",
            "Epoch 166/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6676 - binary_accuracy: 0.5988 - val_loss: 0.6650 - val_binary_accuracy: 0.6084\n",
            "Epoch 167/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6675 - binary_accuracy: 0.5995 - val_loss: 0.6649 - val_binary_accuracy: 0.6078\n",
            "Epoch 168/1000\n",
            "6974/6974 [==============================] - 0s 63us/sample - loss: 0.6675 - binary_accuracy: 0.5984 - val_loss: 0.6649 - val_binary_accuracy: 0.6072\n",
            "Epoch 169/1000\n",
            "6974/6974 [==============================] - 1s 75us/sample - loss: 0.6674 - binary_accuracy: 0.5995 - val_loss: 0.6649 - val_binary_accuracy: 0.6072\n",
            "Epoch 170/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6674 - binary_accuracy: 0.5982 - val_loss: 0.6649 - val_binary_accuracy: 0.6078\n",
            "Epoch 171/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6674 - binary_accuracy: 0.5976 - val_loss: 0.6649 - val_binary_accuracy: 0.6095\n",
            "Epoch 172/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6673 - binary_accuracy: 0.5985 - val_loss: 0.6649 - val_binary_accuracy: 0.6084\n",
            "Epoch 173/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6673 - binary_accuracy: 0.5995 - val_loss: 0.6648 - val_binary_accuracy: 0.6089\n",
            "Epoch 174/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6672 - binary_accuracy: 0.6001 - val_loss: 0.6648 - val_binary_accuracy: 0.6084\n",
            "Epoch 175/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6672 - binary_accuracy: 0.5987 - val_loss: 0.6648 - val_binary_accuracy: 0.6089\n",
            "Epoch 176/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6672 - binary_accuracy: 0.6001 - val_loss: 0.6648 - val_binary_accuracy: 0.6089\n",
            "Epoch 177/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6671 - binary_accuracy: 0.6005 - val_loss: 0.6648 - val_binary_accuracy: 0.6095\n",
            "Epoch 178/1000\n",
            "6974/6974 [==============================] - 1s 84us/sample - loss: 0.6671 - binary_accuracy: 0.5989 - val_loss: 0.6648 - val_binary_accuracy: 0.6101\n",
            "Epoch 179/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6671 - binary_accuracy: 0.5994 - val_loss: 0.6648 - val_binary_accuracy: 0.6095\n",
            "Epoch 180/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6671 - binary_accuracy: 0.5994 - val_loss: 0.6647 - val_binary_accuracy: 0.6101\n",
            "Epoch 181/1000\n",
            "6974/6974 [==============================] - 0s 72us/sample - loss: 0.6670 - binary_accuracy: 0.5991 - val_loss: 0.6647 - val_binary_accuracy: 0.6084\n",
            "Epoch 182/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6670 - binary_accuracy: 0.5997 - val_loss: 0.6647 - val_binary_accuracy: 0.6084\n",
            "Epoch 183/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6669 - binary_accuracy: 0.6001 - val_loss: 0.6647 - val_binary_accuracy: 0.6101\n",
            "Epoch 184/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6669 - binary_accuracy: 0.5999 - val_loss: 0.6647 - val_binary_accuracy: 0.6084\n",
            "Epoch 185/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6669 - binary_accuracy: 0.5984 - val_loss: 0.6646 - val_binary_accuracy: 0.6095\n",
            "Epoch 186/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6668 - binary_accuracy: 0.6002 - val_loss: 0.6646 - val_binary_accuracy: 0.6095\n",
            "Epoch 187/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6668 - binary_accuracy: 0.5991 - val_loss: 0.6646 - val_binary_accuracy: 0.6095\n",
            "Epoch 188/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6668 - binary_accuracy: 0.5988 - val_loss: 0.6646 - val_binary_accuracy: 0.6089\n",
            "Epoch 189/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6667 - binary_accuracy: 0.6004 - val_loss: 0.6646 - val_binary_accuracy: 0.6095\n",
            "Epoch 190/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6667 - binary_accuracy: 0.6002 - val_loss: 0.6646 - val_binary_accuracy: 0.6084\n",
            "Epoch 191/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6667 - binary_accuracy: 0.6008 - val_loss: 0.6645 - val_binary_accuracy: 0.6101\n",
            "Epoch 192/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6666 - binary_accuracy: 0.6001 - val_loss: 0.6645 - val_binary_accuracy: 0.6089\n",
            "Epoch 193/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6666 - binary_accuracy: 0.5995 - val_loss: 0.6645 - val_binary_accuracy: 0.6089\n",
            "Epoch 194/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6666 - binary_accuracy: 0.6004 - val_loss: 0.6645 - val_binary_accuracy: 0.6089\n",
            "Epoch 195/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6666 - binary_accuracy: 0.5992 - val_loss: 0.6645 - val_binary_accuracy: 0.6089\n",
            "Epoch 196/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6665 - binary_accuracy: 0.6001 - val_loss: 0.6645 - val_binary_accuracy: 0.6084\n",
            "Epoch 197/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6665 - binary_accuracy: 0.5999 - val_loss: 0.6645 - val_binary_accuracy: 0.6089\n",
            "Epoch 198/1000\n",
            "6974/6974 [==============================] - 1s 86us/sample - loss: 0.6665 - binary_accuracy: 0.6001 - val_loss: 0.6644 - val_binary_accuracy: 0.6072\n",
            "Epoch 199/1000\n",
            "6974/6974 [==============================] - 1s 82us/sample - loss: 0.6664 - binary_accuracy: 0.6001 - val_loss: 0.6644 - val_binary_accuracy: 0.6072\n",
            "Epoch 200/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6664 - binary_accuracy: 0.5995 - val_loss: 0.6644 - val_binary_accuracy: 0.6089\n",
            "Epoch 201/1000\n",
            "6974/6974 [==============================] - 0s 65us/sample - loss: 0.6664 - binary_accuracy: 0.5992 - val_loss: 0.6644 - val_binary_accuracy: 0.6095\n",
            "Epoch 202/1000\n",
            "6974/6974 [==============================] - 1s 80us/sample - loss: 0.6664 - binary_accuracy: 0.6002 - val_loss: 0.6644 - val_binary_accuracy: 0.6095\n",
            "Epoch 203/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6663 - binary_accuracy: 0.6001 - val_loss: 0.6644 - val_binary_accuracy: 0.6095\n",
            "Epoch 204/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6663 - binary_accuracy: 0.6002 - val_loss: 0.6644 - val_binary_accuracy: 0.6095\n",
            "Epoch 205/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6662 - binary_accuracy: 0.5992 - val_loss: 0.6644 - val_binary_accuracy: 0.6095\n",
            "Epoch 206/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6662 - binary_accuracy: 0.6004 - val_loss: 0.6644 - val_binary_accuracy: 0.6101\n",
            "Epoch 207/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6662 - binary_accuracy: 0.6011 - val_loss: 0.6643 - val_binary_accuracy: 0.6072\n",
            "Epoch 208/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6662 - binary_accuracy: 0.6001 - val_loss: 0.6643 - val_binary_accuracy: 0.6072\n",
            "Epoch 209/1000\n",
            "6974/6974 [==============================] - 0s 66us/sample - loss: 0.6661 - binary_accuracy: 0.6001 - val_loss: 0.6643 - val_binary_accuracy: 0.6089\n",
            "Epoch 210/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6661 - binary_accuracy: 0.6002 - val_loss: 0.6643 - val_binary_accuracy: 0.6112\n",
            "Epoch 211/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6661 - binary_accuracy: 0.5997 - val_loss: 0.6643 - val_binary_accuracy: 0.6112\n",
            "Epoch 212/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6661 - binary_accuracy: 0.5999 - val_loss: 0.6643 - val_binary_accuracy: 0.6101\n",
            "Epoch 213/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6660 - binary_accuracy: 0.5998 - val_loss: 0.6643 - val_binary_accuracy: 0.6101\n",
            "Epoch 214/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6660 - binary_accuracy: 0.6007 - val_loss: 0.6642 - val_binary_accuracy: 0.6084\n",
            "Epoch 215/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6660 - binary_accuracy: 0.5995 - val_loss: 0.6642 - val_binary_accuracy: 0.6067\n",
            "Epoch 216/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6659 - binary_accuracy: 0.6009 - val_loss: 0.6642 - val_binary_accuracy: 0.6084\n",
            "Epoch 217/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6659 - binary_accuracy: 0.5999 - val_loss: 0.6642 - val_binary_accuracy: 0.6095\n",
            "Epoch 218/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6659 - binary_accuracy: 0.5998 - val_loss: 0.6642 - val_binary_accuracy: 0.6095\n",
            "Epoch 219/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6659 - binary_accuracy: 0.5999 - val_loss: 0.6642 - val_binary_accuracy: 0.6095\n",
            "Epoch 220/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6659 - binary_accuracy: 0.6001 - val_loss: 0.6642 - val_binary_accuracy: 0.6095\n",
            "Epoch 221/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6658 - binary_accuracy: 0.5999 - val_loss: 0.6642 - val_binary_accuracy: 0.6095\n",
            "Epoch 222/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6658 - binary_accuracy: 0.6007 - val_loss: 0.6642 - val_binary_accuracy: 0.6101\n",
            "Epoch 223/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6658 - binary_accuracy: 0.5991 - val_loss: 0.6642 - val_binary_accuracy: 0.6101\n",
            "Epoch 224/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6658 - binary_accuracy: 0.6002 - val_loss: 0.6641 - val_binary_accuracy: 0.6095\n",
            "Epoch 225/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6657 - binary_accuracy: 0.6002 - val_loss: 0.6641 - val_binary_accuracy: 0.6095\n",
            "Epoch 226/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6657 - binary_accuracy: 0.5991 - val_loss: 0.6641 - val_binary_accuracy: 0.6101\n",
            "Epoch 227/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6657 - binary_accuracy: 0.6001 - val_loss: 0.6641 - val_binary_accuracy: 0.6101\n",
            "Epoch 228/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6656 - binary_accuracy: 0.6008 - val_loss: 0.6641 - val_binary_accuracy: 0.6107\n",
            "Epoch 229/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6656 - binary_accuracy: 0.6007 - val_loss: 0.6641 - val_binary_accuracy: 0.6107\n",
            "Epoch 230/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6656 - binary_accuracy: 0.6011 - val_loss: 0.6641 - val_binary_accuracy: 0.6089\n",
            "Epoch 231/1000\n",
            "6974/6974 [==============================] - 1s 80us/sample - loss: 0.6656 - binary_accuracy: 0.6004 - val_loss: 0.6641 - val_binary_accuracy: 0.6112\n",
            "Epoch 232/1000\n",
            "6974/6974 [==============================] - 1s 81us/sample - loss: 0.6656 - binary_accuracy: 0.6002 - val_loss: 0.6640 - val_binary_accuracy: 0.6101\n",
            "Epoch 233/1000\n",
            "6974/6974 [==============================] - 1s 105us/sample - loss: 0.6655 - binary_accuracy: 0.5999 - val_loss: 0.6640 - val_binary_accuracy: 0.6101\n",
            "Epoch 234/1000\n",
            "6974/6974 [==============================] - 1s 105us/sample - loss: 0.6655 - binary_accuracy: 0.6011 - val_loss: 0.6640 - val_binary_accuracy: 0.6084\n",
            "Epoch 235/1000\n",
            "6974/6974 [==============================] - 1s 87us/sample - loss: 0.6655 - binary_accuracy: 0.5999 - val_loss: 0.6640 - val_binary_accuracy: 0.6089\n",
            "Epoch 236/1000\n",
            "6974/6974 [==============================] - 1s 84us/sample - loss: 0.6655 - binary_accuracy: 0.6005 - val_loss: 0.6640 - val_binary_accuracy: 0.6095\n",
            "Epoch 237/1000\n",
            "6974/6974 [==============================] - 1s 86us/sample - loss: 0.6655 - binary_accuracy: 0.5998 - val_loss: 0.6640 - val_binary_accuracy: 0.6095\n",
            "Epoch 238/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6654 - binary_accuracy: 0.6009 - val_loss: 0.6640 - val_binary_accuracy: 0.6078\n",
            "Epoch 239/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6654 - binary_accuracy: 0.6008 - val_loss: 0.6640 - val_binary_accuracy: 0.6089\n",
            "Epoch 240/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6654 - binary_accuracy: 0.6001 - val_loss: 0.6640 - val_binary_accuracy: 0.6078\n",
            "Epoch 241/1000\n",
            "6974/6974 [==============================] - 1s 80us/sample - loss: 0.6654 - binary_accuracy: 0.6009 - val_loss: 0.6640 - val_binary_accuracy: 0.6084\n",
            "Epoch 242/1000\n",
            "6974/6974 [==============================] - 1s 116us/sample - loss: 0.6653 - binary_accuracy: 0.6008 - val_loss: 0.6640 - val_binary_accuracy: 0.6078\n",
            "Epoch 243/1000\n",
            "6974/6974 [==============================] - 1s 112us/sample - loss: 0.6653 - binary_accuracy: 0.6017 - val_loss: 0.6640 - val_binary_accuracy: 0.6084\n",
            "Epoch 244/1000\n",
            "6974/6974 [==============================] - 1s 103us/sample - loss: 0.6653 - binary_accuracy: 0.6004 - val_loss: 0.6640 - val_binary_accuracy: 0.6084\n",
            "Epoch 245/1000\n",
            "6974/6974 [==============================] - 1s 106us/sample - loss: 0.6653 - binary_accuracy: 0.6008 - val_loss: 0.6640 - val_binary_accuracy: 0.6078\n",
            "Epoch 246/1000\n",
            "6974/6974 [==============================] - 1s 104us/sample - loss: 0.6652 - binary_accuracy: 0.6005 - val_loss: 0.6639 - val_binary_accuracy: 0.6072\n",
            "Epoch 247/1000\n",
            "6974/6974 [==============================] - 1s 97us/sample - loss: 0.6652 - binary_accuracy: 0.6017 - val_loss: 0.6639 - val_binary_accuracy: 0.6072\n",
            "Epoch 248/1000\n",
            "6974/6974 [==============================] - 1s 101us/sample - loss: 0.6652 - binary_accuracy: 0.6018 - val_loss: 0.6639 - val_binary_accuracy: 0.6061\n",
            "Epoch 249/1000\n",
            "6974/6974 [==============================] - 1s 86us/sample - loss: 0.6652 - binary_accuracy: 0.5999 - val_loss: 0.6639 - val_binary_accuracy: 0.6072\n",
            "Epoch 250/1000\n",
            "6974/6974 [==============================] - 1s 87us/sample - loss: 0.6652 - binary_accuracy: 0.6018 - val_loss: 0.6639 - val_binary_accuracy: 0.6084\n",
            "Epoch 251/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6651 - binary_accuracy: 0.6011 - val_loss: 0.6639 - val_binary_accuracy: 0.6084\n",
            "Epoch 252/1000\n",
            "6974/6974 [==============================] - 1s 75us/sample - loss: 0.6651 - binary_accuracy: 0.6015 - val_loss: 0.6639 - val_binary_accuracy: 0.6078\n",
            "Epoch 253/1000\n",
            "6974/6974 [==============================] - 1s 82us/sample - loss: 0.6651 - binary_accuracy: 0.6012 - val_loss: 0.6639 - val_binary_accuracy: 0.6072\n",
            "Epoch 254/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6651 - binary_accuracy: 0.6015 - val_loss: 0.6639 - val_binary_accuracy: 0.6084\n",
            "Epoch 255/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6650 - binary_accuracy: 0.6020 - val_loss: 0.6639 - val_binary_accuracy: 0.6084\n",
            "Epoch 256/1000\n",
            "6974/6974 [==============================] - 0s 66us/sample - loss: 0.6650 - binary_accuracy: 0.6025 - val_loss: 0.6639 - val_binary_accuracy: 0.6084\n",
            "Epoch 257/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6650 - binary_accuracy: 0.6012 - val_loss: 0.6639 - val_binary_accuracy: 0.6089\n",
            "Epoch 258/1000\n",
            "6974/6974 [==============================] - 0s 69us/sample - loss: 0.6650 - binary_accuracy: 0.6021 - val_loss: 0.6639 - val_binary_accuracy: 0.6089\n",
            "Epoch 259/1000\n",
            "6974/6974 [==============================] - 0s 66us/sample - loss: 0.6650 - binary_accuracy: 0.6015 - val_loss: 0.6639 - val_binary_accuracy: 0.6084\n",
            "Epoch 260/1000\n",
            "6974/6974 [==============================] - 0s 67us/sample - loss: 0.6649 - binary_accuracy: 0.6020 - val_loss: 0.6639 - val_binary_accuracy: 0.6101\n",
            "Epoch 261/1000\n",
            "6974/6974 [==============================] - 0s 64us/sample - loss: 0.6649 - binary_accuracy: 0.6015 - val_loss: 0.6639 - val_binary_accuracy: 0.6084\n",
            "Epoch 262/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6649 - binary_accuracy: 0.6014 - val_loss: 0.6639 - val_binary_accuracy: 0.6072\n",
            "Epoch 263/1000\n",
            "6974/6974 [==============================] - 0s 71us/sample - loss: 0.6649 - binary_accuracy: 0.6020 - val_loss: 0.6639 - val_binary_accuracy: 0.6084\n",
            "Epoch 264/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6649 - binary_accuracy: 0.6015 - val_loss: 0.6639 - val_binary_accuracy: 0.6078\n",
            "Epoch 265/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6649 - binary_accuracy: 0.6017 - val_loss: 0.6639 - val_binary_accuracy: 0.6084\n",
            "Epoch 266/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6648 - binary_accuracy: 0.6017 - val_loss: 0.6639 - val_binary_accuracy: 0.6078\n",
            "Epoch 267/1000\n",
            "6974/6974 [==============================] - 1s 77us/sample - loss: 0.6648 - binary_accuracy: 0.6021 - val_loss: 0.6638 - val_binary_accuracy: 0.6072\n",
            "Epoch 268/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6648 - binary_accuracy: 0.6025 - val_loss: 0.6639 - val_binary_accuracy: 0.6101\n",
            "Epoch 269/1000\n",
            "6974/6974 [==============================] - 1s 90us/sample - loss: 0.6648 - binary_accuracy: 0.6028 - val_loss: 0.6638 - val_binary_accuracy: 0.6101\n",
            "Epoch 270/1000\n",
            "6974/6974 [==============================] - 1s 87us/sample - loss: 0.6647 - binary_accuracy: 0.6020 - val_loss: 0.6639 - val_binary_accuracy: 0.6101\n",
            "Epoch 271/1000\n",
            "6974/6974 [==============================] - 1s 82us/sample - loss: 0.6647 - binary_accuracy: 0.6025 - val_loss: 0.6639 - val_binary_accuracy: 0.6101\n",
            "Epoch 272/1000\n",
            "6974/6974 [==============================] - 1s 87us/sample - loss: 0.6647 - binary_accuracy: 0.6025 - val_loss: 0.6638 - val_binary_accuracy: 0.6084\n",
            "Epoch 273/1000\n",
            "6974/6974 [==============================] - 1s 90us/sample - loss: 0.6647 - binary_accuracy: 0.6022 - val_loss: 0.6638 - val_binary_accuracy: 0.6078\n",
            "Epoch 274/1000\n",
            "6974/6974 [==============================] - 1s 94us/sample - loss: 0.6647 - binary_accuracy: 0.6034 - val_loss: 0.6638 - val_binary_accuracy: 0.6089\n",
            "Epoch 275/1000\n",
            "6974/6974 [==============================] - 1s 99us/sample - loss: 0.6647 - binary_accuracy: 0.6025 - val_loss: 0.6638 - val_binary_accuracy: 0.6084\n",
            "Epoch 276/1000\n",
            "6974/6974 [==============================] - 1s 108us/sample - loss: 0.6646 - binary_accuracy: 0.6022 - val_loss: 0.6638 - val_binary_accuracy: 0.6089\n",
            "Epoch 277/1000\n",
            "6974/6974 [==============================] - 1s 103us/sample - loss: 0.6646 - binary_accuracy: 0.6027 - val_loss: 0.6638 - val_binary_accuracy: 0.6089\n",
            "Epoch 278/1000\n",
            "6974/6974 [==============================] - 1s 113us/sample - loss: 0.6646 - binary_accuracy: 0.6027 - val_loss: 0.6638 - val_binary_accuracy: 0.6095\n",
            "Epoch 279/1000\n",
            "6974/6974 [==============================] - 1s 96us/sample - loss: 0.6646 - binary_accuracy: 0.6025 - val_loss: 0.6638 - val_binary_accuracy: 0.6095\n",
            "Epoch 280/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6646 - binary_accuracy: 0.6038 - val_loss: 0.6638 - val_binary_accuracy: 0.6078\n",
            "Epoch 281/1000\n",
            "6974/6974 [==============================] - 1s 78us/sample - loss: 0.6645 - binary_accuracy: 0.6022 - val_loss: 0.6638 - val_binary_accuracy: 0.6095\n",
            "Epoch 282/1000\n",
            "6974/6974 [==============================] - 0s 68us/sample - loss: 0.6645 - binary_accuracy: 0.6027 - val_loss: 0.6638 - val_binary_accuracy: 0.6084\n",
            "Epoch 283/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6645 - binary_accuracy: 0.6025 - val_loss: 0.6638 - val_binary_accuracy: 0.6095\n",
            "Epoch 284/1000\n",
            "6974/6974 [==============================] - 1s 79us/sample - loss: 0.6645 - binary_accuracy: 0.6018 - val_loss: 0.6638 - val_binary_accuracy: 0.6095\n",
            "Epoch 285/1000\n",
            "6974/6974 [==============================] - 1s 74us/sample - loss: 0.6645 - binary_accuracy: 0.6017 - val_loss: 0.6638 - val_binary_accuracy: 0.6095\n",
            "Epoch 286/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6645 - binary_accuracy: 0.6014 - val_loss: 0.6638 - val_binary_accuracy: 0.6095\n",
            "Epoch 287/1000\n",
            "6974/6974 [==============================] - 1s 75us/sample - loss: 0.6644 - binary_accuracy: 0.6021 - val_loss: 0.6638 - val_binary_accuracy: 0.6101\n",
            "Epoch 288/1000\n",
            "6974/6974 [==============================] - 0s 70us/sample - loss: 0.6644 - binary_accuracy: 0.6012 - val_loss: 0.6638 - val_binary_accuracy: 0.6101\n",
            "Epoch 289/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6644 - binary_accuracy: 0.6027 - val_loss: 0.6638 - val_binary_accuracy: 0.6101\n",
            "Epoch 290/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6644 - binary_accuracy: 0.6025 - val_loss: 0.6638 - val_binary_accuracy: 0.6101\n",
            "Epoch 291/1000\n",
            "6974/6974 [==============================] - 1s 72us/sample - loss: 0.6644 - binary_accuracy: 0.6025 - val_loss: 0.6638 - val_binary_accuracy: 0.6101\n",
            "Epoch 292/1000\n",
            "6974/6974 [==============================] - 1s 73us/sample - loss: 0.6644 - binary_accuracy: 0.6025 - val_loss: 0.6638 - val_binary_accuracy: 0.6107\n",
            "(6975, 20)\n",
            "(1743, 20)\n",
            "Train on 6975 samples, validate on 1743 samples\n",
            "Epoch 1/1000\n",
            "6975/6975 [==============================] - 1s 98us/sample - loss: 0.6939 - binary_accuracy: 0.5009 - val_loss: 0.6937 - val_binary_accuracy: 0.5009\n",
            "Epoch 2/1000\n",
            "6975/6975 [==============================] - 1s 87us/sample - loss: 0.6936 - binary_accuracy: 0.5011 - val_loss: 0.6935 - val_binary_accuracy: 0.5009\n",
            "Epoch 3/1000\n",
            "6975/6975 [==============================] - 1s 83us/sample - loss: 0.6934 - binary_accuracy: 0.5011 - val_loss: 0.6933 - val_binary_accuracy: 0.5020\n",
            "Epoch 4/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6932 - binary_accuracy: 0.5006 - val_loss: 0.6931 - val_binary_accuracy: 0.5003\n",
            "Epoch 5/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6930 - binary_accuracy: 0.5014 - val_loss: 0.6930 - val_binary_accuracy: 0.5003\n",
            "Epoch 6/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6929 - binary_accuracy: 0.5024 - val_loss: 0.6928 - val_binary_accuracy: 0.5009\n",
            "Epoch 7/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6927 - binary_accuracy: 0.5031 - val_loss: 0.6927 - val_binary_accuracy: 0.5009\n",
            "Epoch 8/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6926 - binary_accuracy: 0.5047 - val_loss: 0.6926 - val_binary_accuracy: 0.5020\n",
            "Epoch 9/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6925 - binary_accuracy: 0.5058 - val_loss: 0.6925 - val_binary_accuracy: 0.5020\n",
            "Epoch 10/1000\n",
            "6975/6975 [==============================] - 1s 84us/sample - loss: 0.6924 - binary_accuracy: 0.5080 - val_loss: 0.6925 - val_binary_accuracy: 0.5026\n",
            "Epoch 11/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6923 - binary_accuracy: 0.5095 - val_loss: 0.6924 - val_binary_accuracy: 0.5055\n",
            "Epoch 12/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6922 - binary_accuracy: 0.5135 - val_loss: 0.6923 - val_binary_accuracy: 0.5072\n",
            "Epoch 13/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6921 - binary_accuracy: 0.5161 - val_loss: 0.6923 - val_binary_accuracy: 0.5049\n",
            "Epoch 14/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6921 - binary_accuracy: 0.5176 - val_loss: 0.6922 - val_binary_accuracy: 0.5032\n",
            "Epoch 15/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6920 - binary_accuracy: 0.5193 - val_loss: 0.6922 - val_binary_accuracy: 0.5026\n",
            "Epoch 16/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6919 - binary_accuracy: 0.5213 - val_loss: 0.6921 - val_binary_accuracy: 0.5003\n",
            "Epoch 17/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6918 - binary_accuracy: 0.5262 - val_loss: 0.6921 - val_binary_accuracy: 0.5014\n",
            "Epoch 18/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6917 - binary_accuracy: 0.5273 - val_loss: 0.6920 - val_binary_accuracy: 0.5014\n",
            "Epoch 19/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6916 - binary_accuracy: 0.5295 - val_loss: 0.6920 - val_binary_accuracy: 0.5037\n",
            "Epoch 20/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6916 - binary_accuracy: 0.5332 - val_loss: 0.6919 - val_binary_accuracy: 0.5014\n",
            "Epoch 21/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6915 - binary_accuracy: 0.5328 - val_loss: 0.6919 - val_binary_accuracy: 0.5009\n",
            "Epoch 22/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6914 - binary_accuracy: 0.5338 - val_loss: 0.6918 - val_binary_accuracy: 0.5003\n",
            "Epoch 23/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6913 - binary_accuracy: 0.5302 - val_loss: 0.6917 - val_binary_accuracy: 0.5003\n",
            "Epoch 24/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6912 - binary_accuracy: 0.5332 - val_loss: 0.6917 - val_binary_accuracy: 0.4997\n",
            "Epoch 25/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6911 - binary_accuracy: 0.5338 - val_loss: 0.6916 - val_binary_accuracy: 0.5020\n",
            "Epoch 26/1000\n",
            "6975/6975 [==============================] - 0s 66us/sample - loss: 0.6910 - binary_accuracy: 0.5343 - val_loss: 0.6916 - val_binary_accuracy: 0.5020\n",
            "Epoch 27/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6909 - binary_accuracy: 0.5325 - val_loss: 0.6915 - val_binary_accuracy: 0.5043\n",
            "Epoch 28/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6908 - binary_accuracy: 0.5345 - val_loss: 0.6914 - val_binary_accuracy: 0.5049\n",
            "Epoch 29/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6907 - binary_accuracy: 0.5349 - val_loss: 0.6914 - val_binary_accuracy: 0.5055\n",
            "Epoch 30/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6906 - binary_accuracy: 0.5348 - val_loss: 0.6913 - val_binary_accuracy: 0.5060\n",
            "Epoch 31/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6905 - binary_accuracy: 0.5349 - val_loss: 0.6913 - val_binary_accuracy: 0.5066\n",
            "Epoch 32/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6904 - binary_accuracy: 0.5338 - val_loss: 0.6912 - val_binary_accuracy: 0.5066\n",
            "Epoch 33/1000\n",
            "6975/6975 [==============================] - 0s 66us/sample - loss: 0.6903 - binary_accuracy: 0.5343 - val_loss: 0.6911 - val_binary_accuracy: 0.5089\n",
            "Epoch 34/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6902 - binary_accuracy: 0.5348 - val_loss: 0.6911 - val_binary_accuracy: 0.5100\n",
            "Epoch 35/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6901 - binary_accuracy: 0.5348 - val_loss: 0.6910 - val_binary_accuracy: 0.5100\n",
            "Epoch 36/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6900 - binary_accuracy: 0.5376 - val_loss: 0.6910 - val_binary_accuracy: 0.5123\n",
            "Epoch 37/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6899 - binary_accuracy: 0.5376 - val_loss: 0.6909 - val_binary_accuracy: 0.5123\n",
            "Epoch 38/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6898 - binary_accuracy: 0.5396 - val_loss: 0.6908 - val_binary_accuracy: 0.5123\n",
            "Epoch 39/1000\n",
            "6975/6975 [==============================] - 1s 83us/sample - loss: 0.6897 - binary_accuracy: 0.5408 - val_loss: 0.6908 - val_binary_accuracy: 0.5141\n",
            "Epoch 40/1000\n",
            "6975/6975 [==============================] - 1s 83us/sample - loss: 0.6896 - binary_accuracy: 0.5416 - val_loss: 0.6907 - val_binary_accuracy: 0.5123\n",
            "Epoch 41/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6895 - binary_accuracy: 0.5416 - val_loss: 0.6906 - val_binary_accuracy: 0.5135\n",
            "Epoch 42/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6895 - binary_accuracy: 0.5439 - val_loss: 0.6906 - val_binary_accuracy: 0.5152\n",
            "Epoch 43/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6894 - binary_accuracy: 0.5437 - val_loss: 0.6905 - val_binary_accuracy: 0.5152\n",
            "Epoch 44/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6893 - binary_accuracy: 0.5427 - val_loss: 0.6904 - val_binary_accuracy: 0.5186\n",
            "Epoch 45/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6892 - binary_accuracy: 0.5462 - val_loss: 0.6904 - val_binary_accuracy: 0.5209\n",
            "Epoch 46/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6891 - binary_accuracy: 0.5457 - val_loss: 0.6903 - val_binary_accuracy: 0.5244\n",
            "Epoch 47/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6890 - binary_accuracy: 0.5465 - val_loss: 0.6902 - val_binary_accuracy: 0.5238\n",
            "Epoch 48/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6889 - binary_accuracy: 0.5472 - val_loss: 0.6902 - val_binary_accuracy: 0.5267\n",
            "Epoch 49/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6888 - binary_accuracy: 0.5494 - val_loss: 0.6901 - val_binary_accuracy: 0.5267\n",
            "Epoch 50/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6887 - binary_accuracy: 0.5467 - val_loss: 0.6900 - val_binary_accuracy: 0.5278\n",
            "Epoch 51/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.6886 - binary_accuracy: 0.5497 - val_loss: 0.6900 - val_binary_accuracy: 0.5290\n",
            "Epoch 52/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6885 - binary_accuracy: 0.5495 - val_loss: 0.6899 - val_binary_accuracy: 0.5295\n",
            "Epoch 53/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6884 - binary_accuracy: 0.5504 - val_loss: 0.6898 - val_binary_accuracy: 0.5301\n",
            "Epoch 54/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6883 - binary_accuracy: 0.5511 - val_loss: 0.6898 - val_binary_accuracy: 0.5295\n",
            "Epoch 55/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6882 - binary_accuracy: 0.5498 - val_loss: 0.6897 - val_binary_accuracy: 0.5290\n",
            "Epoch 56/1000\n",
            "6975/6975 [==============================] - 1s 84us/sample - loss: 0.6881 - binary_accuracy: 0.5531 - val_loss: 0.6896 - val_binary_accuracy: 0.5290\n",
            "Epoch 57/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6880 - binary_accuracy: 0.5538 - val_loss: 0.6895 - val_binary_accuracy: 0.5290\n",
            "Epoch 58/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6879 - binary_accuracy: 0.5511 - val_loss: 0.6895 - val_binary_accuracy: 0.5278\n",
            "Epoch 59/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6878 - binary_accuracy: 0.5533 - val_loss: 0.6894 - val_binary_accuracy: 0.5278\n",
            "Epoch 60/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6876 - binary_accuracy: 0.5540 - val_loss: 0.6893 - val_binary_accuracy: 0.5290\n",
            "Epoch 61/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6875 - binary_accuracy: 0.5553 - val_loss: 0.6893 - val_binary_accuracy: 0.5295\n",
            "Epoch 62/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6874 - binary_accuracy: 0.5544 - val_loss: 0.6892 - val_binary_accuracy: 0.5290\n",
            "Epoch 63/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6873 - binary_accuracy: 0.5547 - val_loss: 0.6891 - val_binary_accuracy: 0.5290\n",
            "Epoch 64/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6872 - binary_accuracy: 0.5590 - val_loss: 0.6890 - val_binary_accuracy: 0.5318\n",
            "Epoch 65/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6871 - binary_accuracy: 0.5599 - val_loss: 0.6890 - val_binary_accuracy: 0.5318\n",
            "Epoch 66/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6870 - binary_accuracy: 0.5604 - val_loss: 0.6889 - val_binary_accuracy: 0.5301\n",
            "Epoch 67/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6869 - binary_accuracy: 0.5591 - val_loss: 0.6888 - val_binary_accuracy: 0.5307\n",
            "Epoch 68/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6868 - binary_accuracy: 0.5609 - val_loss: 0.6888 - val_binary_accuracy: 0.5330\n",
            "Epoch 69/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6867 - binary_accuracy: 0.5629 - val_loss: 0.6887 - val_binary_accuracy: 0.5324\n",
            "Epoch 70/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6866 - binary_accuracy: 0.5611 - val_loss: 0.6886 - val_binary_accuracy: 0.5364\n",
            "Epoch 71/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6865 - binary_accuracy: 0.5644 - val_loss: 0.6885 - val_binary_accuracy: 0.5359\n",
            "Epoch 72/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6863 - binary_accuracy: 0.5640 - val_loss: 0.6885 - val_binary_accuracy: 0.5370\n",
            "Epoch 73/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6862 - binary_accuracy: 0.5650 - val_loss: 0.6884 - val_binary_accuracy: 0.5376\n",
            "Epoch 74/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6861 - binary_accuracy: 0.5660 - val_loss: 0.6883 - val_binary_accuracy: 0.5382\n",
            "Epoch 75/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6860 - binary_accuracy: 0.5675 - val_loss: 0.6883 - val_binary_accuracy: 0.5370\n",
            "Epoch 76/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6859 - binary_accuracy: 0.5652 - val_loss: 0.6882 - val_binary_accuracy: 0.5370\n",
            "Epoch 77/1000\n",
            "6975/6975 [==============================] - 1s 85us/sample - loss: 0.6858 - binary_accuracy: 0.5675 - val_loss: 0.6881 - val_binary_accuracy: 0.5359\n",
            "Epoch 78/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6857 - binary_accuracy: 0.5649 - val_loss: 0.6880 - val_binary_accuracy: 0.5364\n",
            "Epoch 79/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6856 - binary_accuracy: 0.5662 - val_loss: 0.6880 - val_binary_accuracy: 0.5376\n",
            "Epoch 80/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6855 - binary_accuracy: 0.5690 - val_loss: 0.6879 - val_binary_accuracy: 0.5399\n",
            "Epoch 81/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6853 - binary_accuracy: 0.5669 - val_loss: 0.6878 - val_binary_accuracy: 0.5422\n",
            "Epoch 82/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6852 - binary_accuracy: 0.5679 - val_loss: 0.6877 - val_binary_accuracy: 0.5410\n",
            "Epoch 83/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6851 - binary_accuracy: 0.5709 - val_loss: 0.6877 - val_binary_accuracy: 0.5445\n",
            "Epoch 84/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6850 - binary_accuracy: 0.5716 - val_loss: 0.6876 - val_binary_accuracy: 0.5439\n",
            "Epoch 85/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6849 - binary_accuracy: 0.5710 - val_loss: 0.6875 - val_binary_accuracy: 0.5433\n",
            "Epoch 86/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6848 - binary_accuracy: 0.5718 - val_loss: 0.6874 - val_binary_accuracy: 0.5422\n",
            "Epoch 87/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6847 - binary_accuracy: 0.5729 - val_loss: 0.6874 - val_binary_accuracy: 0.5433\n",
            "Epoch 88/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6845 - binary_accuracy: 0.5729 - val_loss: 0.6873 - val_binary_accuracy: 0.5491\n",
            "Epoch 89/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6844 - binary_accuracy: 0.5726 - val_loss: 0.6872 - val_binary_accuracy: 0.5473\n",
            "Epoch 90/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6843 - binary_accuracy: 0.5763 - val_loss: 0.6871 - val_binary_accuracy: 0.5513\n",
            "Epoch 91/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6842 - binary_accuracy: 0.5741 - val_loss: 0.6871 - val_binary_accuracy: 0.5519\n",
            "Epoch 92/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6841 - binary_accuracy: 0.5758 - val_loss: 0.6870 - val_binary_accuracy: 0.5519\n",
            "Epoch 93/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6840 - binary_accuracy: 0.5756 - val_loss: 0.6869 - val_binary_accuracy: 0.5525\n",
            "Epoch 94/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6839 - binary_accuracy: 0.5763 - val_loss: 0.6868 - val_binary_accuracy: 0.5519\n",
            "Epoch 95/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6837 - binary_accuracy: 0.5765 - val_loss: 0.6868 - val_binary_accuracy: 0.5508\n",
            "Epoch 96/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6836 - binary_accuracy: 0.5789 - val_loss: 0.6867 - val_binary_accuracy: 0.5513\n",
            "Epoch 97/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6835 - binary_accuracy: 0.5792 - val_loss: 0.6866 - val_binary_accuracy: 0.5508\n",
            "Epoch 98/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6834 - binary_accuracy: 0.5778 - val_loss: 0.6866 - val_binary_accuracy: 0.5491\n",
            "Epoch 99/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6833 - binary_accuracy: 0.5778 - val_loss: 0.6865 - val_binary_accuracy: 0.5519\n",
            "Epoch 100/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6831 - binary_accuracy: 0.5775 - val_loss: 0.6864 - val_binary_accuracy: 0.5542\n",
            "Epoch 101/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6830 - binary_accuracy: 0.5782 - val_loss: 0.6863 - val_binary_accuracy: 0.5542\n",
            "Epoch 102/1000\n",
            "6975/6975 [==============================] - 1s 84us/sample - loss: 0.6829 - binary_accuracy: 0.5798 - val_loss: 0.6863 - val_binary_accuracy: 0.5513\n",
            "Epoch 103/1000\n",
            "6975/6975 [==============================] - 1s 83us/sample - loss: 0.6828 - binary_accuracy: 0.5792 - val_loss: 0.6862 - val_binary_accuracy: 0.5519\n",
            "Epoch 104/1000\n",
            "6975/6975 [==============================] - 1s 86us/sample - loss: 0.6827 - binary_accuracy: 0.5818 - val_loss: 0.6861 - val_binary_accuracy: 0.5531\n",
            "Epoch 105/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6826 - binary_accuracy: 0.5815 - val_loss: 0.6861 - val_binary_accuracy: 0.5531\n",
            "Epoch 106/1000\n",
            "6975/6975 [==============================] - 1s 85us/sample - loss: 0.6824 - binary_accuracy: 0.5809 - val_loss: 0.6860 - val_binary_accuracy: 0.5548\n",
            "Epoch 107/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6823 - binary_accuracy: 0.5808 - val_loss: 0.6859 - val_binary_accuracy: 0.5542\n",
            "Epoch 108/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6822 - binary_accuracy: 0.5804 - val_loss: 0.6858 - val_binary_accuracy: 0.5548\n",
            "Epoch 109/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6821 - binary_accuracy: 0.5829 - val_loss: 0.6857 - val_binary_accuracy: 0.5513\n",
            "Epoch 110/1000\n",
            "6975/6975 [==============================] - 1s 83us/sample - loss: 0.6820 - binary_accuracy: 0.5821 - val_loss: 0.6857 - val_binary_accuracy: 0.5525\n",
            "Epoch 111/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6819 - binary_accuracy: 0.5824 - val_loss: 0.6856 - val_binary_accuracy: 0.5513\n",
            "Epoch 112/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6818 - binary_accuracy: 0.5816 - val_loss: 0.6855 - val_binary_accuracy: 0.5531\n",
            "Epoch 113/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6817 - binary_accuracy: 0.5835 - val_loss: 0.6855 - val_binary_accuracy: 0.5548\n",
            "Epoch 114/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6816 - binary_accuracy: 0.5831 - val_loss: 0.6854 - val_binary_accuracy: 0.5548\n",
            "Epoch 115/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6815 - binary_accuracy: 0.5828 - val_loss: 0.6853 - val_binary_accuracy: 0.5571\n",
            "Epoch 116/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6813 - binary_accuracy: 0.5837 - val_loss: 0.6853 - val_binary_accuracy: 0.5582\n",
            "Epoch 117/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6812 - binary_accuracy: 0.5829 - val_loss: 0.6852 - val_binary_accuracy: 0.5565\n",
            "Epoch 118/1000\n",
            "6975/6975 [==============================] - 1s 84us/sample - loss: 0.6811 - binary_accuracy: 0.5852 - val_loss: 0.6851 - val_binary_accuracy: 0.5582\n",
            "Epoch 119/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6810 - binary_accuracy: 0.5838 - val_loss: 0.6851 - val_binary_accuracy: 0.5605\n",
            "Epoch 120/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6809 - binary_accuracy: 0.5854 - val_loss: 0.6850 - val_binary_accuracy: 0.5611\n",
            "Epoch 121/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6808 - binary_accuracy: 0.5855 - val_loss: 0.6849 - val_binary_accuracy: 0.5622\n",
            "Epoch 122/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6807 - binary_accuracy: 0.5865 - val_loss: 0.6849 - val_binary_accuracy: 0.5617\n",
            "Epoch 123/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6806 - binary_accuracy: 0.5854 - val_loss: 0.6848 - val_binary_accuracy: 0.5634\n",
            "Epoch 124/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6805 - binary_accuracy: 0.5877 - val_loss: 0.6847 - val_binary_accuracy: 0.5634\n",
            "Epoch 125/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6804 - binary_accuracy: 0.5864 - val_loss: 0.6847 - val_binary_accuracy: 0.5634\n",
            "Epoch 126/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6803 - binary_accuracy: 0.5865 - val_loss: 0.6846 - val_binary_accuracy: 0.5622\n",
            "Epoch 127/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6802 - binary_accuracy: 0.5891 - val_loss: 0.6845 - val_binary_accuracy: 0.5622\n",
            "Epoch 128/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6801 - binary_accuracy: 0.5864 - val_loss: 0.6845 - val_binary_accuracy: 0.5617\n",
            "Epoch 129/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6799 - binary_accuracy: 0.5884 - val_loss: 0.6844 - val_binary_accuracy: 0.5611\n",
            "Epoch 130/1000\n",
            "6975/6975 [==============================] - 0s 67us/sample - loss: 0.6798 - binary_accuracy: 0.5890 - val_loss: 0.6843 - val_binary_accuracy: 0.5617\n",
            "Epoch 131/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6797 - binary_accuracy: 0.5881 - val_loss: 0.6843 - val_binary_accuracy: 0.5611\n",
            "Epoch 132/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6796 - binary_accuracy: 0.5891 - val_loss: 0.6842 - val_binary_accuracy: 0.5622\n",
            "Epoch 133/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6795 - binary_accuracy: 0.5895 - val_loss: 0.6842 - val_binary_accuracy: 0.5617\n",
            "Epoch 134/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6794 - binary_accuracy: 0.5907 - val_loss: 0.6841 - val_binary_accuracy: 0.5617\n",
            "Epoch 135/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6793 - binary_accuracy: 0.5903 - val_loss: 0.6841 - val_binary_accuracy: 0.5622\n",
            "Epoch 136/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6792 - binary_accuracy: 0.5890 - val_loss: 0.6840 - val_binary_accuracy: 0.5628\n",
            "Epoch 137/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6791 - binary_accuracy: 0.5900 - val_loss: 0.6840 - val_binary_accuracy: 0.5622\n",
            "Epoch 138/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6790 - binary_accuracy: 0.5903 - val_loss: 0.6839 - val_binary_accuracy: 0.5617\n",
            "Epoch 139/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6789 - binary_accuracy: 0.5891 - val_loss: 0.6839 - val_binary_accuracy: 0.5611\n",
            "Epoch 140/1000\n",
            "6975/6975 [==============================] - 0s 72us/sample - loss: 0.6788 - binary_accuracy: 0.5913 - val_loss: 0.6838 - val_binary_accuracy: 0.5628\n",
            "Epoch 141/1000\n",
            "6975/6975 [==============================] - 1s 87us/sample - loss: 0.6787 - binary_accuracy: 0.5907 - val_loss: 0.6838 - val_binary_accuracy: 0.5605\n",
            "Epoch 142/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6786 - binary_accuracy: 0.5915 - val_loss: 0.6837 - val_binary_accuracy: 0.5611\n",
            "Epoch 143/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6785 - binary_accuracy: 0.5911 - val_loss: 0.6836 - val_binary_accuracy: 0.5628\n",
            "Epoch 144/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6784 - binary_accuracy: 0.5934 - val_loss: 0.6836 - val_binary_accuracy: 0.5634\n",
            "Epoch 145/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6783 - binary_accuracy: 0.5917 - val_loss: 0.6835 - val_binary_accuracy: 0.5634\n",
            "Epoch 146/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.6782 - binary_accuracy: 0.5933 - val_loss: 0.6835 - val_binary_accuracy: 0.5640\n",
            "Epoch 147/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6781 - binary_accuracy: 0.5927 - val_loss: 0.6835 - val_binary_accuracy: 0.5645\n",
            "Epoch 148/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6780 - binary_accuracy: 0.5931 - val_loss: 0.6834 - val_binary_accuracy: 0.5640\n",
            "Epoch 149/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6779 - binary_accuracy: 0.5928 - val_loss: 0.6834 - val_binary_accuracy: 0.5645\n",
            "Epoch 150/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6778 - binary_accuracy: 0.5923 - val_loss: 0.6833 - val_binary_accuracy: 0.5651\n",
            "Epoch 151/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6778 - binary_accuracy: 0.5931 - val_loss: 0.6833 - val_binary_accuracy: 0.5640\n",
            "Epoch 152/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6777 - binary_accuracy: 0.5941 - val_loss: 0.6832 - val_binary_accuracy: 0.5617\n",
            "Epoch 153/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6776 - binary_accuracy: 0.5937 - val_loss: 0.6831 - val_binary_accuracy: 0.5617\n",
            "Epoch 154/1000\n",
            "6975/6975 [==============================] - 1s 90us/sample - loss: 0.6775 - binary_accuracy: 0.5941 - val_loss: 0.6831 - val_binary_accuracy: 0.5634\n",
            "Epoch 155/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6774 - binary_accuracy: 0.5934 - val_loss: 0.6831 - val_binary_accuracy: 0.5617\n",
            "Epoch 156/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6773 - binary_accuracy: 0.5933 - val_loss: 0.6830 - val_binary_accuracy: 0.5617\n",
            "Epoch 157/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6772 - binary_accuracy: 0.5943 - val_loss: 0.6830 - val_binary_accuracy: 0.5605\n",
            "Epoch 158/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.6771 - binary_accuracy: 0.5931 - val_loss: 0.6829 - val_binary_accuracy: 0.5582\n",
            "Epoch 159/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6770 - binary_accuracy: 0.5938 - val_loss: 0.6829 - val_binary_accuracy: 0.5600\n",
            "Epoch 160/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6770 - binary_accuracy: 0.5947 - val_loss: 0.6828 - val_binary_accuracy: 0.5594\n",
            "Epoch 161/1000\n",
            "6975/6975 [==============================] - 1s 91us/sample - loss: 0.6769 - binary_accuracy: 0.5940 - val_loss: 0.6828 - val_binary_accuracy: 0.5594\n",
            "Epoch 162/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6768 - binary_accuracy: 0.5953 - val_loss: 0.6827 - val_binary_accuracy: 0.5594\n",
            "Epoch 163/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6767 - binary_accuracy: 0.5934 - val_loss: 0.6827 - val_binary_accuracy: 0.5600\n",
            "Epoch 164/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6766 - binary_accuracy: 0.5961 - val_loss: 0.6827 - val_binary_accuracy: 0.5594\n",
            "Epoch 165/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6766 - binary_accuracy: 0.5957 - val_loss: 0.6826 - val_binary_accuracy: 0.5600\n",
            "Epoch 166/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6765 - binary_accuracy: 0.5958 - val_loss: 0.6826 - val_binary_accuracy: 0.5582\n",
            "Epoch 167/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6764 - binary_accuracy: 0.5958 - val_loss: 0.6825 - val_binary_accuracy: 0.5588\n",
            "Epoch 168/1000\n",
            "6975/6975 [==============================] - 1s 94us/sample - loss: 0.6763 - binary_accuracy: 0.5944 - val_loss: 0.6825 - val_binary_accuracy: 0.5588\n",
            "Epoch 169/1000\n",
            "6975/6975 [==============================] - 1s 89us/sample - loss: 0.6762 - binary_accuracy: 0.5954 - val_loss: 0.6825 - val_binary_accuracy: 0.5605\n",
            "Epoch 170/1000\n",
            "6975/6975 [==============================] - 1s 88us/sample - loss: 0.6761 - binary_accuracy: 0.5958 - val_loss: 0.6824 - val_binary_accuracy: 0.5605\n",
            "Epoch 171/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6761 - binary_accuracy: 0.5961 - val_loss: 0.6824 - val_binary_accuracy: 0.5594\n",
            "Epoch 172/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6760 - binary_accuracy: 0.5953 - val_loss: 0.6823 - val_binary_accuracy: 0.5588\n",
            "Epoch 173/1000\n",
            "6975/6975 [==============================] - 1s 87us/sample - loss: 0.6759 - binary_accuracy: 0.5956 - val_loss: 0.6823 - val_binary_accuracy: 0.5600\n",
            "Epoch 174/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6758 - binary_accuracy: 0.5960 - val_loss: 0.6822 - val_binary_accuracy: 0.5617\n",
            "Epoch 175/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6758 - binary_accuracy: 0.5956 - val_loss: 0.6822 - val_binary_accuracy: 0.5588\n",
            "Epoch 176/1000\n",
            "6975/6975 [==============================] - 1s 95us/sample - loss: 0.6757 - binary_accuracy: 0.5960 - val_loss: 0.6822 - val_binary_accuracy: 0.5600\n",
            "Epoch 177/1000\n",
            "6975/6975 [==============================] - 1s 86us/sample - loss: 0.6756 - binary_accuracy: 0.5964 - val_loss: 0.6821 - val_binary_accuracy: 0.5611\n",
            "Epoch 178/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6755 - binary_accuracy: 0.5971 - val_loss: 0.6821 - val_binary_accuracy: 0.5622\n",
            "Epoch 179/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6754 - binary_accuracy: 0.5960 - val_loss: 0.6821 - val_binary_accuracy: 0.5628\n",
            "Epoch 180/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6754 - binary_accuracy: 0.5960 - val_loss: 0.6820 - val_binary_accuracy: 0.5634\n",
            "Epoch 181/1000\n",
            "6975/6975 [==============================] - 1s 90us/sample - loss: 0.6753 - binary_accuracy: 0.5973 - val_loss: 0.6820 - val_binary_accuracy: 0.5634\n",
            "Epoch 182/1000\n",
            "6975/6975 [==============================] - 1s 89us/sample - loss: 0.6752 - binary_accuracy: 0.5974 - val_loss: 0.6820 - val_binary_accuracy: 0.5640\n",
            "Epoch 183/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6751 - binary_accuracy: 0.5971 - val_loss: 0.6819 - val_binary_accuracy: 0.5634\n",
            "Epoch 184/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6751 - binary_accuracy: 0.5974 - val_loss: 0.6819 - val_binary_accuracy: 0.5634\n",
            "Epoch 185/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.6750 - binary_accuracy: 0.5970 - val_loss: 0.6818 - val_binary_accuracy: 0.5657\n",
            "Epoch 186/1000\n",
            "6975/6975 [==============================] - 1s 88us/sample - loss: 0.6749 - binary_accuracy: 0.5976 - val_loss: 0.6818 - val_binary_accuracy: 0.5645\n",
            "Epoch 187/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6748 - binary_accuracy: 0.5973 - val_loss: 0.6818 - val_binary_accuracy: 0.5645\n",
            "Epoch 188/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6748 - binary_accuracy: 0.5974 - val_loss: 0.6817 - val_binary_accuracy: 0.5651\n",
            "Epoch 189/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6747 - binary_accuracy: 0.5977 - val_loss: 0.6817 - val_binary_accuracy: 0.5651\n",
            "Epoch 190/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6746 - binary_accuracy: 0.5974 - val_loss: 0.6817 - val_binary_accuracy: 0.5651\n",
            "Epoch 191/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6746 - binary_accuracy: 0.5977 - val_loss: 0.6817 - val_binary_accuracy: 0.5651\n",
            "Epoch 192/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6745 - binary_accuracy: 0.5984 - val_loss: 0.6817 - val_binary_accuracy: 0.5651\n",
            "Epoch 193/1000\n",
            "6975/6975 [==============================] - 1s 86us/sample - loss: 0.6744 - binary_accuracy: 0.5977 - val_loss: 0.6816 - val_binary_accuracy: 0.5645\n",
            "Epoch 194/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6743 - binary_accuracy: 0.5983 - val_loss: 0.6816 - val_binary_accuracy: 0.5651\n",
            "Epoch 195/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6743 - binary_accuracy: 0.5984 - val_loss: 0.6815 - val_binary_accuracy: 0.5640\n",
            "Epoch 196/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6742 - binary_accuracy: 0.5990 - val_loss: 0.6815 - val_binary_accuracy: 0.5634\n",
            "Epoch 197/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6741 - binary_accuracy: 0.5996 - val_loss: 0.6815 - val_binary_accuracy: 0.5640\n",
            "Epoch 198/1000\n",
            "6975/6975 [==============================] - 1s 92us/sample - loss: 0.6741 - binary_accuracy: 0.5994 - val_loss: 0.6814 - val_binary_accuracy: 0.5645\n",
            "Epoch 199/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6740 - binary_accuracy: 0.5990 - val_loss: 0.6814 - val_binary_accuracy: 0.5640\n",
            "Epoch 200/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.6739 - binary_accuracy: 0.5993 - val_loss: 0.6814 - val_binary_accuracy: 0.5640\n",
            "Epoch 201/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6739 - binary_accuracy: 0.5983 - val_loss: 0.6813 - val_binary_accuracy: 0.5640\n",
            "Epoch 202/1000\n",
            "6975/6975 [==============================] - 1s 84us/sample - loss: 0.6738 - binary_accuracy: 0.5994 - val_loss: 0.6813 - val_binary_accuracy: 0.5640\n",
            "Epoch 203/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6738 - binary_accuracy: 0.5981 - val_loss: 0.6813 - val_binary_accuracy: 0.5640\n",
            "Epoch 204/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6737 - binary_accuracy: 0.5991 - val_loss: 0.6813 - val_binary_accuracy: 0.5640\n",
            "Epoch 205/1000\n",
            "6975/6975 [==============================] - 0s 72us/sample - loss: 0.6736 - binary_accuracy: 0.5996 - val_loss: 0.6812 - val_binary_accuracy: 0.5628\n",
            "Epoch 206/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.6736 - binary_accuracy: 0.6000 - val_loss: 0.6812 - val_binary_accuracy: 0.5628\n",
            "Epoch 207/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6735 - binary_accuracy: 0.5996 - val_loss: 0.6812 - val_binary_accuracy: 0.5651\n",
            "Epoch 208/1000\n",
            "6975/6975 [==============================] - 1s 87us/sample - loss: 0.6734 - binary_accuracy: 0.6001 - val_loss: 0.6812 - val_binary_accuracy: 0.5628\n",
            "Epoch 209/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6734 - binary_accuracy: 0.6007 - val_loss: 0.6811 - val_binary_accuracy: 0.5628\n",
            "Epoch 210/1000\n",
            "6975/6975 [==============================] - 1s 89us/sample - loss: 0.6733 - binary_accuracy: 0.6003 - val_loss: 0.6811 - val_binary_accuracy: 0.5634\n",
            "Epoch 211/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.6733 - binary_accuracy: 0.6009 - val_loss: 0.6811 - val_binary_accuracy: 0.5628\n",
            "Epoch 212/1000\n",
            "6975/6975 [==============================] - 1s 85us/sample - loss: 0.6732 - binary_accuracy: 0.5999 - val_loss: 0.6811 - val_binary_accuracy: 0.5634\n",
            "Epoch 213/1000\n",
            "6975/6975 [==============================] - 1s 83us/sample - loss: 0.6731 - binary_accuracy: 0.6010 - val_loss: 0.6811 - val_binary_accuracy: 0.5634\n",
            "Epoch 214/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6731 - binary_accuracy: 0.6006 - val_loss: 0.6810 - val_binary_accuracy: 0.5634\n",
            "Epoch 215/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6730 - binary_accuracy: 0.6020 - val_loss: 0.6810 - val_binary_accuracy: 0.5634\n",
            "Epoch 216/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6729 - binary_accuracy: 0.6017 - val_loss: 0.6810 - val_binary_accuracy: 0.5628\n",
            "Epoch 217/1000\n",
            "6975/6975 [==============================] - 1s 84us/sample - loss: 0.6729 - binary_accuracy: 0.6019 - val_loss: 0.6810 - val_binary_accuracy: 0.5634\n",
            "Epoch 218/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6728 - binary_accuracy: 0.6022 - val_loss: 0.6810 - val_binary_accuracy: 0.5640\n",
            "Epoch 219/1000\n",
            "6975/6975 [==============================] - 1s 87us/sample - loss: 0.6727 - binary_accuracy: 0.6011 - val_loss: 0.6809 - val_binary_accuracy: 0.5634\n",
            "Epoch 220/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6727 - binary_accuracy: 0.6014 - val_loss: 0.6809 - val_binary_accuracy: 0.5634\n",
            "Epoch 221/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6726 - binary_accuracy: 0.6022 - val_loss: 0.6808 - val_binary_accuracy: 0.5628\n",
            "Epoch 222/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6726 - binary_accuracy: 0.6023 - val_loss: 0.6808 - val_binary_accuracy: 0.5617\n",
            "Epoch 223/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6725 - binary_accuracy: 0.6010 - val_loss: 0.6809 - val_binary_accuracy: 0.5628\n",
            "Epoch 224/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6724 - binary_accuracy: 0.6016 - val_loss: 0.6808 - val_binary_accuracy: 0.5628\n",
            "Epoch 225/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6724 - binary_accuracy: 0.6023 - val_loss: 0.6808 - val_binary_accuracy: 0.5617\n",
            "Epoch 226/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6723 - binary_accuracy: 0.6027 - val_loss: 0.6808 - val_binary_accuracy: 0.5611\n",
            "Epoch 227/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6723 - binary_accuracy: 0.6023 - val_loss: 0.6808 - val_binary_accuracy: 0.5617\n",
            "Epoch 228/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6722 - binary_accuracy: 0.6014 - val_loss: 0.6807 - val_binary_accuracy: 0.5628\n",
            "Epoch 229/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6722 - binary_accuracy: 0.6023 - val_loss: 0.6807 - val_binary_accuracy: 0.5622\n",
            "Epoch 230/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6721 - binary_accuracy: 0.6029 - val_loss: 0.6807 - val_binary_accuracy: 0.5628\n",
            "Epoch 231/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6721 - binary_accuracy: 0.6019 - val_loss: 0.6807 - val_binary_accuracy: 0.5617\n",
            "Epoch 232/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6720 - binary_accuracy: 0.6020 - val_loss: 0.6806 - val_binary_accuracy: 0.5622\n",
            "Epoch 233/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6719 - binary_accuracy: 0.6009 - val_loss: 0.6806 - val_binary_accuracy: 0.5622\n",
            "Epoch 234/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6719 - binary_accuracy: 0.6013 - val_loss: 0.6806 - val_binary_accuracy: 0.5628\n",
            "Epoch 235/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6718 - binary_accuracy: 0.6006 - val_loss: 0.6806 - val_binary_accuracy: 0.5628\n",
            "Epoch 236/1000\n",
            "6975/6975 [==============================] - 0s 67us/sample - loss: 0.6718 - binary_accuracy: 0.6027 - val_loss: 0.6806 - val_binary_accuracy: 0.5611\n",
            "Epoch 237/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6717 - binary_accuracy: 0.6017 - val_loss: 0.6805 - val_binary_accuracy: 0.5611\n",
            "Epoch 238/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6717 - binary_accuracy: 0.6019 - val_loss: 0.6805 - val_binary_accuracy: 0.5628\n",
            "Epoch 239/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6716 - binary_accuracy: 0.6016 - val_loss: 0.6805 - val_binary_accuracy: 0.5622\n",
            "Epoch 240/1000\n",
            "6975/6975 [==============================] - 0s 66us/sample - loss: 0.6716 - binary_accuracy: 0.6014 - val_loss: 0.6806 - val_binary_accuracy: 0.5634\n",
            "Epoch 241/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6715 - binary_accuracy: 0.6007 - val_loss: 0.6805 - val_binary_accuracy: 0.5622\n",
            "Epoch 242/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6715 - binary_accuracy: 0.6014 - val_loss: 0.6805 - val_binary_accuracy: 0.5634\n",
            "Epoch 243/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6714 - binary_accuracy: 0.6013 - val_loss: 0.6805 - val_binary_accuracy: 0.5645\n",
            "Epoch 244/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.6714 - binary_accuracy: 0.6010 - val_loss: 0.6804 - val_binary_accuracy: 0.5617\n",
            "Epoch 245/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6713 - binary_accuracy: 0.6007 - val_loss: 0.6804 - val_binary_accuracy: 0.5617\n",
            "Epoch 246/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6713 - binary_accuracy: 0.6020 - val_loss: 0.6804 - val_binary_accuracy: 0.5617\n",
            "Epoch 247/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6712 - binary_accuracy: 0.6011 - val_loss: 0.6804 - val_binary_accuracy: 0.5622\n",
            "Epoch 248/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.6712 - binary_accuracy: 0.6011 - val_loss: 0.6804 - val_binary_accuracy: 0.5622\n",
            "Epoch 249/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6711 - binary_accuracy: 0.6020 - val_loss: 0.6804 - val_binary_accuracy: 0.5628\n",
            "Epoch 250/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6711 - binary_accuracy: 0.6016 - val_loss: 0.6804 - val_binary_accuracy: 0.5617\n",
            "Epoch 251/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6710 - binary_accuracy: 0.6016 - val_loss: 0.6803 - val_binary_accuracy: 0.5628\n",
            "Epoch 252/1000\n",
            "6975/6975 [==============================] - 1s 95us/sample - loss: 0.6710 - binary_accuracy: 0.6004 - val_loss: 0.6803 - val_binary_accuracy: 0.5622\n",
            "Epoch 253/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.6709 - binary_accuracy: 0.6019 - val_loss: 0.6803 - val_binary_accuracy: 0.5617\n",
            "Epoch 254/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6709 - binary_accuracy: 0.6020 - val_loss: 0.6803 - val_binary_accuracy: 0.5617\n",
            "Epoch 255/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.6708 - binary_accuracy: 0.6014 - val_loss: 0.6803 - val_binary_accuracy: 0.5611\n",
            "Epoch 256/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.6708 - binary_accuracy: 0.6016 - val_loss: 0.6803 - val_binary_accuracy: 0.5628\n",
            "Epoch 257/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6707 - binary_accuracy: 0.6007 - val_loss: 0.6803 - val_binary_accuracy: 0.5617\n",
            "Epoch 258/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6707 - binary_accuracy: 0.6010 - val_loss: 0.6803 - val_binary_accuracy: 0.5622\n",
            "Epoch 259/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6706 - binary_accuracy: 0.6003 - val_loss: 0.6802 - val_binary_accuracy: 0.5617\n",
            "Epoch 260/1000\n",
            "6975/6975 [==============================] - 1s 90us/sample - loss: 0.6706 - binary_accuracy: 0.6003 - val_loss: 0.6802 - val_binary_accuracy: 0.5628\n",
            "Epoch 261/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6705 - binary_accuracy: 0.6007 - val_loss: 0.6802 - val_binary_accuracy: 0.5628\n",
            "Epoch 262/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6705 - binary_accuracy: 0.6014 - val_loss: 0.6801 - val_binary_accuracy: 0.5628\n",
            "Epoch 263/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6704 - binary_accuracy: 0.6007 - val_loss: 0.6802 - val_binary_accuracy: 0.5622\n",
            "Epoch 264/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6704 - binary_accuracy: 0.5994 - val_loss: 0.6801 - val_binary_accuracy: 0.5622\n",
            "Epoch 265/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6704 - binary_accuracy: 0.6006 - val_loss: 0.6801 - val_binary_accuracy: 0.5628\n",
            "Epoch 266/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6703 - binary_accuracy: 0.6010 - val_loss: 0.6801 - val_binary_accuracy: 0.5628\n",
            "Epoch 267/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6703 - binary_accuracy: 0.5999 - val_loss: 0.6800 - val_binary_accuracy: 0.5611\n",
            "Epoch 268/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6702 - binary_accuracy: 0.5997 - val_loss: 0.6801 - val_binary_accuracy: 0.5617\n",
            "Epoch 269/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6702 - binary_accuracy: 0.6011 - val_loss: 0.6801 - val_binary_accuracy: 0.5622\n",
            "Epoch 270/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6701 - binary_accuracy: 0.6000 - val_loss: 0.6800 - val_binary_accuracy: 0.5617\n",
            "Epoch 271/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6701 - binary_accuracy: 0.6016 - val_loss: 0.6800 - val_binary_accuracy: 0.5622\n",
            "Epoch 272/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6700 - binary_accuracy: 0.6009 - val_loss: 0.6800 - val_binary_accuracy: 0.5628\n",
            "Epoch 273/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6700 - binary_accuracy: 0.6014 - val_loss: 0.6800 - val_binary_accuracy: 0.5634\n",
            "Epoch 274/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6700 - binary_accuracy: 0.6013 - val_loss: 0.6799 - val_binary_accuracy: 0.5622\n",
            "Epoch 275/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6699 - binary_accuracy: 0.6016 - val_loss: 0.6800 - val_binary_accuracy: 0.5634\n",
            "Epoch 276/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6699 - binary_accuracy: 0.6016 - val_loss: 0.6799 - val_binary_accuracy: 0.5628\n",
            "Epoch 277/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.6698 - binary_accuracy: 0.6011 - val_loss: 0.6799 - val_binary_accuracy: 0.5628\n",
            "Epoch 278/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6698 - binary_accuracy: 0.6027 - val_loss: 0.6799 - val_binary_accuracy: 0.5622\n",
            "Epoch 279/1000\n",
            "6975/6975 [==============================] - 1s 83us/sample - loss: 0.6698 - binary_accuracy: 0.6013 - val_loss: 0.6799 - val_binary_accuracy: 0.5628\n",
            "Epoch 280/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6697 - binary_accuracy: 0.6017 - val_loss: 0.6798 - val_binary_accuracy: 0.5622\n",
            "Epoch 281/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6697 - binary_accuracy: 0.6019 - val_loss: 0.6798 - val_binary_accuracy: 0.5645\n",
            "Epoch 282/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6696 - binary_accuracy: 0.6026 - val_loss: 0.6798 - val_binary_accuracy: 0.5622\n",
            "Epoch 283/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6696 - binary_accuracy: 0.6024 - val_loss: 0.6798 - val_binary_accuracy: 0.5622\n",
            "Epoch 284/1000\n",
            "6975/6975 [==============================] - 0s 67us/sample - loss: 0.6696 - binary_accuracy: 0.6019 - val_loss: 0.6798 - val_binary_accuracy: 0.5622\n",
            "Epoch 285/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6695 - binary_accuracy: 0.6027 - val_loss: 0.6798 - val_binary_accuracy: 0.5628\n",
            "Epoch 286/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6695 - binary_accuracy: 0.6030 - val_loss: 0.6798 - val_binary_accuracy: 0.5628\n",
            "Epoch 287/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6694 - binary_accuracy: 0.6024 - val_loss: 0.6797 - val_binary_accuracy: 0.5628\n",
            "Epoch 288/1000\n",
            "6975/6975 [==============================] - 0s 67us/sample - loss: 0.6694 - binary_accuracy: 0.6034 - val_loss: 0.6797 - val_binary_accuracy: 0.5645\n",
            "Epoch 289/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6694 - binary_accuracy: 0.6029 - val_loss: 0.6797 - val_binary_accuracy: 0.5645\n",
            "Epoch 290/1000\n",
            "6975/6975 [==============================] - 1s 83us/sample - loss: 0.6693 - binary_accuracy: 0.6032 - val_loss: 0.6797 - val_binary_accuracy: 0.5645\n",
            "Epoch 291/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6693 - binary_accuracy: 0.6030 - val_loss: 0.6797 - val_binary_accuracy: 0.5645\n",
            "Epoch 292/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6692 - binary_accuracy: 0.6034 - val_loss: 0.6797 - val_binary_accuracy: 0.5651\n",
            "Epoch 293/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6692 - binary_accuracy: 0.6044 - val_loss: 0.6797 - val_binary_accuracy: 0.5651\n",
            "Epoch 294/1000\n",
            "6975/6975 [==============================] - 0s 66us/sample - loss: 0.6692 - binary_accuracy: 0.6037 - val_loss: 0.6796 - val_binary_accuracy: 0.5640\n",
            "Epoch 295/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6691 - binary_accuracy: 0.6032 - val_loss: 0.6796 - val_binary_accuracy: 0.5628\n",
            "Epoch 296/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6691 - binary_accuracy: 0.6043 - val_loss: 0.6796 - val_binary_accuracy: 0.5634\n",
            "Epoch 297/1000\n",
            "6975/6975 [==============================] - 0s 72us/sample - loss: 0.6691 - binary_accuracy: 0.6037 - val_loss: 0.6796 - val_binary_accuracy: 0.5640\n",
            "Epoch 298/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6690 - binary_accuracy: 0.6043 - val_loss: 0.6796 - val_binary_accuracy: 0.5628\n",
            "Epoch 299/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6690 - binary_accuracy: 0.6033 - val_loss: 0.6795 - val_binary_accuracy: 0.5645\n",
            "Epoch 300/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6689 - binary_accuracy: 0.6040 - val_loss: 0.6796 - val_binary_accuracy: 0.5628\n",
            "Epoch 301/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6689 - binary_accuracy: 0.6039 - val_loss: 0.6796 - val_binary_accuracy: 0.5651\n",
            "Epoch 302/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6689 - binary_accuracy: 0.6057 - val_loss: 0.6796 - val_binary_accuracy: 0.5651\n",
            "Epoch 303/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6689 - binary_accuracy: 0.6049 - val_loss: 0.6796 - val_binary_accuracy: 0.5622\n",
            "Epoch 304/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6688 - binary_accuracy: 0.6043 - val_loss: 0.6795 - val_binary_accuracy: 0.5651\n",
            "Epoch 305/1000\n",
            "6975/6975 [==============================] - 0s 72us/sample - loss: 0.6688 - binary_accuracy: 0.6049 - val_loss: 0.6795 - val_binary_accuracy: 0.5645\n",
            "Epoch 306/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6687 - binary_accuracy: 0.6042 - val_loss: 0.6795 - val_binary_accuracy: 0.5651\n",
            "Epoch 307/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6687 - binary_accuracy: 0.6047 - val_loss: 0.6794 - val_binary_accuracy: 0.5668\n",
            "Epoch 308/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6687 - binary_accuracy: 0.6049 - val_loss: 0.6794 - val_binary_accuracy: 0.5663\n",
            "Epoch 309/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6686 - binary_accuracy: 0.6046 - val_loss: 0.6794 - val_binary_accuracy: 0.5657\n",
            "Epoch 310/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6686 - binary_accuracy: 0.6054 - val_loss: 0.6794 - val_binary_accuracy: 0.5663\n",
            "Epoch 311/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6686 - binary_accuracy: 0.6039 - val_loss: 0.6794 - val_binary_accuracy: 0.5663\n",
            "Epoch 312/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6685 - binary_accuracy: 0.6047 - val_loss: 0.6794 - val_binary_accuracy: 0.5663\n",
            "Epoch 313/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6685 - binary_accuracy: 0.6050 - val_loss: 0.6794 - val_binary_accuracy: 0.5663\n",
            "Epoch 314/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6685 - binary_accuracy: 0.6057 - val_loss: 0.6794 - val_binary_accuracy: 0.5674\n",
            "Epoch 315/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6684 - binary_accuracy: 0.6059 - val_loss: 0.6794 - val_binary_accuracy: 0.5668\n",
            "Epoch 316/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6684 - binary_accuracy: 0.6054 - val_loss: 0.6794 - val_binary_accuracy: 0.5663\n",
            "Epoch 317/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6684 - binary_accuracy: 0.6054 - val_loss: 0.6794 - val_binary_accuracy: 0.5668\n",
            "Epoch 318/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6684 - binary_accuracy: 0.6043 - val_loss: 0.6793 - val_binary_accuracy: 0.5680\n",
            "Epoch 319/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6683 - binary_accuracy: 0.6052 - val_loss: 0.6793 - val_binary_accuracy: 0.5680\n",
            "Epoch 320/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6683 - binary_accuracy: 0.6056 - val_loss: 0.6793 - val_binary_accuracy: 0.5680\n",
            "Epoch 321/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6682 - binary_accuracy: 0.6050 - val_loss: 0.6794 - val_binary_accuracy: 0.5663\n",
            "Epoch 322/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6682 - binary_accuracy: 0.6053 - val_loss: 0.6793 - val_binary_accuracy: 0.5686\n",
            "Epoch 323/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6682 - binary_accuracy: 0.6050 - val_loss: 0.6793 - val_binary_accuracy: 0.5686\n",
            "Epoch 324/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6681 - binary_accuracy: 0.6059 - val_loss: 0.6793 - val_binary_accuracy: 0.5680\n",
            "Epoch 325/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6681 - binary_accuracy: 0.6057 - val_loss: 0.6793 - val_binary_accuracy: 0.5680\n",
            "Epoch 326/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6681 - binary_accuracy: 0.6062 - val_loss: 0.6794 - val_binary_accuracy: 0.5668\n",
            "Epoch 327/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6681 - binary_accuracy: 0.6056 - val_loss: 0.6794 - val_binary_accuracy: 0.5668\n",
            "Epoch 328/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6680 - binary_accuracy: 0.6053 - val_loss: 0.6793 - val_binary_accuracy: 0.5680\n",
            "Epoch 329/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6680 - binary_accuracy: 0.6060 - val_loss: 0.6793 - val_binary_accuracy: 0.5691\n",
            "Epoch 330/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6680 - binary_accuracy: 0.6053 - val_loss: 0.6793 - val_binary_accuracy: 0.5686\n",
            "Epoch 331/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6679 - binary_accuracy: 0.6059 - val_loss: 0.6792 - val_binary_accuracy: 0.5691\n",
            "Epoch 332/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6679 - binary_accuracy: 0.6052 - val_loss: 0.6792 - val_binary_accuracy: 0.5686\n",
            "Epoch 333/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6679 - binary_accuracy: 0.6063 - val_loss: 0.6792 - val_binary_accuracy: 0.5691\n",
            "Epoch 334/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6678 - binary_accuracy: 0.6059 - val_loss: 0.6792 - val_binary_accuracy: 0.5691\n",
            "Epoch 335/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6678 - binary_accuracy: 0.6056 - val_loss: 0.6792 - val_binary_accuracy: 0.5691\n",
            "Epoch 336/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6678 - binary_accuracy: 0.6065 - val_loss: 0.6792 - val_binary_accuracy: 0.5691\n",
            "Epoch 337/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6678 - binary_accuracy: 0.6059 - val_loss: 0.6792 - val_binary_accuracy: 0.5691\n",
            "Epoch 338/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6677 - binary_accuracy: 0.6059 - val_loss: 0.6791 - val_binary_accuracy: 0.5686\n",
            "Epoch 339/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6677 - binary_accuracy: 0.6053 - val_loss: 0.6792 - val_binary_accuracy: 0.5703\n",
            "Epoch 340/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6677 - binary_accuracy: 0.6063 - val_loss: 0.6792 - val_binary_accuracy: 0.5691\n",
            "Epoch 341/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6676 - binary_accuracy: 0.6059 - val_loss: 0.6792 - val_binary_accuracy: 0.5691\n",
            "Epoch 342/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6676 - binary_accuracy: 0.6057 - val_loss: 0.6792 - val_binary_accuracy: 0.5697\n",
            "Epoch 343/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6676 - binary_accuracy: 0.6062 - val_loss: 0.6791 - val_binary_accuracy: 0.5697\n",
            "Epoch 344/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6676 - binary_accuracy: 0.6057 - val_loss: 0.6791 - val_binary_accuracy: 0.5703\n",
            "Epoch 345/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6675 - binary_accuracy: 0.6053 - val_loss: 0.6791 - val_binary_accuracy: 0.5703\n",
            "Epoch 346/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6675 - binary_accuracy: 0.6059 - val_loss: 0.6791 - val_binary_accuracy: 0.5697\n",
            "Epoch 347/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6675 - binary_accuracy: 0.6059 - val_loss: 0.6791 - val_binary_accuracy: 0.5703\n",
            "Epoch 348/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6674 - binary_accuracy: 0.6053 - val_loss: 0.6791 - val_binary_accuracy: 0.5714\n",
            "Epoch 349/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6674 - binary_accuracy: 0.6063 - val_loss: 0.6791 - val_binary_accuracy: 0.5709\n",
            "Epoch 350/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6674 - binary_accuracy: 0.6057 - val_loss: 0.6791 - val_binary_accuracy: 0.5703\n",
            "Epoch 351/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6674 - binary_accuracy: 0.6059 - val_loss: 0.6791 - val_binary_accuracy: 0.5709\n",
            "Epoch 352/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6673 - binary_accuracy: 0.6062 - val_loss: 0.6791 - val_binary_accuracy: 0.5709\n",
            "Epoch 353/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6673 - binary_accuracy: 0.6062 - val_loss: 0.6790 - val_binary_accuracy: 0.5703\n",
            "Epoch 354/1000\n",
            "6975/6975 [==============================] - 0s 72us/sample - loss: 0.6673 - binary_accuracy: 0.6069 - val_loss: 0.6790 - val_binary_accuracy: 0.5703\n",
            "Epoch 355/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6672 - binary_accuracy: 0.6052 - val_loss: 0.6790 - val_binary_accuracy: 0.5703\n",
            "Epoch 356/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6672 - binary_accuracy: 0.6059 - val_loss: 0.6790 - val_binary_accuracy: 0.5703\n",
            "Epoch 357/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6672 - binary_accuracy: 0.6060 - val_loss: 0.6791 - val_binary_accuracy: 0.5714\n",
            "Epoch 358/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6672 - binary_accuracy: 0.6066 - val_loss: 0.6791 - val_binary_accuracy: 0.5709\n",
            "Epoch 359/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6671 - binary_accuracy: 0.6062 - val_loss: 0.6790 - val_binary_accuracy: 0.5709\n",
            "Epoch 360/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6671 - binary_accuracy: 0.6065 - val_loss: 0.6790 - val_binary_accuracy: 0.5697\n",
            "Epoch 361/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6671 - binary_accuracy: 0.6056 - val_loss: 0.6790 - val_binary_accuracy: 0.5709\n",
            "Epoch 362/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6670 - binary_accuracy: 0.6063 - val_loss: 0.6790 - val_binary_accuracy: 0.5714\n",
            "Epoch 363/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6670 - binary_accuracy: 0.6053 - val_loss: 0.6790 - val_binary_accuracy: 0.5709\n",
            "Epoch 364/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6670 - binary_accuracy: 0.6059 - val_loss: 0.6790 - val_binary_accuracy: 0.5703\n",
            "Epoch 365/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6670 - binary_accuracy: 0.6063 - val_loss: 0.6790 - val_binary_accuracy: 0.5709\n",
            "Epoch 366/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6669 - binary_accuracy: 0.6054 - val_loss: 0.6790 - val_binary_accuracy: 0.5703\n",
            "Epoch 367/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6669 - binary_accuracy: 0.6056 - val_loss: 0.6790 - val_binary_accuracy: 0.5714\n",
            "Epoch 368/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6669 - binary_accuracy: 0.6053 - val_loss: 0.6790 - val_binary_accuracy: 0.5697\n",
            "Epoch 369/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6669 - binary_accuracy: 0.6057 - val_loss: 0.6790 - val_binary_accuracy: 0.5703\n",
            "Epoch 370/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6669 - binary_accuracy: 0.6067 - val_loss: 0.6790 - val_binary_accuracy: 0.5703\n",
            "Epoch 371/1000\n",
            "6975/6975 [==============================] - 1s 86us/sample - loss: 0.6668 - binary_accuracy: 0.6060 - val_loss: 0.6790 - val_binary_accuracy: 0.5697\n",
            "Epoch 372/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6668 - binary_accuracy: 0.6057 - val_loss: 0.6790 - val_binary_accuracy: 0.5697\n",
            "Epoch 373/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6668 - binary_accuracy: 0.6060 - val_loss: 0.6790 - val_binary_accuracy: 0.5703\n",
            "Epoch 374/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6667 - binary_accuracy: 0.6059 - val_loss: 0.6790 - val_binary_accuracy: 0.5697\n",
            "Epoch 375/1000\n",
            "6975/6975 [==============================] - 0s 66us/sample - loss: 0.6667 - binary_accuracy: 0.6070 - val_loss: 0.6789 - val_binary_accuracy: 0.5726\n",
            "Epoch 376/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6667 - binary_accuracy: 0.6059 - val_loss: 0.6789 - val_binary_accuracy: 0.5714\n",
            "Epoch 377/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6667 - binary_accuracy: 0.6063 - val_loss: 0.6790 - val_binary_accuracy: 0.5703\n",
            "Epoch 378/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6666 - binary_accuracy: 0.6062 - val_loss: 0.6789 - val_binary_accuracy: 0.5703\n",
            "Epoch 379/1000\n",
            "6975/6975 [==============================] - 0s 67us/sample - loss: 0.6666 - binary_accuracy: 0.6069 - val_loss: 0.6789 - val_binary_accuracy: 0.5726\n",
            "Epoch 380/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.6666 - binary_accuracy: 0.6065 - val_loss: 0.6789 - val_binary_accuracy: 0.5703\n",
            "Epoch 381/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6666 - binary_accuracy: 0.6065 - val_loss: 0.6789 - val_binary_accuracy: 0.5709\n",
            "Epoch 382/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6665 - binary_accuracy: 0.6067 - val_loss: 0.6789 - val_binary_accuracy: 0.5703\n",
            "Epoch 383/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6665 - binary_accuracy: 0.6060 - val_loss: 0.6789 - val_binary_accuracy: 0.5731\n",
            "Epoch 384/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6665 - binary_accuracy: 0.6069 - val_loss: 0.6789 - val_binary_accuracy: 0.5720\n",
            "Epoch 385/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6665 - binary_accuracy: 0.6052 - val_loss: 0.6789 - val_binary_accuracy: 0.5709\n",
            "Epoch 386/1000\n",
            "6975/6975 [==============================] - 1s 86us/sample - loss: 0.6664 - binary_accuracy: 0.6067 - val_loss: 0.6789 - val_binary_accuracy: 0.5697\n",
            "Epoch 387/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6664 - binary_accuracy: 0.6067 - val_loss: 0.6790 - val_binary_accuracy: 0.5697\n",
            "Epoch 388/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6664 - binary_accuracy: 0.6063 - val_loss: 0.6790 - val_binary_accuracy: 0.5697\n",
            "Epoch 389/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6664 - binary_accuracy: 0.6060 - val_loss: 0.6789 - val_binary_accuracy: 0.5703\n",
            "Epoch 390/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6664 - binary_accuracy: 0.6072 - val_loss: 0.6789 - val_binary_accuracy: 0.5703\n",
            "Epoch 391/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6663 - binary_accuracy: 0.6060 - val_loss: 0.6789 - val_binary_accuracy: 0.5703\n",
            "Epoch 392/1000\n",
            "6975/6975 [==============================] - 0s 66us/sample - loss: 0.6663 - binary_accuracy: 0.6063 - val_loss: 0.6789 - val_binary_accuracy: 0.5731\n",
            "Epoch 393/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6663 - binary_accuracy: 0.6067 - val_loss: 0.6789 - val_binary_accuracy: 0.5703\n",
            "Epoch 394/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6663 - binary_accuracy: 0.6063 - val_loss: 0.6789 - val_binary_accuracy: 0.5697\n",
            "Epoch 395/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6662 - binary_accuracy: 0.6069 - val_loss: 0.6789 - val_binary_accuracy: 0.5714\n",
            "Epoch 396/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6662 - binary_accuracy: 0.6065 - val_loss: 0.6789 - val_binary_accuracy: 0.5731\n",
            "Epoch 397/1000\n",
            "6975/6975 [==============================] - 1s 88us/sample - loss: 0.6662 - binary_accuracy: 0.6062 - val_loss: 0.6789 - val_binary_accuracy: 0.5709\n",
            "Epoch 398/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6662 - binary_accuracy: 0.6070 - val_loss: 0.6789 - val_binary_accuracy: 0.5726\n",
            "Epoch 399/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6661 - binary_accuracy: 0.6067 - val_loss: 0.6788 - val_binary_accuracy: 0.5737\n",
            "Epoch 400/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6661 - binary_accuracy: 0.6059 - val_loss: 0.6788 - val_binary_accuracy: 0.5743\n",
            "Epoch 401/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6661 - binary_accuracy: 0.6062 - val_loss: 0.6789 - val_binary_accuracy: 0.5731\n",
            "Epoch 402/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6661 - binary_accuracy: 0.6077 - val_loss: 0.6789 - val_binary_accuracy: 0.5726\n",
            "Epoch 403/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6661 - binary_accuracy: 0.6075 - val_loss: 0.6788 - val_binary_accuracy: 0.5743\n",
            "Epoch 404/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6660 - binary_accuracy: 0.6053 - val_loss: 0.6788 - val_binary_accuracy: 0.5743\n",
            "Epoch 405/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6660 - binary_accuracy: 0.6067 - val_loss: 0.6788 - val_binary_accuracy: 0.5737\n",
            "Epoch 406/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6660 - binary_accuracy: 0.6059 - val_loss: 0.6788 - val_binary_accuracy: 0.5743\n",
            "Epoch 407/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6660 - binary_accuracy: 0.6065 - val_loss: 0.6788 - val_binary_accuracy: 0.5743\n",
            "Epoch 408/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6659 - binary_accuracy: 0.6060 - val_loss: 0.6788 - val_binary_accuracy: 0.5749\n",
            "Epoch 409/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6659 - binary_accuracy: 0.6072 - val_loss: 0.6788 - val_binary_accuracy: 0.5737\n",
            "Epoch 410/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6659 - binary_accuracy: 0.6059 - val_loss: 0.6788 - val_binary_accuracy: 0.5714\n",
            "Epoch 411/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6659 - binary_accuracy: 0.6060 - val_loss: 0.6788 - val_binary_accuracy: 0.5737\n",
            "Epoch 412/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6659 - binary_accuracy: 0.6049 - val_loss: 0.6788 - val_binary_accuracy: 0.5720\n",
            "Epoch 413/1000\n",
            "6975/6975 [==============================] - 0s 66us/sample - loss: 0.6658 - binary_accuracy: 0.6072 - val_loss: 0.6788 - val_binary_accuracy: 0.5731\n",
            "Epoch 414/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6658 - binary_accuracy: 0.6067 - val_loss: 0.6788 - val_binary_accuracy: 0.5754\n",
            "Epoch 415/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6658 - binary_accuracy: 0.6079 - val_loss: 0.6788 - val_binary_accuracy: 0.5737\n",
            "Epoch 416/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6658 - binary_accuracy: 0.6065 - val_loss: 0.6787 - val_binary_accuracy: 0.5754\n",
            "Epoch 417/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6657 - binary_accuracy: 0.6066 - val_loss: 0.6788 - val_binary_accuracy: 0.5749\n",
            "Epoch 418/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6657 - binary_accuracy: 0.6060 - val_loss: 0.6787 - val_binary_accuracy: 0.5754\n",
            "Epoch 419/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6657 - binary_accuracy: 0.6069 - val_loss: 0.6787 - val_binary_accuracy: 0.5772\n",
            "Epoch 420/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6657 - binary_accuracy: 0.6077 - val_loss: 0.6788 - val_binary_accuracy: 0.5714\n",
            "Epoch 421/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6657 - binary_accuracy: 0.6060 - val_loss: 0.6788 - val_binary_accuracy: 0.5714\n",
            "Epoch 422/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6656 - binary_accuracy: 0.6065 - val_loss: 0.6787 - val_binary_accuracy: 0.5749\n",
            "Epoch 423/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6656 - binary_accuracy: 0.6066 - val_loss: 0.6787 - val_binary_accuracy: 0.5754\n",
            "Epoch 424/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6656 - binary_accuracy: 0.6060 - val_loss: 0.6787 - val_binary_accuracy: 0.5754\n",
            "Epoch 425/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6656 - binary_accuracy: 0.6077 - val_loss: 0.6788 - val_binary_accuracy: 0.5743\n",
            "Epoch 426/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6656 - binary_accuracy: 0.6063 - val_loss: 0.6788 - val_binary_accuracy: 0.5714\n",
            "Epoch 427/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6655 - binary_accuracy: 0.6072 - val_loss: 0.6788 - val_binary_accuracy: 0.5720\n",
            "Epoch 428/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6655 - binary_accuracy: 0.6063 - val_loss: 0.6788 - val_binary_accuracy: 0.5737\n",
            "Epoch 429/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6655 - binary_accuracy: 0.6065 - val_loss: 0.6787 - val_binary_accuracy: 0.5760\n",
            "Epoch 430/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6655 - binary_accuracy: 0.6066 - val_loss: 0.6788 - val_binary_accuracy: 0.5714\n",
            "Epoch 431/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6655 - binary_accuracy: 0.6060 - val_loss: 0.6788 - val_binary_accuracy: 0.5737\n",
            "Epoch 432/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6654 - binary_accuracy: 0.6066 - val_loss: 0.6787 - val_binary_accuracy: 0.5749\n",
            "Epoch 433/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6654 - binary_accuracy: 0.6063 - val_loss: 0.6787 - val_binary_accuracy: 0.5760\n",
            "Epoch 434/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6654 - binary_accuracy: 0.6077 - val_loss: 0.6787 - val_binary_accuracy: 0.5743\n",
            "Epoch 435/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6654 - binary_accuracy: 0.6065 - val_loss: 0.6787 - val_binary_accuracy: 0.5772\n",
            "Epoch 436/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6654 - binary_accuracy: 0.6063 - val_loss: 0.6787 - val_binary_accuracy: 0.5737\n",
            "Epoch 437/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6653 - binary_accuracy: 0.6072 - val_loss: 0.6787 - val_binary_accuracy: 0.5743\n",
            "Epoch 438/1000\n",
            "6975/6975 [==============================] - 1s 93us/sample - loss: 0.6653 - binary_accuracy: 0.6065 - val_loss: 0.6787 - val_binary_accuracy: 0.5743\n",
            "Epoch 439/1000\n",
            "6975/6975 [==============================] - 0s 65us/sample - loss: 0.6653 - binary_accuracy: 0.6062 - val_loss: 0.6788 - val_binary_accuracy: 0.5737\n",
            "Epoch 440/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6653 - binary_accuracy: 0.6067 - val_loss: 0.6787 - val_binary_accuracy: 0.5743\n",
            "Epoch 441/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6653 - binary_accuracy: 0.6072 - val_loss: 0.6788 - val_binary_accuracy: 0.5720\n",
            "Epoch 442/1000\n",
            "6975/6975 [==============================] - 0s 66us/sample - loss: 0.6652 - binary_accuracy: 0.6069 - val_loss: 0.6787 - val_binary_accuracy: 0.5737\n",
            "Epoch 443/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6652 - binary_accuracy: 0.6054 - val_loss: 0.6787 - val_binary_accuracy: 0.5737\n",
            "Epoch 444/1000\n",
            "6975/6975 [==============================] - 0s 67us/sample - loss: 0.6652 - binary_accuracy: 0.6066 - val_loss: 0.6787 - val_binary_accuracy: 0.5743\n",
            "Epoch 445/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6652 - binary_accuracy: 0.6062 - val_loss: 0.6787 - val_binary_accuracy: 0.5743\n",
            "(6975, 20)\n",
            "(1743, 20)\n",
            "Train on 6975 samples, validate on 1743 samples\n",
            "Epoch 1/1000\n",
            "6975/6975 [==============================] - 1s 127us/sample - loss: 0.7232 - binary_accuracy: 0.4989 - val_loss: 0.7179 - val_binary_accuracy: 0.4986\n",
            "Epoch 2/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.7149 - binary_accuracy: 0.4989 - val_loss: 0.7116 - val_binary_accuracy: 0.4986\n",
            "Epoch 3/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.7094 - binary_accuracy: 0.4989 - val_loss: 0.7073 - val_binary_accuracy: 0.4986\n",
            "Epoch 4/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.7056 - binary_accuracy: 0.4988 - val_loss: 0.7042 - val_binary_accuracy: 0.4986\n",
            "Epoch 5/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.7028 - binary_accuracy: 0.4989 - val_loss: 0.7019 - val_binary_accuracy: 0.4974\n",
            "Epoch 6/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.7007 - binary_accuracy: 0.4982 - val_loss: 0.7002 - val_binary_accuracy: 0.4957\n",
            "Epoch 7/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6991 - binary_accuracy: 0.4968 - val_loss: 0.6988 - val_binary_accuracy: 0.4963\n",
            "Epoch 8/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6979 - binary_accuracy: 0.4971 - val_loss: 0.6977 - val_binary_accuracy: 0.5020\n",
            "Epoch 9/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6969 - binary_accuracy: 0.4966 - val_loss: 0.6969 - val_binary_accuracy: 0.5020\n",
            "Epoch 10/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6961 - binary_accuracy: 0.4963 - val_loss: 0.6962 - val_binary_accuracy: 0.4997\n",
            "Epoch 11/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6954 - binary_accuracy: 0.4939 - val_loss: 0.6957 - val_binary_accuracy: 0.4968\n",
            "Epoch 12/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6950 - binary_accuracy: 0.4975 - val_loss: 0.6952 - val_binary_accuracy: 0.5009\n",
            "Epoch 13/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6946 - binary_accuracy: 0.5005 - val_loss: 0.6949 - val_binary_accuracy: 0.5009\n",
            "Epoch 14/1000\n",
            "6975/6975 [==============================] - 1s 88us/sample - loss: 0.6943 - binary_accuracy: 0.4995 - val_loss: 0.6945 - val_binary_accuracy: 0.4974\n",
            "Epoch 15/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6940 - binary_accuracy: 0.5048 - val_loss: 0.6942 - val_binary_accuracy: 0.5003\n",
            "Epoch 16/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6937 - binary_accuracy: 0.5042 - val_loss: 0.6940 - val_binary_accuracy: 0.5009\n",
            "Epoch 17/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6935 - binary_accuracy: 0.5048 - val_loss: 0.6938 - val_binary_accuracy: 0.4968\n",
            "Epoch 18/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6933 - binary_accuracy: 0.5057 - val_loss: 0.6937 - val_binary_accuracy: 0.4997\n",
            "Epoch 19/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6931 - binary_accuracy: 0.5081 - val_loss: 0.6935 - val_binary_accuracy: 0.5009\n",
            "Epoch 20/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6929 - binary_accuracy: 0.5091 - val_loss: 0.6934 - val_binary_accuracy: 0.4986\n",
            "Epoch 21/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6928 - binary_accuracy: 0.5105 - val_loss: 0.6932 - val_binary_accuracy: 0.4991\n",
            "Epoch 22/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6927 - binary_accuracy: 0.5128 - val_loss: 0.6931 - val_binary_accuracy: 0.5003\n",
            "Epoch 23/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6925 - binary_accuracy: 0.5135 - val_loss: 0.6930 - val_binary_accuracy: 0.4991\n",
            "Epoch 24/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6924 - binary_accuracy: 0.5156 - val_loss: 0.6928 - val_binary_accuracy: 0.5032\n",
            "Epoch 25/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6923 - binary_accuracy: 0.5174 - val_loss: 0.6927 - val_binary_accuracy: 0.5066\n",
            "Epoch 26/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6921 - binary_accuracy: 0.5189 - val_loss: 0.6926 - val_binary_accuracy: 0.5100\n",
            "Epoch 27/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6920 - binary_accuracy: 0.5217 - val_loss: 0.6924 - val_binary_accuracy: 0.5135\n",
            "Epoch 28/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6919 - binary_accuracy: 0.5232 - val_loss: 0.6923 - val_binary_accuracy: 0.5164\n",
            "Epoch 29/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6918 - binary_accuracy: 0.5263 - val_loss: 0.6922 - val_binary_accuracy: 0.5186\n",
            "Epoch 30/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6916 - binary_accuracy: 0.5293 - val_loss: 0.6921 - val_binary_accuracy: 0.5255\n",
            "Epoch 31/1000\n",
            "6975/6975 [==============================] - 1s 83us/sample - loss: 0.6915 - binary_accuracy: 0.5300 - val_loss: 0.6919 - val_binary_accuracy: 0.5250\n",
            "Epoch 32/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.6914 - binary_accuracy: 0.5318 - val_loss: 0.6918 - val_binary_accuracy: 0.5255\n",
            "Epoch 33/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6913 - binary_accuracy: 0.5310 - val_loss: 0.6917 - val_binary_accuracy: 0.5250\n",
            "Epoch 34/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6911 - binary_accuracy: 0.5318 - val_loss: 0.6915 - val_binary_accuracy: 0.5284\n",
            "Epoch 35/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6910 - binary_accuracy: 0.5312 - val_loss: 0.6914 - val_binary_accuracy: 0.5330\n",
            "Epoch 36/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6909 - binary_accuracy: 0.5320 - val_loss: 0.6913 - val_binary_accuracy: 0.5347\n",
            "Epoch 37/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6908 - binary_accuracy: 0.5326 - val_loss: 0.6911 - val_binary_accuracy: 0.5353\n",
            "Epoch 38/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6907 - binary_accuracy: 0.5330 - val_loss: 0.6910 - val_binary_accuracy: 0.5387\n",
            "Epoch 39/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6906 - binary_accuracy: 0.5362 - val_loss: 0.6908 - val_binary_accuracy: 0.5399\n",
            "Epoch 40/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6905 - binary_accuracy: 0.5365 - val_loss: 0.6906 - val_binary_accuracy: 0.5370\n",
            "Epoch 41/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6903 - binary_accuracy: 0.5369 - val_loss: 0.6905 - val_binary_accuracy: 0.5404\n",
            "Epoch 42/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6902 - binary_accuracy: 0.5385 - val_loss: 0.6903 - val_binary_accuracy: 0.5439\n",
            "Epoch 43/1000\n",
            "6975/6975 [==============================] - 0s 65us/sample - loss: 0.6901 - binary_accuracy: 0.5418 - val_loss: 0.6902 - val_binary_accuracy: 0.5433\n",
            "Epoch 44/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6900 - binary_accuracy: 0.5416 - val_loss: 0.6900 - val_binary_accuracy: 0.5468\n",
            "Epoch 45/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6899 - binary_accuracy: 0.5421 - val_loss: 0.6899 - val_binary_accuracy: 0.5502\n",
            "Epoch 46/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6898 - binary_accuracy: 0.5424 - val_loss: 0.6897 - val_binary_accuracy: 0.5525\n",
            "Epoch 47/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6897 - binary_accuracy: 0.5437 - val_loss: 0.6896 - val_binary_accuracy: 0.5548\n",
            "Epoch 48/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6896 - binary_accuracy: 0.5444 - val_loss: 0.6895 - val_binary_accuracy: 0.5577\n",
            "Epoch 49/1000\n",
            "6975/6975 [==============================] - 0s 67us/sample - loss: 0.6895 - binary_accuracy: 0.5472 - val_loss: 0.6893 - val_binary_accuracy: 0.5565\n",
            "Epoch 50/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6894 - binary_accuracy: 0.5471 - val_loss: 0.6892 - val_binary_accuracy: 0.5571\n",
            "Epoch 51/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6893 - binary_accuracy: 0.5472 - val_loss: 0.6891 - val_binary_accuracy: 0.5577\n",
            "Epoch 52/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6892 - binary_accuracy: 0.5478 - val_loss: 0.6889 - val_binary_accuracy: 0.5605\n",
            "Epoch 53/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6891 - binary_accuracy: 0.5482 - val_loss: 0.6888 - val_binary_accuracy: 0.5600\n",
            "Epoch 54/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6890 - binary_accuracy: 0.5508 - val_loss: 0.6887 - val_binary_accuracy: 0.5600\n",
            "Epoch 55/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6889 - binary_accuracy: 0.5504 - val_loss: 0.6885 - val_binary_accuracy: 0.5628\n",
            "Epoch 56/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6888 - binary_accuracy: 0.5518 - val_loss: 0.6884 - val_binary_accuracy: 0.5645\n",
            "Epoch 57/1000\n",
            "6975/6975 [==============================] - 1s 85us/sample - loss: 0.6887 - binary_accuracy: 0.5518 - val_loss: 0.6882 - val_binary_accuracy: 0.5663\n",
            "Epoch 58/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6885 - binary_accuracy: 0.5515 - val_loss: 0.6881 - val_binary_accuracy: 0.5663\n",
            "Epoch 59/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6884 - binary_accuracy: 0.5543 - val_loss: 0.6879 - val_binary_accuracy: 0.5651\n",
            "Epoch 60/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6883 - binary_accuracy: 0.5543 - val_loss: 0.6878 - val_binary_accuracy: 0.5680\n",
            "Epoch 61/1000\n",
            "6975/6975 [==============================] - 1s 85us/sample - loss: 0.6882 - binary_accuracy: 0.5563 - val_loss: 0.6876 - val_binary_accuracy: 0.5691\n",
            "Epoch 62/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6881 - binary_accuracy: 0.5560 - val_loss: 0.6875 - val_binary_accuracy: 0.5697\n",
            "Epoch 63/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6880 - binary_accuracy: 0.5563 - val_loss: 0.6873 - val_binary_accuracy: 0.5686\n",
            "Epoch 64/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6879 - binary_accuracy: 0.5561 - val_loss: 0.6872 - val_binary_accuracy: 0.5697\n",
            "Epoch 65/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6878 - binary_accuracy: 0.5580 - val_loss: 0.6870 - val_binary_accuracy: 0.5703\n",
            "Epoch 66/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6876 - binary_accuracy: 0.5574 - val_loss: 0.6869 - val_binary_accuracy: 0.5714\n",
            "Epoch 67/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6875 - binary_accuracy: 0.5591 - val_loss: 0.6867 - val_binary_accuracy: 0.5714\n",
            "Epoch 68/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6874 - binary_accuracy: 0.5591 - val_loss: 0.6866 - val_binary_accuracy: 0.5737\n",
            "Epoch 69/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6873 - binary_accuracy: 0.5596 - val_loss: 0.6864 - val_binary_accuracy: 0.5731\n",
            "Epoch 70/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6872 - binary_accuracy: 0.5597 - val_loss: 0.6862 - val_binary_accuracy: 0.5720\n",
            "Epoch 71/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6871 - binary_accuracy: 0.5587 - val_loss: 0.6861 - val_binary_accuracy: 0.5726\n",
            "Epoch 72/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6870 - binary_accuracy: 0.5614 - val_loss: 0.6860 - val_binary_accuracy: 0.5731\n",
            "Epoch 73/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6869 - binary_accuracy: 0.5610 - val_loss: 0.6858 - val_binary_accuracy: 0.5743\n",
            "Epoch 74/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6868 - binary_accuracy: 0.5614 - val_loss: 0.6857 - val_binary_accuracy: 0.5749\n",
            "Epoch 75/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6867 - binary_accuracy: 0.5606 - val_loss: 0.6855 - val_binary_accuracy: 0.5754\n",
            "Epoch 76/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6865 - binary_accuracy: 0.5629 - val_loss: 0.6854 - val_binary_accuracy: 0.5754\n",
            "Epoch 77/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6864 - binary_accuracy: 0.5611 - val_loss: 0.6852 - val_binary_accuracy: 0.5783\n",
            "Epoch 78/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6863 - binary_accuracy: 0.5622 - val_loss: 0.6851 - val_binary_accuracy: 0.5777\n",
            "Epoch 79/1000\n",
            "6975/6975 [==============================] - 0s 72us/sample - loss: 0.6862 - binary_accuracy: 0.5627 - val_loss: 0.6850 - val_binary_accuracy: 0.5777\n",
            "Epoch 80/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6861 - binary_accuracy: 0.5632 - val_loss: 0.6848 - val_binary_accuracy: 0.5749\n",
            "Epoch 81/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6860 - binary_accuracy: 0.5639 - val_loss: 0.6847 - val_binary_accuracy: 0.5789\n",
            "Epoch 82/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6859 - binary_accuracy: 0.5647 - val_loss: 0.6845 - val_binary_accuracy: 0.5812\n",
            "Epoch 83/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6857 - binary_accuracy: 0.5650 - val_loss: 0.6844 - val_binary_accuracy: 0.5818\n",
            "Epoch 84/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6856 - binary_accuracy: 0.5657 - val_loss: 0.6842 - val_binary_accuracy: 0.5841\n",
            "Epoch 85/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6855 - binary_accuracy: 0.5663 - val_loss: 0.6841 - val_binary_accuracy: 0.5841\n",
            "Epoch 86/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6854 - binary_accuracy: 0.5672 - val_loss: 0.6839 - val_binary_accuracy: 0.5852\n",
            "Epoch 87/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6853 - binary_accuracy: 0.5663 - val_loss: 0.6838 - val_binary_accuracy: 0.5858\n",
            "Epoch 88/1000\n",
            "6975/6975 [==============================] - 0s 67us/sample - loss: 0.6851 - binary_accuracy: 0.5669 - val_loss: 0.6836 - val_binary_accuracy: 0.5852\n",
            "Epoch 89/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6850 - binary_accuracy: 0.5667 - val_loss: 0.6835 - val_binary_accuracy: 0.5835\n",
            "Epoch 90/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6849 - binary_accuracy: 0.5673 - val_loss: 0.6833 - val_binary_accuracy: 0.5823\n",
            "Epoch 91/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6848 - binary_accuracy: 0.5667 - val_loss: 0.6831 - val_binary_accuracy: 0.5852\n",
            "Epoch 92/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6846 - binary_accuracy: 0.5666 - val_loss: 0.6830 - val_binary_accuracy: 0.5841\n",
            "Epoch 93/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6845 - binary_accuracy: 0.5670 - val_loss: 0.6828 - val_binary_accuracy: 0.5852\n",
            "Epoch 94/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6844 - binary_accuracy: 0.5692 - val_loss: 0.6827 - val_binary_accuracy: 0.5863\n",
            "Epoch 95/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6843 - binary_accuracy: 0.5695 - val_loss: 0.6825 - val_binary_accuracy: 0.5846\n",
            "Epoch 96/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6841 - binary_accuracy: 0.5690 - val_loss: 0.6824 - val_binary_accuracy: 0.5858\n",
            "Epoch 97/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6840 - binary_accuracy: 0.5697 - val_loss: 0.6822 - val_binary_accuracy: 0.5858\n",
            "Epoch 98/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6839 - binary_accuracy: 0.5692 - val_loss: 0.6821 - val_binary_accuracy: 0.5875\n",
            "Epoch 99/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6837 - binary_accuracy: 0.5703 - val_loss: 0.6819 - val_binary_accuracy: 0.5863\n",
            "Epoch 100/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6836 - binary_accuracy: 0.5713 - val_loss: 0.6818 - val_binary_accuracy: 0.5886\n",
            "Epoch 101/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6835 - binary_accuracy: 0.5705 - val_loss: 0.6817 - val_binary_accuracy: 0.5892\n",
            "Epoch 102/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6834 - binary_accuracy: 0.5708 - val_loss: 0.6815 - val_binary_accuracy: 0.5915\n",
            "Epoch 103/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6832 - binary_accuracy: 0.5706 - val_loss: 0.6813 - val_binary_accuracy: 0.5915\n",
            "Epoch 104/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6831 - binary_accuracy: 0.5722 - val_loss: 0.6812 - val_binary_accuracy: 0.5909\n",
            "Epoch 105/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6830 - binary_accuracy: 0.5718 - val_loss: 0.6810 - val_binary_accuracy: 0.5909\n",
            "Epoch 106/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6828 - binary_accuracy: 0.5729 - val_loss: 0.6808 - val_binary_accuracy: 0.5915\n",
            "Epoch 107/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6827 - binary_accuracy: 0.5712 - val_loss: 0.6806 - val_binary_accuracy: 0.5938\n",
            "Epoch 108/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6826 - binary_accuracy: 0.5712 - val_loss: 0.6804 - val_binary_accuracy: 0.5904\n",
            "Epoch 109/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6824 - binary_accuracy: 0.5726 - val_loss: 0.6803 - val_binary_accuracy: 0.5898\n",
            "Epoch 110/1000\n",
            "6975/6975 [==============================] - 1s 84us/sample - loss: 0.6823 - binary_accuracy: 0.5720 - val_loss: 0.6801 - val_binary_accuracy: 0.5909\n",
            "Epoch 111/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6821 - binary_accuracy: 0.5729 - val_loss: 0.6799 - val_binary_accuracy: 0.5921\n",
            "Epoch 112/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6820 - binary_accuracy: 0.5738 - val_loss: 0.6798 - val_binary_accuracy: 0.5921\n",
            "Epoch 113/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6818 - binary_accuracy: 0.5739 - val_loss: 0.6796 - val_binary_accuracy: 0.5927\n",
            "Epoch 114/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6817 - binary_accuracy: 0.5743 - val_loss: 0.6794 - val_binary_accuracy: 0.5944\n",
            "Epoch 115/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6815 - binary_accuracy: 0.5739 - val_loss: 0.6793 - val_binary_accuracy: 0.5961\n",
            "Epoch 116/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6814 - binary_accuracy: 0.5751 - val_loss: 0.6791 - val_binary_accuracy: 0.5944\n",
            "Epoch 117/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6813 - binary_accuracy: 0.5768 - val_loss: 0.6790 - val_binary_accuracy: 0.5955\n",
            "Epoch 118/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6811 - binary_accuracy: 0.5779 - val_loss: 0.6788 - val_binary_accuracy: 0.5950\n",
            "Epoch 119/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6809 - binary_accuracy: 0.5784 - val_loss: 0.6787 - val_binary_accuracy: 0.5955\n",
            "Epoch 120/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6808 - binary_accuracy: 0.5785 - val_loss: 0.6785 - val_binary_accuracy: 0.5955\n",
            "Epoch 121/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6806 - binary_accuracy: 0.5771 - val_loss: 0.6784 - val_binary_accuracy: 0.5950\n",
            "Epoch 122/1000\n",
            "6975/6975 [==============================] - 0s 72us/sample - loss: 0.6805 - binary_accuracy: 0.5795 - val_loss: 0.6782 - val_binary_accuracy: 0.5955\n",
            "Epoch 123/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6804 - binary_accuracy: 0.5801 - val_loss: 0.6781 - val_binary_accuracy: 0.5972\n",
            "Epoch 124/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6802 - binary_accuracy: 0.5806 - val_loss: 0.6780 - val_binary_accuracy: 0.5972\n",
            "Epoch 125/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6801 - binary_accuracy: 0.5799 - val_loss: 0.6778 - val_binary_accuracy: 0.5978\n",
            "Epoch 126/1000\n",
            "6975/6975 [==============================] - 0s 67us/sample - loss: 0.6799 - binary_accuracy: 0.5805 - val_loss: 0.6777 - val_binary_accuracy: 0.5984\n",
            "Epoch 127/1000\n",
            "6975/6975 [==============================] - 0s 72us/sample - loss: 0.6798 - binary_accuracy: 0.5816 - val_loss: 0.6776 - val_binary_accuracy: 0.5984\n",
            "Epoch 128/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6797 - binary_accuracy: 0.5829 - val_loss: 0.6775 - val_binary_accuracy: 0.5955\n",
            "Epoch 129/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6796 - binary_accuracy: 0.5827 - val_loss: 0.6774 - val_binary_accuracy: 0.5944\n",
            "Epoch 130/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6794 - binary_accuracy: 0.5839 - val_loss: 0.6773 - val_binary_accuracy: 0.5944\n",
            "Epoch 131/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6793 - binary_accuracy: 0.5839 - val_loss: 0.6771 - val_binary_accuracy: 0.5950\n",
            "Epoch 132/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6792 - binary_accuracy: 0.5838 - val_loss: 0.6770 - val_binary_accuracy: 0.5944\n",
            "Epoch 133/1000\n",
            "6975/6975 [==============================] - 1s 86us/sample - loss: 0.6791 - binary_accuracy: 0.5845 - val_loss: 0.6769 - val_binary_accuracy: 0.5950\n",
            "Epoch 134/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6790 - binary_accuracy: 0.5848 - val_loss: 0.6768 - val_binary_accuracy: 0.5944\n",
            "Epoch 135/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6789 - binary_accuracy: 0.5847 - val_loss: 0.6767 - val_binary_accuracy: 0.5944\n",
            "Epoch 136/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6787 - binary_accuracy: 0.5841 - val_loss: 0.6766 - val_binary_accuracy: 0.5950\n",
            "Epoch 137/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.6786 - binary_accuracy: 0.5842 - val_loss: 0.6765 - val_binary_accuracy: 0.5950\n",
            "Epoch 138/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6785 - binary_accuracy: 0.5851 - val_loss: 0.6763 - val_binary_accuracy: 0.5950\n",
            "Epoch 139/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6784 - binary_accuracy: 0.5849 - val_loss: 0.6763 - val_binary_accuracy: 0.5938\n",
            "Epoch 140/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6783 - binary_accuracy: 0.5839 - val_loss: 0.6761 - val_binary_accuracy: 0.5932\n",
            "Epoch 141/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6782 - binary_accuracy: 0.5857 - val_loss: 0.6760 - val_binary_accuracy: 0.5944\n",
            "Epoch 142/1000\n",
            "6975/6975 [==============================] - 1s 89us/sample - loss: 0.6781 - binary_accuracy: 0.5858 - val_loss: 0.6759 - val_binary_accuracy: 0.5961\n",
            "Epoch 143/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6779 - binary_accuracy: 0.5854 - val_loss: 0.6758 - val_binary_accuracy: 0.5961\n",
            "Epoch 144/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6778 - binary_accuracy: 0.5858 - val_loss: 0.6757 - val_binary_accuracy: 0.5972\n",
            "Epoch 145/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6777 - binary_accuracy: 0.5857 - val_loss: 0.6756 - val_binary_accuracy: 0.5972\n",
            "Epoch 146/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6776 - binary_accuracy: 0.5855 - val_loss: 0.6755 - val_binary_accuracy: 0.5967\n",
            "Epoch 147/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6775 - binary_accuracy: 0.5864 - val_loss: 0.6754 - val_binary_accuracy: 0.5967\n",
            "Epoch 148/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6774 - binary_accuracy: 0.5867 - val_loss: 0.6753 - val_binary_accuracy: 0.5978\n",
            "Epoch 149/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6773 - binary_accuracy: 0.5867 - val_loss: 0.6752 - val_binary_accuracy: 0.5978\n",
            "Epoch 150/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6772 - binary_accuracy: 0.5880 - val_loss: 0.6751 - val_binary_accuracy: 0.5990\n",
            "Epoch 151/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6771 - binary_accuracy: 0.5872 - val_loss: 0.6750 - val_binary_accuracy: 0.5984\n",
            "Epoch 152/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6770 - binary_accuracy: 0.5851 - val_loss: 0.6749 - val_binary_accuracy: 0.5978\n",
            "Epoch 153/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6769 - binary_accuracy: 0.5855 - val_loss: 0.6748 - val_binary_accuracy: 0.5978\n",
            "Epoch 154/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6768 - binary_accuracy: 0.5855 - val_loss: 0.6747 - val_binary_accuracy: 0.5967\n",
            "Epoch 155/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6767 - binary_accuracy: 0.5859 - val_loss: 0.6746 - val_binary_accuracy: 0.5990\n",
            "Epoch 156/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6766 - binary_accuracy: 0.5861 - val_loss: 0.6745 - val_binary_accuracy: 0.5984\n",
            "Epoch 157/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6765 - binary_accuracy: 0.5882 - val_loss: 0.6744 - val_binary_accuracy: 0.5990\n",
            "Epoch 158/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6764 - binary_accuracy: 0.5871 - val_loss: 0.6743 - val_binary_accuracy: 0.5990\n",
            "Epoch 159/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6763 - binary_accuracy: 0.5868 - val_loss: 0.6742 - val_binary_accuracy: 0.5984\n",
            "Epoch 160/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6762 - binary_accuracy: 0.5882 - val_loss: 0.6741 - val_binary_accuracy: 0.5978\n",
            "Epoch 161/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6761 - binary_accuracy: 0.5875 - val_loss: 0.6740 - val_binary_accuracy: 0.5978\n",
            "Epoch 162/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6760 - binary_accuracy: 0.5867 - val_loss: 0.6740 - val_binary_accuracy: 0.5990\n",
            "Epoch 163/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6759 - binary_accuracy: 0.5877 - val_loss: 0.6739 - val_binary_accuracy: 0.5990\n",
            "Epoch 164/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6758 - binary_accuracy: 0.5872 - val_loss: 0.6738 - val_binary_accuracy: 0.5990\n",
            "Epoch 165/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6757 - binary_accuracy: 0.5880 - val_loss: 0.6737 - val_binary_accuracy: 0.5984\n",
            "Epoch 166/1000\n",
            "6975/6975 [==============================] - 1s 88us/sample - loss: 0.6756 - binary_accuracy: 0.5881 - val_loss: 0.6735 - val_binary_accuracy: 0.5972\n",
            "Epoch 167/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6755 - binary_accuracy: 0.5887 - val_loss: 0.6735 - val_binary_accuracy: 0.5978\n",
            "Epoch 168/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6754 - binary_accuracy: 0.5881 - val_loss: 0.6733 - val_binary_accuracy: 0.5978\n",
            "Epoch 169/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6753 - binary_accuracy: 0.5888 - val_loss: 0.6732 - val_binary_accuracy: 0.5972\n",
            "Epoch 170/1000\n",
            "6975/6975 [==============================] - 1s 96us/sample - loss: 0.6752 - binary_accuracy: 0.5891 - val_loss: 0.6731 - val_binary_accuracy: 0.5972\n",
            "Epoch 171/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6751 - binary_accuracy: 0.5885 - val_loss: 0.6731 - val_binary_accuracy: 0.5978\n",
            "Epoch 172/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6750 - binary_accuracy: 0.5874 - val_loss: 0.6730 - val_binary_accuracy: 0.5972\n",
            "Epoch 173/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6749 - binary_accuracy: 0.5891 - val_loss: 0.6729 - val_binary_accuracy: 0.5990\n",
            "Epoch 174/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6748 - binary_accuracy: 0.5881 - val_loss: 0.6728 - val_binary_accuracy: 0.5967\n",
            "Epoch 175/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6747 - binary_accuracy: 0.5884 - val_loss: 0.6727 - val_binary_accuracy: 0.5978\n",
            "Epoch 176/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6746 - binary_accuracy: 0.5877 - val_loss: 0.6726 - val_binary_accuracy: 0.5990\n",
            "Epoch 177/1000\n",
            "6975/6975 [==============================] - 1s 87us/sample - loss: 0.6745 - binary_accuracy: 0.5884 - val_loss: 0.6725 - val_binary_accuracy: 0.5984\n",
            "Epoch 178/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6744 - binary_accuracy: 0.5900 - val_loss: 0.6724 - val_binary_accuracy: 0.5967\n",
            "Epoch 179/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6744 - binary_accuracy: 0.5892 - val_loss: 0.6723 - val_binary_accuracy: 0.5972\n",
            "Epoch 180/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6743 - binary_accuracy: 0.5890 - val_loss: 0.6722 - val_binary_accuracy: 0.5978\n",
            "Epoch 181/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6742 - binary_accuracy: 0.5890 - val_loss: 0.6721 - val_binary_accuracy: 0.5972\n",
            "Epoch 182/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6741 - binary_accuracy: 0.5897 - val_loss: 0.6720 - val_binary_accuracy: 0.5978\n",
            "Epoch 183/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6740 - binary_accuracy: 0.5891 - val_loss: 0.6720 - val_binary_accuracy: 0.5978\n",
            "Epoch 184/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6739 - binary_accuracy: 0.5891 - val_loss: 0.6719 - val_binary_accuracy: 0.5984\n",
            "Epoch 185/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6738 - binary_accuracy: 0.5897 - val_loss: 0.6718 - val_binary_accuracy: 0.5967\n",
            "Epoch 186/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6738 - binary_accuracy: 0.5891 - val_loss: 0.6717 - val_binary_accuracy: 0.5978\n",
            "Epoch 187/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6737 - binary_accuracy: 0.5888 - val_loss: 0.6716 - val_binary_accuracy: 0.5984\n",
            "Epoch 188/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6736 - binary_accuracy: 0.5891 - val_loss: 0.6716 - val_binary_accuracy: 0.5961\n",
            "Epoch 189/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6735 - binary_accuracy: 0.5887 - val_loss: 0.6715 - val_binary_accuracy: 0.5967\n",
            "Epoch 190/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6734 - binary_accuracy: 0.5884 - val_loss: 0.6714 - val_binary_accuracy: 0.5967\n",
            "Epoch 191/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6733 - binary_accuracy: 0.5878 - val_loss: 0.6713 - val_binary_accuracy: 0.5972\n",
            "Epoch 192/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6732 - binary_accuracy: 0.5903 - val_loss: 0.6713 - val_binary_accuracy: 0.5955\n",
            "Epoch 193/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6732 - binary_accuracy: 0.5897 - val_loss: 0.6712 - val_binary_accuracy: 0.5967\n",
            "Epoch 194/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6731 - binary_accuracy: 0.5894 - val_loss: 0.6711 - val_binary_accuracy: 0.5972\n",
            "Epoch 195/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6730 - binary_accuracy: 0.5903 - val_loss: 0.6710 - val_binary_accuracy: 0.5955\n",
            "Epoch 196/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6729 - binary_accuracy: 0.5892 - val_loss: 0.6710 - val_binary_accuracy: 0.5967\n",
            "Epoch 197/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6728 - binary_accuracy: 0.5913 - val_loss: 0.6709 - val_binary_accuracy: 0.5938\n",
            "Epoch 198/1000\n",
            "6975/6975 [==============================] - 1s 94us/sample - loss: 0.6727 - binary_accuracy: 0.5908 - val_loss: 0.6708 - val_binary_accuracy: 0.5955\n",
            "Epoch 199/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6727 - binary_accuracy: 0.5913 - val_loss: 0.6708 - val_binary_accuracy: 0.5950\n",
            "Epoch 200/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6726 - binary_accuracy: 0.5905 - val_loss: 0.6707 - val_binary_accuracy: 0.5950\n",
            "Epoch 201/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6725 - binary_accuracy: 0.5921 - val_loss: 0.6706 - val_binary_accuracy: 0.5938\n",
            "Epoch 202/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6724 - binary_accuracy: 0.5918 - val_loss: 0.6705 - val_binary_accuracy: 0.5944\n",
            "Epoch 203/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6724 - binary_accuracy: 0.5915 - val_loss: 0.6705 - val_binary_accuracy: 0.5938\n",
            "Epoch 204/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6723 - binary_accuracy: 0.5921 - val_loss: 0.6704 - val_binary_accuracy: 0.5944\n",
            "Epoch 205/1000\n",
            "6975/6975 [==============================] - 1s 85us/sample - loss: 0.6722 - binary_accuracy: 0.5928 - val_loss: 0.6703 - val_binary_accuracy: 0.5944\n",
            "Epoch 206/1000\n",
            "6975/6975 [==============================] - 1s 88us/sample - loss: 0.6721 - binary_accuracy: 0.5937 - val_loss: 0.6703 - val_binary_accuracy: 0.5961\n",
            "Epoch 207/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6721 - binary_accuracy: 0.5935 - val_loss: 0.6702 - val_binary_accuracy: 0.5944\n",
            "Epoch 208/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6720 - binary_accuracy: 0.5928 - val_loss: 0.6701 - val_binary_accuracy: 0.5955\n",
            "Epoch 209/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6719 - binary_accuracy: 0.5935 - val_loss: 0.6701 - val_binary_accuracy: 0.5955\n",
            "Epoch 210/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6718 - binary_accuracy: 0.5937 - val_loss: 0.6700 - val_binary_accuracy: 0.5950\n",
            "Epoch 211/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6718 - binary_accuracy: 0.5930 - val_loss: 0.6699 - val_binary_accuracy: 0.5967\n",
            "Epoch 212/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6717 - binary_accuracy: 0.5935 - val_loss: 0.6699 - val_binary_accuracy: 0.5961\n",
            "Epoch 213/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6716 - binary_accuracy: 0.5930 - val_loss: 0.6698 - val_binary_accuracy: 0.5961\n",
            "Epoch 214/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6715 - binary_accuracy: 0.5941 - val_loss: 0.6698 - val_binary_accuracy: 0.5967\n",
            "Epoch 215/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6715 - binary_accuracy: 0.5941 - val_loss: 0.6697 - val_binary_accuracy: 0.5972\n",
            "Epoch 216/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6714 - binary_accuracy: 0.5951 - val_loss: 0.6697 - val_binary_accuracy: 0.5967\n",
            "Epoch 217/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6713 - binary_accuracy: 0.5944 - val_loss: 0.6696 - val_binary_accuracy: 0.5961\n",
            "Epoch 218/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6713 - binary_accuracy: 0.5948 - val_loss: 0.6695 - val_binary_accuracy: 0.5961\n",
            "Epoch 219/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6712 - binary_accuracy: 0.5946 - val_loss: 0.6695 - val_binary_accuracy: 0.5967\n",
            "Epoch 220/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6711 - binary_accuracy: 0.5956 - val_loss: 0.6694 - val_binary_accuracy: 0.5961\n",
            "Epoch 221/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6711 - binary_accuracy: 0.5946 - val_loss: 0.6694 - val_binary_accuracy: 0.5955\n",
            "Epoch 222/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6710 - binary_accuracy: 0.5957 - val_loss: 0.6693 - val_binary_accuracy: 0.5955\n",
            "Epoch 223/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6709 - binary_accuracy: 0.5960 - val_loss: 0.6693 - val_binary_accuracy: 0.5950\n",
            "Epoch 224/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6709 - binary_accuracy: 0.5953 - val_loss: 0.6692 - val_binary_accuracy: 0.5950\n",
            "Epoch 225/1000\n",
            "6975/6975 [==============================] - 0s 72us/sample - loss: 0.6708 - binary_accuracy: 0.5961 - val_loss: 0.6692 - val_binary_accuracy: 0.5950\n",
            "Epoch 226/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6708 - binary_accuracy: 0.5957 - val_loss: 0.6691 - val_binary_accuracy: 0.5961\n",
            "Epoch 227/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6707 - binary_accuracy: 0.5953 - val_loss: 0.6691 - val_binary_accuracy: 0.5944\n",
            "Epoch 228/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6706 - binary_accuracy: 0.5963 - val_loss: 0.6690 - val_binary_accuracy: 0.5955\n",
            "Epoch 229/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6706 - binary_accuracy: 0.5956 - val_loss: 0.6689 - val_binary_accuracy: 0.5950\n",
            "Epoch 230/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6705 - binary_accuracy: 0.5961 - val_loss: 0.6689 - val_binary_accuracy: 0.5938\n",
            "Epoch 231/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6704 - binary_accuracy: 0.5966 - val_loss: 0.6688 - val_binary_accuracy: 0.5955\n",
            "Epoch 232/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6704 - binary_accuracy: 0.5951 - val_loss: 0.6688 - val_binary_accuracy: 0.5944\n",
            "Epoch 233/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6703 - binary_accuracy: 0.5956 - val_loss: 0.6687 - val_binary_accuracy: 0.5944\n",
            "Epoch 234/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6703 - binary_accuracy: 0.5954 - val_loss: 0.6687 - val_binary_accuracy: 0.5950\n",
            "Epoch 235/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6702 - binary_accuracy: 0.5951 - val_loss: 0.6686 - val_binary_accuracy: 0.5961\n",
            "Epoch 236/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6702 - binary_accuracy: 0.5941 - val_loss: 0.6686 - val_binary_accuracy: 0.5950\n",
            "Epoch 237/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6701 - binary_accuracy: 0.5951 - val_loss: 0.6685 - val_binary_accuracy: 0.5950\n",
            "Epoch 238/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6700 - binary_accuracy: 0.5963 - val_loss: 0.6685 - val_binary_accuracy: 0.5955\n",
            "Epoch 239/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6700 - binary_accuracy: 0.5960 - val_loss: 0.6684 - val_binary_accuracy: 0.5955\n",
            "Epoch 240/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6699 - binary_accuracy: 0.5957 - val_loss: 0.6684 - val_binary_accuracy: 0.5961\n",
            "Epoch 241/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6699 - binary_accuracy: 0.5948 - val_loss: 0.6684 - val_binary_accuracy: 0.5961\n",
            "Epoch 242/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6698 - binary_accuracy: 0.5956 - val_loss: 0.6683 - val_binary_accuracy: 0.5955\n",
            "Epoch 243/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6698 - binary_accuracy: 0.5954 - val_loss: 0.6683 - val_binary_accuracy: 0.5967\n",
            "Epoch 244/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6697 - binary_accuracy: 0.5951 - val_loss: 0.6682 - val_binary_accuracy: 0.5961\n",
            "Epoch 245/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6697 - binary_accuracy: 0.5963 - val_loss: 0.6682 - val_binary_accuracy: 0.5961\n",
            "Epoch 246/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6696 - binary_accuracy: 0.5951 - val_loss: 0.6681 - val_binary_accuracy: 0.5961\n",
            "Epoch 247/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6696 - binary_accuracy: 0.5948 - val_loss: 0.6681 - val_binary_accuracy: 0.5972\n",
            "Epoch 248/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6695 - binary_accuracy: 0.5951 - val_loss: 0.6681 - val_binary_accuracy: 0.5978\n",
            "Epoch 249/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6695 - binary_accuracy: 0.5958 - val_loss: 0.6680 - val_binary_accuracy: 0.5978\n",
            "Epoch 250/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6694 - binary_accuracy: 0.5960 - val_loss: 0.6680 - val_binary_accuracy: 0.5978\n",
            "Epoch 251/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6694 - binary_accuracy: 0.5951 - val_loss: 0.6679 - val_binary_accuracy: 0.5984\n",
            "Epoch 252/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6693 - binary_accuracy: 0.5958 - val_loss: 0.6679 - val_binary_accuracy: 0.5978\n",
            "Epoch 253/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6693 - binary_accuracy: 0.5951 - val_loss: 0.6679 - val_binary_accuracy: 0.5978\n",
            "Epoch 254/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6692 - binary_accuracy: 0.5951 - val_loss: 0.6679 - val_binary_accuracy: 0.5978\n",
            "Epoch 255/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6692 - binary_accuracy: 0.5960 - val_loss: 0.6678 - val_binary_accuracy: 0.5984\n",
            "Epoch 256/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6691 - binary_accuracy: 0.5956 - val_loss: 0.6678 - val_binary_accuracy: 0.5984\n",
            "Epoch 257/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6691 - binary_accuracy: 0.5960 - val_loss: 0.6677 - val_binary_accuracy: 0.5978\n",
            "Epoch 258/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6690 - binary_accuracy: 0.5964 - val_loss: 0.6677 - val_binary_accuracy: 0.5984\n",
            "Epoch 259/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6690 - binary_accuracy: 0.5960 - val_loss: 0.6677 - val_binary_accuracy: 0.5984\n",
            "Epoch 260/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6689 - binary_accuracy: 0.5964 - val_loss: 0.6676 - val_binary_accuracy: 0.5972\n",
            "Epoch 261/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6689 - binary_accuracy: 0.5968 - val_loss: 0.6676 - val_binary_accuracy: 0.5978\n",
            "Epoch 262/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6688 - binary_accuracy: 0.5951 - val_loss: 0.6675 - val_binary_accuracy: 0.5984\n",
            "Epoch 263/1000\n",
            "6975/6975 [==============================] - 0s 72us/sample - loss: 0.6688 - binary_accuracy: 0.5978 - val_loss: 0.6675 - val_binary_accuracy: 0.5978\n",
            "Epoch 264/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6687 - binary_accuracy: 0.5963 - val_loss: 0.6675 - val_binary_accuracy: 0.5972\n",
            "Epoch 265/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6687 - binary_accuracy: 0.5941 - val_loss: 0.6674 - val_binary_accuracy: 0.5984\n",
            "Epoch 266/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6686 - binary_accuracy: 0.5971 - val_loss: 0.6674 - val_binary_accuracy: 0.5967\n",
            "Epoch 267/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6686 - binary_accuracy: 0.5953 - val_loss: 0.6674 - val_binary_accuracy: 0.5961\n",
            "Epoch 268/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6685 - binary_accuracy: 0.5961 - val_loss: 0.6674 - val_binary_accuracy: 0.5967\n",
            "Epoch 269/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6685 - binary_accuracy: 0.5970 - val_loss: 0.6674 - val_binary_accuracy: 0.5967\n",
            "Epoch 270/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6684 - binary_accuracy: 0.5966 - val_loss: 0.6673 - val_binary_accuracy: 0.5961\n",
            "Epoch 271/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6684 - binary_accuracy: 0.5966 - val_loss: 0.6673 - val_binary_accuracy: 0.5961\n",
            "Epoch 272/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6683 - binary_accuracy: 0.5970 - val_loss: 0.6672 - val_binary_accuracy: 0.5967\n",
            "Epoch 273/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6683 - binary_accuracy: 0.5966 - val_loss: 0.6672 - val_binary_accuracy: 0.5967\n",
            "Epoch 274/1000\n",
            "6975/6975 [==============================] - 1s 85us/sample - loss: 0.6683 - binary_accuracy: 0.5974 - val_loss: 0.6672 - val_binary_accuracy: 0.5972\n",
            "Epoch 275/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6682 - binary_accuracy: 0.5973 - val_loss: 0.6672 - val_binary_accuracy: 0.5967\n",
            "Epoch 276/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6682 - binary_accuracy: 0.5964 - val_loss: 0.6671 - val_binary_accuracy: 0.5978\n",
            "Epoch 277/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6681 - binary_accuracy: 0.5971 - val_loss: 0.6671 - val_binary_accuracy: 0.5967\n",
            "Epoch 278/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6681 - binary_accuracy: 0.5980 - val_loss: 0.6671 - val_binary_accuracy: 0.5978\n",
            "Epoch 279/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6680 - binary_accuracy: 0.5976 - val_loss: 0.6671 - val_binary_accuracy: 0.6001\n",
            "Epoch 280/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6680 - binary_accuracy: 0.5966 - val_loss: 0.6670 - val_binary_accuracy: 0.5978\n",
            "Epoch 281/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6680 - binary_accuracy: 0.5964 - val_loss: 0.6670 - val_binary_accuracy: 0.5978\n",
            "Epoch 282/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6679 - binary_accuracy: 0.5966 - val_loss: 0.6669 - val_binary_accuracy: 0.5972\n",
            "Epoch 283/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6679 - binary_accuracy: 0.5971 - val_loss: 0.6669 - val_binary_accuracy: 0.5984\n",
            "Epoch 284/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6678 - binary_accuracy: 0.5970 - val_loss: 0.6669 - val_binary_accuracy: 0.5978\n",
            "Epoch 285/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6678 - binary_accuracy: 0.5977 - val_loss: 0.6669 - val_binary_accuracy: 0.5995\n",
            "Epoch 286/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6678 - binary_accuracy: 0.5970 - val_loss: 0.6668 - val_binary_accuracy: 0.5995\n",
            "Epoch 287/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6677 - binary_accuracy: 0.5968 - val_loss: 0.6668 - val_binary_accuracy: 0.5984\n",
            "Epoch 288/1000\n",
            "6975/6975 [==============================] - 0s 67us/sample - loss: 0.6677 - binary_accuracy: 0.5986 - val_loss: 0.6668 - val_binary_accuracy: 0.5984\n",
            "Epoch 289/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6676 - binary_accuracy: 0.5973 - val_loss: 0.6667 - val_binary_accuracy: 0.5984\n",
            "Epoch 290/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6676 - binary_accuracy: 0.5977 - val_loss: 0.6667 - val_binary_accuracy: 0.5978\n",
            "Epoch 291/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6676 - binary_accuracy: 0.5981 - val_loss: 0.6667 - val_binary_accuracy: 0.5972\n",
            "Epoch 292/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6675 - binary_accuracy: 0.5980 - val_loss: 0.6667 - val_binary_accuracy: 0.5990\n",
            "Epoch 293/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6675 - binary_accuracy: 0.5984 - val_loss: 0.6667 - val_binary_accuracy: 0.5990\n",
            "Epoch 294/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6675 - binary_accuracy: 0.5977 - val_loss: 0.6667 - val_binary_accuracy: 0.5984\n",
            "Epoch 295/1000\n",
            "6975/6975 [==============================] - 1s 87us/sample - loss: 0.6674 - binary_accuracy: 0.5981 - val_loss: 0.6666 - val_binary_accuracy: 0.5995\n",
            "Epoch 296/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6674 - binary_accuracy: 0.5974 - val_loss: 0.6666 - val_binary_accuracy: 0.5990\n",
            "Epoch 297/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6673 - binary_accuracy: 0.5973 - val_loss: 0.6665 - val_binary_accuracy: 0.5990\n",
            "Epoch 298/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6673 - binary_accuracy: 0.5983 - val_loss: 0.6666 - val_binary_accuracy: 0.6007\n",
            "Epoch 299/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6673 - binary_accuracy: 0.5974 - val_loss: 0.6665 - val_binary_accuracy: 0.5995\n",
            "Epoch 300/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6672 - binary_accuracy: 0.5981 - val_loss: 0.6665 - val_binary_accuracy: 0.5984\n",
            "Epoch 301/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6672 - binary_accuracy: 0.5980 - val_loss: 0.6665 - val_binary_accuracy: 0.5990\n",
            "Epoch 302/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6672 - binary_accuracy: 0.5997 - val_loss: 0.6665 - val_binary_accuracy: 0.5990\n",
            "Epoch 303/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6671 - binary_accuracy: 0.5989 - val_loss: 0.6665 - val_binary_accuracy: 0.5990\n",
            "Epoch 304/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6671 - binary_accuracy: 0.6001 - val_loss: 0.6664 - val_binary_accuracy: 0.5990\n",
            "Epoch 305/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6671 - binary_accuracy: 0.5990 - val_loss: 0.6664 - val_binary_accuracy: 0.5995\n",
            "Epoch 306/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6670 - binary_accuracy: 0.5987 - val_loss: 0.6663 - val_binary_accuracy: 0.5984\n",
            "Epoch 307/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6670 - binary_accuracy: 0.5974 - val_loss: 0.6663 - val_binary_accuracy: 0.5984\n",
            "Epoch 308/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6670 - binary_accuracy: 0.5984 - val_loss: 0.6663 - val_binary_accuracy: 0.5984\n",
            "Epoch 309/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6669 - binary_accuracy: 0.5994 - val_loss: 0.6663 - val_binary_accuracy: 0.5978\n",
            "Epoch 310/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6669 - binary_accuracy: 0.5990 - val_loss: 0.6662 - val_binary_accuracy: 0.5978\n",
            "Epoch 311/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6669 - binary_accuracy: 0.5989 - val_loss: 0.6662 - val_binary_accuracy: 0.5972\n",
            "Epoch 312/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6668 - binary_accuracy: 0.5986 - val_loss: 0.6662 - val_binary_accuracy: 0.5972\n",
            "Epoch 313/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6668 - binary_accuracy: 0.5993 - val_loss: 0.6661 - val_binary_accuracy: 0.5978\n",
            "Epoch 314/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6668 - binary_accuracy: 0.5999 - val_loss: 0.6662 - val_binary_accuracy: 0.5984\n",
            "Epoch 315/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6667 - binary_accuracy: 0.6006 - val_loss: 0.6662 - val_binary_accuracy: 0.5978\n",
            "Epoch 316/1000\n",
            "6975/6975 [==============================] - 0s 67us/sample - loss: 0.6667 - binary_accuracy: 0.5994 - val_loss: 0.6662 - val_binary_accuracy: 0.5984\n",
            "Epoch 317/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6667 - binary_accuracy: 0.5997 - val_loss: 0.6661 - val_binary_accuracy: 0.5978\n",
            "Epoch 318/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6666 - binary_accuracy: 0.5999 - val_loss: 0.6661 - val_binary_accuracy: 0.5978\n",
            "Epoch 319/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6666 - binary_accuracy: 0.5989 - val_loss: 0.6661 - val_binary_accuracy: 0.5984\n",
            "Epoch 320/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6666 - binary_accuracy: 0.5994 - val_loss: 0.6661 - val_binary_accuracy: 0.5990\n",
            "Epoch 321/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6666 - binary_accuracy: 0.6011 - val_loss: 0.6660 - val_binary_accuracy: 0.5990\n",
            "Epoch 322/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6665 - binary_accuracy: 0.6001 - val_loss: 0.6660 - val_binary_accuracy: 0.5972\n",
            "Epoch 323/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6665 - binary_accuracy: 0.5993 - val_loss: 0.6661 - val_binary_accuracy: 0.5990\n",
            "Epoch 324/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6665 - binary_accuracy: 0.6004 - val_loss: 0.6660 - val_binary_accuracy: 0.5984\n",
            "Epoch 325/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6665 - binary_accuracy: 0.6006 - val_loss: 0.6659 - val_binary_accuracy: 0.5984\n",
            "Epoch 326/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6664 - binary_accuracy: 0.6003 - val_loss: 0.6659 - val_binary_accuracy: 0.5984\n",
            "Epoch 327/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6664 - binary_accuracy: 0.5990 - val_loss: 0.6659 - val_binary_accuracy: 0.5978\n",
            "Epoch 328/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6664 - binary_accuracy: 0.5996 - val_loss: 0.6659 - val_binary_accuracy: 0.5978\n",
            "Epoch 329/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6663 - binary_accuracy: 0.6003 - val_loss: 0.6659 - val_binary_accuracy: 0.5984\n",
            "Epoch 330/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6663 - binary_accuracy: 0.6003 - val_loss: 0.6658 - val_binary_accuracy: 0.5995\n",
            "Epoch 331/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6663 - binary_accuracy: 0.5996 - val_loss: 0.6658 - val_binary_accuracy: 0.5995\n",
            "Epoch 332/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6663 - binary_accuracy: 0.6000 - val_loss: 0.6658 - val_binary_accuracy: 0.5984\n",
            "Epoch 333/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6662 - binary_accuracy: 0.6006 - val_loss: 0.6658 - val_binary_accuracy: 0.5984\n",
            "Epoch 334/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6662 - binary_accuracy: 0.6001 - val_loss: 0.6658 - val_binary_accuracy: 0.5995\n",
            "Epoch 335/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6662 - binary_accuracy: 0.5997 - val_loss: 0.6658 - val_binary_accuracy: 0.5978\n",
            "Epoch 336/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6662 - binary_accuracy: 0.6007 - val_loss: 0.6658 - val_binary_accuracy: 0.6001\n",
            "Epoch 337/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6661 - binary_accuracy: 0.6000 - val_loss: 0.6658 - val_binary_accuracy: 0.6001\n",
            "Epoch 338/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6661 - binary_accuracy: 0.5993 - val_loss: 0.6657 - val_binary_accuracy: 0.6013\n",
            "Epoch 339/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6661 - binary_accuracy: 0.6009 - val_loss: 0.6657 - val_binary_accuracy: 0.5990\n",
            "Epoch 340/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6661 - binary_accuracy: 0.6001 - val_loss: 0.6657 - val_binary_accuracy: 0.5984\n",
            "Epoch 341/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6660 - binary_accuracy: 0.6000 - val_loss: 0.6657 - val_binary_accuracy: 0.5990\n",
            "Epoch 342/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6660 - binary_accuracy: 0.6001 - val_loss: 0.6657 - val_binary_accuracy: 0.5995\n",
            "Epoch 343/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6660 - binary_accuracy: 0.6007 - val_loss: 0.6657 - val_binary_accuracy: 0.6013\n",
            "Epoch 344/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6660 - binary_accuracy: 0.6006 - val_loss: 0.6657 - val_binary_accuracy: 0.5995\n",
            "Epoch 345/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6659 - binary_accuracy: 0.6004 - val_loss: 0.6657 - val_binary_accuracy: 0.5990\n",
            "Epoch 346/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6659 - binary_accuracy: 0.6009 - val_loss: 0.6656 - val_binary_accuracy: 0.5995\n",
            "Epoch 347/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6659 - binary_accuracy: 0.6006 - val_loss: 0.6656 - val_binary_accuracy: 0.5990\n",
            "Epoch 348/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6659 - binary_accuracy: 0.6003 - val_loss: 0.6656 - val_binary_accuracy: 0.6001\n",
            "Epoch 349/1000\n",
            "6975/6975 [==============================] - 0s 67us/sample - loss: 0.6659 - binary_accuracy: 0.6006 - val_loss: 0.6656 - val_binary_accuracy: 0.6001\n",
            "Epoch 350/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6658 - binary_accuracy: 0.6011 - val_loss: 0.6656 - val_binary_accuracy: 0.5990\n",
            "Epoch 351/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6658 - binary_accuracy: 0.6011 - val_loss: 0.6656 - val_binary_accuracy: 0.5990\n",
            "Epoch 352/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6658 - binary_accuracy: 0.6004 - val_loss: 0.6656 - val_binary_accuracy: 0.5995\n",
            "Epoch 353/1000\n",
            "6975/6975 [==============================] - 0s 66us/sample - loss: 0.6657 - binary_accuracy: 0.6009 - val_loss: 0.6656 - val_binary_accuracy: 0.6001\n",
            "Epoch 354/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6657 - binary_accuracy: 0.6009 - val_loss: 0.6655 - val_binary_accuracy: 0.6001\n",
            "Epoch 355/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6657 - binary_accuracy: 0.6001 - val_loss: 0.6656 - val_binary_accuracy: 0.5990\n",
            "Epoch 356/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6657 - binary_accuracy: 0.6009 - val_loss: 0.6656 - val_binary_accuracy: 0.5978\n",
            "Epoch 357/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6657 - binary_accuracy: 0.6014 - val_loss: 0.6656 - val_binary_accuracy: 0.5990\n",
            "Epoch 358/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6657 - binary_accuracy: 0.6000 - val_loss: 0.6656 - val_binary_accuracy: 0.5995\n",
            "Epoch 359/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6656 - binary_accuracy: 0.6010 - val_loss: 0.6655 - val_binary_accuracy: 0.5995\n",
            "Epoch 360/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6656 - binary_accuracy: 0.6013 - val_loss: 0.6655 - val_binary_accuracy: 0.5995\n",
            "Epoch 361/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6656 - binary_accuracy: 0.6004 - val_loss: 0.6655 - val_binary_accuracy: 0.6001\n",
            "Epoch 362/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6656 - binary_accuracy: 0.5999 - val_loss: 0.6655 - val_binary_accuracy: 0.6001\n",
            "Epoch 363/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6655 - binary_accuracy: 0.6010 - val_loss: 0.6654 - val_binary_accuracy: 0.6001\n",
            "Epoch 364/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6655 - binary_accuracy: 0.6004 - val_loss: 0.6655 - val_binary_accuracy: 0.5995\n",
            "Epoch 365/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6655 - binary_accuracy: 0.6001 - val_loss: 0.6655 - val_binary_accuracy: 0.5995\n",
            "Epoch 366/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6655 - binary_accuracy: 0.6010 - val_loss: 0.6654 - val_binary_accuracy: 0.6007\n",
            "Epoch 367/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6655 - binary_accuracy: 0.6006 - val_loss: 0.6654 - val_binary_accuracy: 0.5995\n",
            "Epoch 368/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6655 - binary_accuracy: 0.6000 - val_loss: 0.6654 - val_binary_accuracy: 0.6007\n",
            "Epoch 369/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6654 - binary_accuracy: 0.6006 - val_loss: 0.6654 - val_binary_accuracy: 0.6001\n",
            "Epoch 370/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.6654 - binary_accuracy: 0.6001 - val_loss: 0.6654 - val_binary_accuracy: 0.6007\n",
            "Epoch 371/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6654 - binary_accuracy: 0.6007 - val_loss: 0.6653 - val_binary_accuracy: 0.6013\n",
            "Epoch 372/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6654 - binary_accuracy: 0.6003 - val_loss: 0.6654 - val_binary_accuracy: 0.6007\n",
            "Epoch 373/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6653 - binary_accuracy: 0.6013 - val_loss: 0.6654 - val_binary_accuracy: 0.6007\n",
            "Epoch 374/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6653 - binary_accuracy: 0.5999 - val_loss: 0.6654 - val_binary_accuracy: 0.6001\n",
            "Epoch 375/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6653 - binary_accuracy: 0.5999 - val_loss: 0.6653 - val_binary_accuracy: 0.6018\n",
            "Epoch 376/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6653 - binary_accuracy: 0.6009 - val_loss: 0.6654 - val_binary_accuracy: 0.6018\n",
            "Epoch 377/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6653 - binary_accuracy: 0.5990 - val_loss: 0.6654 - val_binary_accuracy: 0.6018\n",
            "Epoch 378/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6652 - binary_accuracy: 0.6001 - val_loss: 0.6653 - val_binary_accuracy: 0.6007\n",
            "Epoch 379/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6652 - binary_accuracy: 0.6013 - val_loss: 0.6653 - val_binary_accuracy: 0.6001\n",
            "Epoch 380/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6652 - binary_accuracy: 0.5997 - val_loss: 0.6653 - val_binary_accuracy: 0.6007\n",
            "Epoch 381/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6652 - binary_accuracy: 0.6003 - val_loss: 0.6653 - val_binary_accuracy: 0.6013\n",
            "Epoch 382/1000\n",
            "6975/6975 [==============================] - 1s 86us/sample - loss: 0.6651 - binary_accuracy: 0.6007 - val_loss: 0.6653 - val_binary_accuracy: 0.6007\n",
            "Epoch 383/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6652 - binary_accuracy: 0.6001 - val_loss: 0.6653 - val_binary_accuracy: 0.6030\n",
            "Epoch 384/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6651 - binary_accuracy: 0.6004 - val_loss: 0.6653 - val_binary_accuracy: 0.6007\n",
            "Epoch 385/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6651 - binary_accuracy: 0.6001 - val_loss: 0.6653 - val_binary_accuracy: 0.6007\n",
            "Epoch 386/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6651 - binary_accuracy: 0.5983 - val_loss: 0.6653 - val_binary_accuracy: 0.6041\n",
            "Epoch 387/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6651 - binary_accuracy: 0.6006 - val_loss: 0.6653 - val_binary_accuracy: 0.6030\n",
            "Epoch 388/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6651 - binary_accuracy: 0.6011 - val_loss: 0.6652 - val_binary_accuracy: 0.6013\n",
            "Epoch 389/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6651 - binary_accuracy: 0.6006 - val_loss: 0.6652 - val_binary_accuracy: 0.6007\n",
            "Epoch 390/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6650 - binary_accuracy: 0.6001 - val_loss: 0.6652 - val_binary_accuracy: 0.6018\n",
            "Epoch 391/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6650 - binary_accuracy: 0.6006 - val_loss: 0.6652 - val_binary_accuracy: 0.6024\n",
            "Epoch 392/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6650 - binary_accuracy: 0.6006 - val_loss: 0.6652 - val_binary_accuracy: 0.6024\n",
            "Epoch 393/1000\n",
            "6975/6975 [==============================] - 0s 72us/sample - loss: 0.6650 - binary_accuracy: 0.6003 - val_loss: 0.6652 - val_binary_accuracy: 0.6018\n",
            "Epoch 394/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6650 - binary_accuracy: 0.6010 - val_loss: 0.6652 - val_binary_accuracy: 0.6030\n",
            "Epoch 395/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6649 - binary_accuracy: 0.6011 - val_loss: 0.6651 - val_binary_accuracy: 0.6024\n",
            "Epoch 396/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6649 - binary_accuracy: 0.6009 - val_loss: 0.6651 - val_binary_accuracy: 0.6024\n",
            "Epoch 397/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6649 - binary_accuracy: 0.6006 - val_loss: 0.6651 - val_binary_accuracy: 0.6024\n",
            "Epoch 398/1000\n",
            "6975/6975 [==============================] - 1s 81us/sample - loss: 0.6649 - binary_accuracy: 0.6001 - val_loss: 0.6651 - val_binary_accuracy: 0.6036\n",
            "Epoch 399/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6648 - binary_accuracy: 0.6010 - val_loss: 0.6651 - val_binary_accuracy: 0.6030\n",
            "Epoch 400/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6648 - binary_accuracy: 0.6001 - val_loss: 0.6651 - val_binary_accuracy: 0.6041\n",
            "Epoch 401/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6649 - binary_accuracy: 0.6007 - val_loss: 0.6650 - val_binary_accuracy: 0.6036\n",
            "Epoch 402/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6648 - binary_accuracy: 0.6011 - val_loss: 0.6650 - val_binary_accuracy: 0.6030\n",
            "Epoch 403/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6648 - binary_accuracy: 0.6013 - val_loss: 0.6650 - val_binary_accuracy: 0.6041\n",
            "Epoch 404/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6648 - binary_accuracy: 0.6013 - val_loss: 0.6651 - val_binary_accuracy: 0.6036\n",
            "Epoch 405/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6648 - binary_accuracy: 0.6014 - val_loss: 0.6651 - val_binary_accuracy: 0.6036\n",
            "Epoch 406/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6647 - binary_accuracy: 0.6014 - val_loss: 0.6650 - val_binary_accuracy: 0.6036\n",
            "Epoch 407/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6647 - binary_accuracy: 0.6013 - val_loss: 0.6650 - val_binary_accuracy: 0.6036\n",
            "Epoch 408/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6647 - binary_accuracy: 0.6011 - val_loss: 0.6650 - val_binary_accuracy: 0.6047\n",
            "Epoch 409/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6647 - binary_accuracy: 0.6017 - val_loss: 0.6650 - val_binary_accuracy: 0.6036\n",
            "Epoch 410/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6647 - binary_accuracy: 0.6017 - val_loss: 0.6650 - val_binary_accuracy: 0.6041\n",
            "Epoch 411/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6647 - binary_accuracy: 0.6009 - val_loss: 0.6650 - val_binary_accuracy: 0.6041\n",
            "Epoch 412/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6646 - binary_accuracy: 0.6020 - val_loss: 0.6650 - val_binary_accuracy: 0.6041\n",
            "Epoch 413/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6647 - binary_accuracy: 0.6017 - val_loss: 0.6649 - val_binary_accuracy: 0.6036\n",
            "Epoch 414/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6646 - binary_accuracy: 0.6010 - val_loss: 0.6650 - val_binary_accuracy: 0.6041\n",
            "Epoch 415/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6646 - binary_accuracy: 0.6014 - val_loss: 0.6649 - val_binary_accuracy: 0.6024\n",
            "Epoch 416/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6646 - binary_accuracy: 0.5999 - val_loss: 0.6649 - val_binary_accuracy: 0.6041\n",
            "Epoch 417/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6646 - binary_accuracy: 0.6014 - val_loss: 0.6649 - val_binary_accuracy: 0.6041\n",
            "Epoch 418/1000\n",
            "6975/6975 [==============================] - 1s 83us/sample - loss: 0.6646 - binary_accuracy: 0.6024 - val_loss: 0.6648 - val_binary_accuracy: 0.6024\n",
            "Epoch 419/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6646 - binary_accuracy: 0.6016 - val_loss: 0.6649 - val_binary_accuracy: 0.6036\n",
            "Epoch 420/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6645 - binary_accuracy: 0.6010 - val_loss: 0.6650 - val_binary_accuracy: 0.6030\n",
            "Epoch 421/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6645 - binary_accuracy: 0.6019 - val_loss: 0.6649 - val_binary_accuracy: 0.6041\n",
            "Epoch 422/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6645 - binary_accuracy: 0.6020 - val_loss: 0.6648 - val_binary_accuracy: 0.6047\n",
            "Epoch 423/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6645 - binary_accuracy: 0.6010 - val_loss: 0.6649 - val_binary_accuracy: 0.6047\n",
            "Epoch 424/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6644 - binary_accuracy: 0.6017 - val_loss: 0.6649 - val_binary_accuracy: 0.6036\n",
            "Epoch 425/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6645 - binary_accuracy: 0.6016 - val_loss: 0.6649 - val_binary_accuracy: 0.6036\n",
            "Epoch 426/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6644 - binary_accuracy: 0.6019 - val_loss: 0.6648 - val_binary_accuracy: 0.6047\n",
            "Epoch 427/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6644 - binary_accuracy: 0.6007 - val_loss: 0.6648 - val_binary_accuracy: 0.6041\n",
            "Epoch 428/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6644 - binary_accuracy: 0.6003 - val_loss: 0.6648 - val_binary_accuracy: 0.6047\n",
            "Epoch 429/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6644 - binary_accuracy: 0.6011 - val_loss: 0.6648 - val_binary_accuracy: 0.6047\n",
            "Epoch 430/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6644 - binary_accuracy: 0.6020 - val_loss: 0.6647 - val_binary_accuracy: 0.6013\n",
            "Epoch 431/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6643 - binary_accuracy: 0.6003 - val_loss: 0.6648 - val_binary_accuracy: 0.6047\n",
            "Epoch 432/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6643 - binary_accuracy: 0.6027 - val_loss: 0.6647 - val_binary_accuracy: 0.6013\n",
            "Epoch 433/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6643 - binary_accuracy: 0.6007 - val_loss: 0.6647 - val_binary_accuracy: 0.6036\n",
            "Epoch 434/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6643 - binary_accuracy: 0.6016 - val_loss: 0.6647 - val_binary_accuracy: 0.6036\n",
            "Epoch 435/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6643 - binary_accuracy: 0.6016 - val_loss: 0.6647 - val_binary_accuracy: 0.6013\n",
            "Epoch 436/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6643 - binary_accuracy: 0.6013 - val_loss: 0.6647 - val_binary_accuracy: 0.6013\n",
            "Epoch 437/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6642 - binary_accuracy: 0.6011 - val_loss: 0.6647 - val_binary_accuracy: 0.6041\n",
            "Epoch 438/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6643 - binary_accuracy: 0.6014 - val_loss: 0.6647 - val_binary_accuracy: 0.6030\n",
            "Epoch 439/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6642 - binary_accuracy: 0.6016 - val_loss: 0.6647 - val_binary_accuracy: 0.6030\n",
            "Epoch 440/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6642 - binary_accuracy: 0.6017 - val_loss: 0.6647 - val_binary_accuracy: 0.6013\n",
            "Epoch 441/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6642 - binary_accuracy: 0.6011 - val_loss: 0.6647 - val_binary_accuracy: 0.6041\n",
            "Epoch 442/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6642 - binary_accuracy: 0.6027 - val_loss: 0.6646 - val_binary_accuracy: 0.6001\n",
            "Epoch 443/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6642 - binary_accuracy: 0.6010 - val_loss: 0.6647 - val_binary_accuracy: 0.6041\n",
            "Epoch 444/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6642 - binary_accuracy: 0.6016 - val_loss: 0.6646 - val_binary_accuracy: 0.6024\n",
            "Epoch 445/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6641 - binary_accuracy: 0.6007 - val_loss: 0.6646 - val_binary_accuracy: 0.6024\n",
            "Epoch 446/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6641 - binary_accuracy: 0.6019 - val_loss: 0.6646 - val_binary_accuracy: 0.6030\n",
            "Epoch 447/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6641 - binary_accuracy: 0.6006 - val_loss: 0.6647 - val_binary_accuracy: 0.6013\n",
            "Epoch 448/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6641 - binary_accuracy: 0.6030 - val_loss: 0.6646 - val_binary_accuracy: 0.6013\n",
            "Epoch 449/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6641 - binary_accuracy: 0.6017 - val_loss: 0.6646 - val_binary_accuracy: 0.6018\n",
            "Epoch 450/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6641 - binary_accuracy: 0.6007 - val_loss: 0.6647 - val_binary_accuracy: 0.6013\n",
            "Epoch 451/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6641 - binary_accuracy: 0.6013 - val_loss: 0.6646 - val_binary_accuracy: 0.6018\n",
            "Epoch 452/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6641 - binary_accuracy: 0.6013 - val_loss: 0.6646 - val_binary_accuracy: 0.6013\n",
            "Epoch 453/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6640 - binary_accuracy: 0.6016 - val_loss: 0.6646 - val_binary_accuracy: 0.6013\n",
            "Epoch 454/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6640 - binary_accuracy: 0.6009 - val_loss: 0.6646 - val_binary_accuracy: 0.6018\n",
            "Epoch 455/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6640 - binary_accuracy: 0.6017 - val_loss: 0.6646 - val_binary_accuracy: 0.6001\n",
            "Epoch 456/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6640 - binary_accuracy: 0.6004 - val_loss: 0.6646 - val_binary_accuracy: 0.6001\n",
            "Epoch 457/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6640 - binary_accuracy: 0.6014 - val_loss: 0.6645 - val_binary_accuracy: 0.6007\n",
            "Epoch 458/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6640 - binary_accuracy: 0.6019 - val_loss: 0.6645 - val_binary_accuracy: 0.6001\n",
            "Epoch 459/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6640 - binary_accuracy: 0.6010 - val_loss: 0.6645 - val_binary_accuracy: 0.6001\n",
            "Epoch 460/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6640 - binary_accuracy: 0.6003 - val_loss: 0.6645 - val_binary_accuracy: 0.5990\n",
            "Epoch 461/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6639 - binary_accuracy: 0.6010 - val_loss: 0.6645 - val_binary_accuracy: 0.5984\n",
            "Epoch 462/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6639 - binary_accuracy: 0.6006 - val_loss: 0.6645 - val_binary_accuracy: 0.5990\n",
            "Epoch 463/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6639 - binary_accuracy: 0.6004 - val_loss: 0.6645 - val_binary_accuracy: 0.5984\n",
            "Epoch 464/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6639 - binary_accuracy: 0.6003 - val_loss: 0.6645 - val_binary_accuracy: 0.5990\n",
            "Epoch 465/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6639 - binary_accuracy: 0.6011 - val_loss: 0.6645 - val_binary_accuracy: 0.5995\n",
            "Epoch 466/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6639 - binary_accuracy: 0.6016 - val_loss: 0.6645 - val_binary_accuracy: 0.5984\n",
            "Epoch 467/1000\n",
            "6975/6975 [==============================] - 1s 82us/sample - loss: 0.6639 - binary_accuracy: 0.6010 - val_loss: 0.6645 - val_binary_accuracy: 0.5984\n",
            "Epoch 468/1000\n",
            "6975/6975 [==============================] - 1s 85us/sample - loss: 0.6639 - binary_accuracy: 0.6016 - val_loss: 0.6646 - val_binary_accuracy: 0.5990\n",
            "Epoch 469/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6639 - binary_accuracy: 0.6019 - val_loss: 0.6644 - val_binary_accuracy: 0.5984\n",
            "Epoch 470/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6638 - binary_accuracy: 0.6010 - val_loss: 0.6645 - val_binary_accuracy: 0.5990\n",
            "Epoch 471/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6638 - binary_accuracy: 0.6017 - val_loss: 0.6644 - val_binary_accuracy: 0.5984\n",
            "Epoch 472/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6638 - binary_accuracy: 0.6032 - val_loss: 0.6644 - val_binary_accuracy: 0.5984\n",
            "Epoch 473/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6638 - binary_accuracy: 0.6010 - val_loss: 0.6644 - val_binary_accuracy: 0.5984\n",
            "Epoch 474/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6638 - binary_accuracy: 0.6017 - val_loss: 0.6644 - val_binary_accuracy: 0.5990\n",
            "Epoch 475/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6637 - binary_accuracy: 0.6007 - val_loss: 0.6644 - val_binary_accuracy: 0.5978\n",
            "Epoch 476/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6638 - binary_accuracy: 0.6006 - val_loss: 0.6644 - val_binary_accuracy: 0.5984\n",
            "Epoch 477/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6637 - binary_accuracy: 0.6013 - val_loss: 0.6644 - val_binary_accuracy: 0.5978\n",
            "Epoch 478/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6637 - binary_accuracy: 0.6007 - val_loss: 0.6644 - val_binary_accuracy: 0.5984\n",
            "Epoch 479/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6637 - binary_accuracy: 0.6016 - val_loss: 0.6644 - val_binary_accuracy: 0.5978\n",
            "Epoch 480/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6637 - binary_accuracy: 0.6016 - val_loss: 0.6644 - val_binary_accuracy: 0.5978\n",
            "Epoch 481/1000\n",
            "6975/6975 [==============================] - 0s 70us/sample - loss: 0.6637 - binary_accuracy: 0.6023 - val_loss: 0.6644 - val_binary_accuracy: 0.5978\n",
            "Epoch 482/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6637 - binary_accuracy: 0.6016 - val_loss: 0.6644 - val_binary_accuracy: 0.5978\n",
            "Epoch 483/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6637 - binary_accuracy: 0.6014 - val_loss: 0.6644 - val_binary_accuracy: 0.5972\n",
            "Epoch 484/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6637 - binary_accuracy: 0.6007 - val_loss: 0.6644 - val_binary_accuracy: 0.5972\n",
            "Epoch 485/1000\n",
            "6975/6975 [==============================] - 0s 68us/sample - loss: 0.6636 - binary_accuracy: 0.6017 - val_loss: 0.6643 - val_binary_accuracy: 0.5972\n",
            "Epoch 486/1000\n",
            "6975/6975 [==============================] - 1s 72us/sample - loss: 0.6636 - binary_accuracy: 0.6013 - val_loss: 0.6644 - val_binary_accuracy: 0.5967\n",
            "Epoch 487/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6636 - binary_accuracy: 0.6010 - val_loss: 0.6643 - val_binary_accuracy: 0.5984\n",
            "Epoch 488/1000\n",
            "6975/6975 [==============================] - 1s 79us/sample - loss: 0.6636 - binary_accuracy: 0.6013 - val_loss: 0.6644 - val_binary_accuracy: 0.5967\n",
            "Epoch 489/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6636 - binary_accuracy: 0.6013 - val_loss: 0.6643 - val_binary_accuracy: 0.5967\n",
            "Epoch 490/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6636 - binary_accuracy: 0.6013 - val_loss: 0.6644 - val_binary_accuracy: 0.5972\n",
            "Epoch 491/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6636 - binary_accuracy: 0.6017 - val_loss: 0.6644 - val_binary_accuracy: 0.5972\n",
            "Epoch 492/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6636 - binary_accuracy: 0.6014 - val_loss: 0.6643 - val_binary_accuracy: 0.5961\n",
            "Epoch 493/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6635 - binary_accuracy: 0.6011 - val_loss: 0.6643 - val_binary_accuracy: 0.5967\n",
            "Epoch 494/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6636 - binary_accuracy: 0.6007 - val_loss: 0.6643 - val_binary_accuracy: 0.5972\n",
            "Epoch 495/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6635 - binary_accuracy: 0.6009 - val_loss: 0.6643 - val_binary_accuracy: 0.5967\n",
            "Epoch 496/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6635 - binary_accuracy: 0.6019 - val_loss: 0.6643 - val_binary_accuracy: 0.5984\n",
            "Epoch 497/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6635 - binary_accuracy: 0.6011 - val_loss: 0.6643 - val_binary_accuracy: 0.5978\n",
            "Epoch 498/1000\n",
            "6975/6975 [==============================] - 1s 78us/sample - loss: 0.6635 - binary_accuracy: 0.6006 - val_loss: 0.6643 - val_binary_accuracy: 0.5961\n",
            "Epoch 499/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6635 - binary_accuracy: 0.6016 - val_loss: 0.6643 - val_binary_accuracy: 0.5967\n",
            "Epoch 500/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6635 - binary_accuracy: 0.6014 - val_loss: 0.6642 - val_binary_accuracy: 0.5972\n",
            "Epoch 501/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6635 - binary_accuracy: 0.6022 - val_loss: 0.6642 - val_binary_accuracy: 0.5967\n",
            "Epoch 502/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6635 - binary_accuracy: 0.6004 - val_loss: 0.6643 - val_binary_accuracy: 0.5961\n",
            "Epoch 503/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6634 - binary_accuracy: 0.6022 - val_loss: 0.6642 - val_binary_accuracy: 0.5967\n",
            "Epoch 504/1000\n",
            "6975/6975 [==============================] - 1s 86us/sample - loss: 0.6634 - binary_accuracy: 0.6016 - val_loss: 0.6642 - val_binary_accuracy: 0.5967\n",
            "Epoch 505/1000\n",
            "6975/6975 [==============================] - 1s 73us/sample - loss: 0.6635 - binary_accuracy: 0.6013 - val_loss: 0.6642 - val_binary_accuracy: 0.5967\n",
            "Epoch 506/1000\n",
            "6975/6975 [==============================] - 1s 76us/sample - loss: 0.6634 - binary_accuracy: 0.6006 - val_loss: 0.6642 - val_binary_accuracy: 0.5950\n",
            "Epoch 507/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6634 - binary_accuracy: 0.6014 - val_loss: 0.6643 - val_binary_accuracy: 0.5961\n",
            "Epoch 508/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6634 - binary_accuracy: 0.6006 - val_loss: 0.6643 - val_binary_accuracy: 0.5961\n",
            "Epoch 509/1000\n",
            "6975/6975 [==============================] - 1s 77us/sample - loss: 0.6634 - binary_accuracy: 0.6016 - val_loss: 0.6643 - val_binary_accuracy: 0.5961\n",
            "Epoch 510/1000\n",
            "6975/6975 [==============================] - 1s 74us/sample - loss: 0.6634 - binary_accuracy: 0.5999 - val_loss: 0.6643 - val_binary_accuracy: 0.5967\n",
            "Epoch 511/1000\n",
            "6975/6975 [==============================] - 1s 75us/sample - loss: 0.6634 - binary_accuracy: 0.6017 - val_loss: 0.6643 - val_binary_accuracy: 0.5967\n",
            "Epoch 512/1000\n",
            "6975/6975 [==============================] - 0s 69us/sample - loss: 0.6633 - binary_accuracy: 0.6009 - val_loss: 0.6642 - val_binary_accuracy: 0.5961\n",
            "Epoch 513/1000\n",
            "6975/6975 [==============================] - 0s 71us/sample - loss: 0.6634 - binary_accuracy: 0.6011 - val_loss: 0.6642 - val_binary_accuracy: 0.5950\n",
            "Epoch 514/1000\n",
            "6975/6975 [==============================] - 1s 80us/sample - loss: 0.6633 - binary_accuracy: 0.5996 - val_loss: 0.6642 - val_binary_accuracy: 0.5955\n",
            "\n",
            " 5 fold accuracy :  ['0.6051', '0.6014', '0.6022', '0.6065', '0.6017']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(performance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io52XcU7nvrg",
        "outputId": "5cdc4a16-17b7-4705-cc51-0cb086544970"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.669360934047524, 0.60951835], [0.6599241221716644, 0.603211], [0.6638395305073589, 0.61066514], [0.678685313623935, 0.5742972], [0.664238231967252, 0.59552497]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.evaluate(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtHX2ChFnMYk",
        "outputId": "0a54302e-15d4-420c-f317-8273f5f06169"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.6689596084279752, 0.59541285]\n"
          ]
        }
      ]
    }
  ]
}